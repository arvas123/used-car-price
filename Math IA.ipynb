{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72bd75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b0f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/vw.csv') #load data into pandas dataframe\n",
    "df.head() #display first 5 rows\n",
    "df.sample(n=5) #display 5 random rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a68dc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model               T-Roc\n",
       "year                 2019\n",
       "transmission    Automatic\n",
       "mileage             13904\n",
       "fuelType           Diesel\n",
       "tax                   145\n",
       "mpg                  49.6\n",
       "engineSize            2.0\n",
       "price               25000\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.dropna(how = 'all', inplace = True) #removes rows which contain any blank cells\n",
    "df_numeric = df.select_dtypes(include=[np.number]) #select coloumns which contain numeric data\n",
    "for col in df_numeric:\n",
    "    if col=='year':\n",
    "        continue\n",
    "    average =  np.average(df_numeric[col])\n",
    "    standard_deviation = np.std(df_numeric[col])\n",
    "    max_value = average + 3*standard_deviation\n",
    "    min_value = average - 3*standard_deviation\n",
    "    for idx, row_val in enumerate(df_numeric[col]):\n",
    "        if min_value<row_val<max_value: #check if value is an outlier with average +- 3*s.d.\n",
    "            print(df.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96ab820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding\n",
    "df_non_numeric = df.select_dtypes(exclude=[np.number]) #Finding the coloumns with categorical data\n",
    "\n",
    "label = LabelEncoder()\n",
    "for col in df_non_numeric:\n",
    "    #Find the unique categories i.e (Manual, Semi-Auto and Automatics)\n",
    "    s=set()\n",
    "    for val in df_non_numeric[col]:\n",
    "        s.add(val)\n",
    "    s=list(s)\n",
    "    int_data = label.fit_transform(s)\n",
    "    int_data = int_data.reshape(len(int_data), 1)\n",
    "    onehot_data = OneHotEncoder(sparse=False) \n",
    "    onehot_data = (onehot_data.fit_transform(int_data)) #Convert the categories into onehot data\n",
    "    df[col] = np.array([onehot_data[s.index(val)] for val in df[col]]) #Add these categories to the dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42204166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10609, 8)\n",
      "(10609, 1)\n",
      "(4548, 8)\n",
      "(4548, 1)\n"
     ]
    }
   ],
   "source": [
    "target_variable = ['price']\n",
    "Predictors = ['model',\t'year',\t'transmission',\t'mileage',\t'fuelType',\t'tax',\t'mpg',\t'engineSize']\n",
    "X=df[Predictors].values\n",
    "y=df[target_variable].values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dfe5a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(8,)))\n",
    "model.add(tf.keras.layers.Dense(4, kernel_initializer = 'normal', activation  = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(4, kernel_initializer = 'normal', activation  = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1, kernel_initializer = 'normal'))\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5620ae7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 315513220.6764 - acc: 0.0000e+00 - val_loss: 238526080.0000 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 224455267.2401 - acc: 0.0000e+00 - val_loss: 206269024.0000 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 180805512.5846 - acc: 0.0000e+00 - val_loss: 123181448.0000 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 91198506.6555 - acc: 0.0000e+00 - val_loss: 47007480.0000 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 41928085.7370 - acc: 0.0000e+00 - val_loss: 41498164.0000 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 39972386.3466 - acc: 0.0000e+00 - val_loss: 40294576.0000 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 39654843.0230 - acc: 0.0000e+00 - val_loss: 40167728.0000 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 38386040.6138 - acc: 0.0000e+00 - val_loss: 39749236.0000 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 39169745.4656 - acc: 0.0000e+00 - val_loss: 39512544.0000 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 39708529.9875 - acc: 0.0000e+00 - val_loss: 39365584.0000 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 38145157.2860 - acc: 0.0000e+00 - val_loss: 39087568.0000 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 37761491.1232 - acc: 0.0000e+00 - val_loss: 38889408.0000 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 37336191.8831 - acc: 0.0000e+00 - val_loss: 38675020.0000 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 36345366.6889 - acc: 0.0000e+00 - val_loss: 38437968.0000 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 37211677.4572 - acc: 0.0000e+00 - val_loss: 38305096.0000 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 36644926.1169 - acc: 0.0000e+00 - val_loss: 38073772.0000 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 36804906.3549 - acc: 0.0000e+00 - val_loss: 37853024.0000 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 38171322.6472 - acc: 0.0000e+00 - val_loss: 37720512.0000 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 36595482.0626 - acc: 0.0000e+00 - val_loss: 37691848.0000 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 37522304.7349 - acc: 0.0000e+00 - val_loss: 37423984.0000 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 35703486.9186 - acc: 0.0000e+00 - val_loss: 37282844.0000 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 37104097.9207 - acc: 0.0000e+00 - val_loss: 37091932.0000 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 35910414.8225 - acc: 0.0000e+00 - val_loss: 36951292.0000 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 36581407.4280 - acc: 0.0000e+00 - val_loss: 36818436.0000 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 35470335.3236 - acc: 0.0000e+00 - val_loss: 36825408.0000 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 36209363.9582 - acc: 0.0000e+00 - val_loss: 36640292.0000 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 34702728.0710 - acc: 0.0000e+00 - val_loss: 36517704.0000 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 35576855.5198 - acc: 0.0000e+00 - val_loss: 36403036.0000 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 34439027.7662 - acc: 0.0000e+00 - val_loss: 36435604.0000 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 35742324.5219 - acc: 0.0000e+00 - val_loss: 36400428.0000 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 34445528.4384 - acc: 0.0000e+00 - val_loss: 36153408.0000 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 34775376.1461 - acc: 0.0000e+00 - val_loss: 36006472.0000 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 34884582.0585 - acc: 0.0000e+00 - val_loss: 35967656.0000 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 34853941.3069 - acc: 0.0000e+00 - val_loss: 36097768.0000 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 35071607.9165 - acc: 0.0000e+00 - val_loss: 35899748.0000 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 34856560.4426 - acc: 0.0000e+00 - val_loss: 35595680.0000 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 35389155.8831 - acc: 0.0000e+00 - val_loss: 35507700.0000 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 35602984.6764 - acc: 0.0000e+00 - val_loss: 35428464.0000 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 34856108.3132 - acc: 0.0000e+00 - val_loss: 35361664.0000 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 34378753.6868 - acc: 0.0000e+00 - val_loss: 35265932.0000 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33944058.4050 - acc: 0.0000e+00 - val_loss: 35197396.0000 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32652027.6409 - acc: 0.0000e+00 - val_loss: 35127900.0000 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33943417.1106 - acc: 0.0000e+00 - val_loss: 35662936.0000 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 33799603.5532 - acc: 0.0000e+00 - val_loss: 35122728.0000 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33904145.0104 - acc: 0.0000e+00 - val_loss: 35150868.0000 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32574487.3862 - acc: 0.0000e+00 - val_loss: 34775544.0000 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32209019.5908 - acc: 0.0000e+00 - val_loss: 34623432.0000 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33058309.8539 - acc: 0.0000e+00 - val_loss: 34695212.0000 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33529013.1106 - acc: 0.0000e+00 - val_loss: 34819740.0000 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33068838.9061 - acc: 0.0000e+00 - val_loss: 34366892.0000 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32630390.3424 - acc: 0.0000e+00 - val_loss: 34346116.0000 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32342054.2192 - acc: 0.0000e+00 - val_loss: 34325116.0000 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33662945.3194 - acc: 0.0000e+00 - val_loss: 34160396.0000 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33121980.4008 - acc: 0.0000e+00 - val_loss: 34025840.0000 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32839930.8058 - acc: 0.0000e+00 - val_loss: 33974764.0000 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33759477.6263 - acc: 0.0000e+00 - val_loss: 33990368.0000 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 34177682.0000 - acc: 0.0000e+00 - val_loss: 33773360.0000 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33112945.1106 - acc: 0.0000e+00 - val_loss: 33951892.0000 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33060283.6367 - acc: 0.0000e+00 - val_loss: 33862040.0000 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33998014.4614 - acc: 0.0000e+00 - val_loss: 33518668.0000 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 33623126.6848 - acc: 0.0000e+00 - val_loss: 33506462.0000 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32825683.5365 - acc: 0.0000e+00 - val_loss: 33311860.0000 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32654301.3612 - acc: 0.0000e+00 - val_loss: 33299754.0000 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32593273.8038 - acc: 0.0000e+00 - val_loss: 33107558.0000 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32077740.2129 - acc: 0.0000e+00 - val_loss: 33108324.0000 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32494880.4238 - acc: 0.0000e+00 - val_loss: 33087902.0000 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 30979008.8894 - acc: 0.0000e+00 - val_loss: 32871546.0000 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 30806171.4154 - acc: 0.0000e+00 - val_loss: 33027342.0000 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 32988609.0960 - acc: 0.0000e+00 - val_loss: 32613244.0000 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 31704596.7265 - acc: 0.0000e+00 - val_loss: 32479420.0000 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 30364650.7808 - acc: 0.0000e+00 - val_loss: 32408514.0000 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 31112808.3925 - acc: 0.0000e+00 - val_loss: 32249590.0000 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 31289937.8664 - acc: 0.0000e+00 - val_loss: 32169426.0000 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 31654255.2526 - acc: 0.0000e+00 - val_loss: 32020922.0000 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 30249976.9019 - acc: 0.0000e+00 - val_loss: 32345518.0000 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 29554257.6075 - acc: 0.0000e+00 - val_loss: 31809558.0000 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 31059498.5386 - acc: 0.0000e+00 - val_loss: 31649556.0000 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 30727449.3904 - acc: 0.0000e+00 - val_loss: 31513018.0000 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 29802112.6096 - acc: 0.0000e+00 - val_loss: 31317434.0000 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 30538827.0271 - acc: 0.0000e+00 - val_loss: 31823428.0000 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 31076840.2129 - acc: 0.0000e+00 - val_loss: 31060360.0000 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 30904147.3967 - acc: 0.0000e+00 - val_loss: 30939866.0000 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 28568642.2422 - acc: 0.0000e+00 - val_loss: 30867516.0000 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 29111819.8163 - acc: 0.0000e+00 - val_loss: 30515544.0000 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 30351176.9603 - acc: 0.0000e+00 - val_loss: 30417880.0000 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 29570596.3758 - acc: 0.0000e+00 - val_loss: 30119584.0000 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 28763651.5699 - acc: 0.0000e+00 - val_loss: 29971400.0000 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 28305245.5783 - acc: 0.0000e+00 - val_loss: 30197884.0000 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 27813808.1545 - acc: 0.0000e+00 - val_loss: 29889024.0000 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 28393555.5825 - acc: 0.0000e+00 - val_loss: 29394556.0000 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 28438355.2735 - acc: 0.0000e+00 - val_loss: 29549042.0000 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 30035245.8622 - acc: 0.0000e+00 - val_loss: 28904680.0000 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 27487411.6743 - acc: 0.0000e+00 - val_loss: 29217842.0000 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 27613637.6785 - acc: 0.0000e+00 - val_loss: 28607108.0000 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 27619091.2651 - acc: 0.0000e+00 - val_loss: 28622190.0000 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 27562693.4530 - acc: 0.0000e+00 - val_loss: 28169246.0000 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 27321701.6827 - acc: 0.0000e+00 - val_loss: 27862412.0000 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 27483859.0397 - acc: 0.0000e+00 - val_loss: 27599864.0000 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 26166816.2004 - acc: 0.0000e+00 - val_loss: 27685412.0000 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 27199146.5887 - acc: 0.0000e+00 - val_loss: 27366432.0000 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 26625191.3069 - acc: 0.0000e+00 - val_loss: 27090288.0000 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 26438768.2380 - acc: 0.0000e+00 - val_loss: 27434984.0000 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 25882221.0585 - acc: 0.0000e+00 - val_loss: 26866302.0000 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 25770949.5699 - acc: 0.0000e+00 - val_loss: 26496380.0000 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 24175873.7954 - acc: 0.0000e+00 - val_loss: 27500772.0000 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 25439571.0188 - acc: 0.0000e+00 - val_loss: 26533052.0000 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 25271986.4843 - acc: 0.0000e+00 - val_loss: 26221036.0000 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 25351751.8121 - acc: 0.0000e+00 - val_loss: 25800098.0000 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 25027562.4593 - acc: 0.0000e+00 - val_loss: 25810508.0000 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 25030892.8601 - acc: 0.0000e+00 - val_loss: 26202950.0000 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 23715716.5866 - acc: 0.0000e+00 - val_loss: 26148912.0000 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 25810086.7474 - acc: 0.0000e+00 - val_loss: 25613540.0000 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 23911955.7370 - acc: 0.0000e+00 - val_loss: 25180704.0000 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 24656094.1044 - acc: 0.0000e+00 - val_loss: 25405822.0000 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 24310439.5866 - acc: 0.0000e+00 - val_loss: 25294366.0000 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 24276268.9896 - acc: 0.0000e+00 - val_loss: 24848560.0000 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 23954555.1649 - acc: 0.0000e+00 - val_loss: 25169700.0000 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 23753673.0438 - acc: 0.0000e+00 - val_loss: 25275270.0000 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 23509412.4739 - acc: 0.0000e+00 - val_loss: 25050398.0000 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 23752492.0919 - acc: 0.0000e+00 - val_loss: 24871550.0000 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22226896.5115 - acc: 0.0000e+00 - val_loss: 25173658.0000 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22423762.2046 - acc: 0.0000e+00 - val_loss: 23968030.0000 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 24013005.2025 - acc: 0.0000e+00 - val_loss: 24034688.0000 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22980632.2067 - acc: 0.0000e+00 - val_loss: 24184482.0000 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22795770.4259 - acc: 0.0000e+00 - val_loss: 24178712.0000 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22300630.3507 - acc: 0.0000e+00 - val_loss: 24620190.0000 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 23225938.0710 - acc: 0.0000e+00 - val_loss: 23610040.0000 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 23564001.8518 - acc: 0.0000e+00 - val_loss: 24363266.0000 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22987909.1900 - acc: 0.0000e+00 - val_loss: 23857294.0000 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22176755.4029 - acc: 0.0000e+00 - val_loss: 24396514.0000 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22328316.2463 - acc: 0.0000e+00 - val_loss: 23267896.0000 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22326348.1086 - acc: 0.0000e+00 - val_loss: 23558630.0000 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 23038303.2380 - acc: 0.0000e+00 - val_loss: 23715768.0000 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 23058634.8518 - acc: 0.0000e+00 - val_loss: 22944088.0000 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21351712.0230 - acc: 0.0000e+00 - val_loss: 22908678.0000 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21924925.5324 - acc: 0.0000e+00 - val_loss: 23400196.0000 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22951319.1983 - acc: 0.0000e+00 - val_loss: 23046588.0000 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21547703.6785 - acc: 0.0000e+00 - val_loss: 22579414.0000 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21844733.1441 - acc: 0.0000e+00 - val_loss: 22505682.0000 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 20367763.4447 - acc: 0.0000e+00 - val_loss: 23131202.0000 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21446723.0063 - acc: 0.0000e+00 - val_loss: 23181454.0000 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 21192523.3695 - acc: 0.0000e+00 - val_loss: 22166252.0000 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22232304.3967 - acc: 0.0000e+00 - val_loss: 22619572.0000 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21282030.9040 - acc: 0.0000e+00 - val_loss: 22063888.0000 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21496681.1900 - acc: 0.0000e+00 - val_loss: 21773030.0000 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 20376725.0710 - acc: 0.0000e+00 - val_loss: 21705900.0000 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21672894.0251 - acc: 0.0000e+00 - val_loss: 22536572.0000 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 22479781.2317 - acc: 0.0000e+00 - val_loss: 22915616.0000 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 20987755.2735 - acc: 0.0000e+00 - val_loss: 21409764.0000 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21662322.6263 - acc: 0.0000e+00 - val_loss: 21490004.0000 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21600639.5741 - acc: 0.0000e+00 - val_loss: 21292920.0000 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 20532111.3779 - acc: 0.0000e+00 - val_loss: 21552136.0000 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 20827295.5052 - acc: 0.0000e+00 - val_loss: 21451110.0000 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 21204888.0251 - acc: 0.0000e+00 - val_loss: 21275324.0000 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 20099806.8518 - acc: 0.0000e+00 - val_loss: 21456174.0000 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 19505126.7662 - acc: 0.0000e+00 - val_loss: 20926612.0000 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 19452197.8372 - acc: 0.0000e+00 - val_loss: 22090072.0000 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 20196222.9635 - acc: 0.0000e+00 - val_loss: 21914134.0000 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 20226095.6973 - acc: 0.0000e+00 - val_loss: 20586412.0000 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18719230.0814 - acc: 0.0000e+00 - val_loss: 20550494.0000 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 19113985.0960 - acc: 0.0000e+00 - val_loss: 21171178.0000 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 20325206.7474 - acc: 0.0000e+00 - val_loss: 20431464.0000 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 19749753.6347 - acc: 0.0000e+00 - val_loss: 20319016.0000 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18094254.8852 - acc: 0.0000e+00 - val_loss: 20691474.0000 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 19641000.6347 - acc: 0.0000e+00 - val_loss: 20033730.0000 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18914209.2735 - acc: 0.0000e+00 - val_loss: 19991174.0000 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 19789697.1023 - acc: 0.0000e+00 - val_loss: 20295214.0000 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 19062945.2150 - acc: 0.0000e+00 - val_loss: 19745326.0000 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18719900.6910 - acc: 0.0000e+00 - val_loss: 19682446.0000 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18502760.1200 - acc: 0.0000e+00 - val_loss: 20081082.0000 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18621495.5616 - acc: 0.0000e+00 - val_loss: 20983808.0000 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18875467.0919 - acc: 0.0000e+00 - val_loss: 21828428.0000 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18772144.7015 - acc: 0.0000e+00 - val_loss: 19346794.0000 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18505800.7808 - acc: 0.0000e+00 - val_loss: 19040004.0000 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18625342.0271 - acc: 0.0000e+00 - val_loss: 19207334.0000 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18366835.1294 - acc: 0.0000e+00 - val_loss: 19652512.0000 - val_acc: 0.0000e+00\n",
      "Epoch 177/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18181201.9770 - acc: 0.0000e+00 - val_loss: 19177642.0000 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18114294.9645 - acc: 0.0000e+00 - val_loss: 19834522.0000 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 18959083.4781 - acc: 0.0000e+00 - val_loss: 18880402.0000 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 17902387.3539 - acc: 0.0000e+00 - val_loss: 18789966.0000 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 17940624.0418 - acc: 0.0000e+00 - val_loss: 19637828.0000 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 17172441.4259 - acc: 0.0000e+00 - val_loss: 19089728.0000 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18665416.3048 - acc: 0.0000e+00 - val_loss: 19258002.0000 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 17401299.4134 - acc: 0.0000e+00 - val_loss: 20185198.0000 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 18148861.9582 - acc: 0.0000e+00 - val_loss: 18342188.0000 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16826048.7537 - acc: 0.0000e+00 - val_loss: 18119520.0000 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 17299199.7015 - acc: 0.0000e+00 - val_loss: 19396308.0000 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 17773380.8727 - acc: 0.0000e+00 - val_loss: 18860948.0000 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 17742253.5532 - acc: 0.0000e+00 - val_loss: 18722992.0000 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16973938.0376 - acc: 0.0000e+00 - val_loss: 17976400.0000 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16989135.0856 - acc: 0.0000e+00 - val_loss: 18097342.0000 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16658977.2714 - acc: 0.0000e+00 - val_loss: 18987794.0000 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 17610221.3716 - acc: 0.0000e+00 - val_loss: 17606436.0000 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 16590996.3027 - acc: 0.0000e+00 - val_loss: 17486346.0000 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 17756684.8038 - acc: 0.0000e+00 - val_loss: 18538732.0000 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16516193.6952 - acc: 0.0000e+00 - val_loss: 17185014.0000 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 16917367.0376 - acc: 0.0000e+00 - val_loss: 17621054.0000 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16985894.2881 - acc: 0.0000e+00 - val_loss: 17016464.0000 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16566517.2109 - acc: 0.0000e+00 - val_loss: 17378742.0000 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 16806979.7171 - acc: 0.0000e+00 - val_loss: 17543666.0000 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16683196.1461 - acc: 0.0000e+00 - val_loss: 17372256.0000 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16874292.7891 - acc: 0.0000e+00 - val_loss: 16728280.0000 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 16104679.8121 - acc: 0.0000e+00 - val_loss: 16820188.0000 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 15508378.6044 - acc: 0.0000e+00 - val_loss: 16542522.0000 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15888218.7098 - acc: 0.0000e+00 - val_loss: 16582079.0000 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16857255.7599 - acc: 0.0000e+00 - val_loss: 17341160.0000 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15981945.0772 - acc: 0.0000e+00 - val_loss: 16719644.0000 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15861104.3716 - acc: 0.0000e+00 - val_loss: 16448706.0000 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16088905.8455 - acc: 0.0000e+00 - val_loss: 16712464.0000 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15598188.7683 - acc: 0.0000e+00 - val_loss: 16265368.0000 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15796212.9019 - acc: 0.0000e+00 - val_loss: 16162926.0000 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15705146.8518 - acc: 0.0000e+00 - val_loss: 16070411.0000 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15379750.1086 - acc: 0.0000e+00 - val_loss: 16831108.0000 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15373817.7724 - acc: 0.0000e+00 - val_loss: 16048876.0000 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15746740.2213 - acc: 0.0000e+00 - val_loss: 15900160.0000 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15277452.0355 - acc: 0.0000e+00 - val_loss: 15669301.0000 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16067129.0689 - acc: 0.0000e+00 - val_loss: 17144212.0000 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 16076239.4593 - acc: 0.0000e+00 - val_loss: 15844163.0000 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15338333.7599 - acc: 0.0000e+00 - val_loss: 15509658.0000 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14596955.6221 - acc: 0.0000e+00 - val_loss: 15992851.0000 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14901522.8977 - acc: 0.0000e+00 - val_loss: 15277679.0000 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14844118.4635 - acc: 0.0000e+00 - val_loss: 15554300.0000 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14561066.5908 - acc: 0.0000e+00 - val_loss: 15703435.0000 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14666733.5219 - acc: 0.0000e+00 - val_loss: 15135175.0000 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14678655.4906 - acc: 0.0000e+00 - val_loss: 15475862.0000 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15507973.3497 - acc: 0.0000e+00 - val_loss: 16915790.0000 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15374639.8977 - acc: 0.0000e+00 - val_loss: 14990072.0000 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14747062.3758 - acc: 0.0000e+00 - val_loss: 15183171.0000 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14876183.3633 - acc: 0.0000e+00 - val_loss: 14990217.0000 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15085061.8288 - acc: 0.0000e+00 - val_loss: 14813890.0000 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14306969.5470 - acc: 0.0000e+00 - val_loss: 15007364.0000 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14954071.1994 - acc: 0.0000e+00 - val_loss: 14893661.0000 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 15403299.0397 - acc: 0.0000e+00 - val_loss: 15101290.0000 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14596777.4050 - acc: 0.0000e+00 - val_loss: 15150917.0000 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14712158.3800 - acc: 0.0000e+00 - val_loss: 16313038.0000 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14519036.2338 - acc: 0.0000e+00 - val_loss: 14628462.0000 - val_acc: 0.0000e+00\n",
      "Epoch 237/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14184291.7641 - acc: 0.0000e+00 - val_loss: 14547541.0000 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14264033.3111 - acc: 0.0000e+00 - val_loss: 14698844.0000 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 14859308.1461 - acc: 0.0000e+00 - val_loss: 16328990.0000 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14517753.7432 - acc: 0.0000e+00 - val_loss: 14387744.0000 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14373316.5344 - acc: 0.0000e+00 - val_loss: 14450999.0000 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14002079.3883 - acc: 0.0000e+00 - val_loss: 14511947.0000 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14282350.1858 - acc: 0.0000e+00 - val_loss: 14470943.0000 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14573457.8330 - acc: 0.0000e+00 - val_loss: 14573350.0000 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14554165.4906 - acc: 0.0000e+00 - val_loss: 14089253.0000 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 13757450.3278 - acc: 0.0000e+00 - val_loss: 15263429.0000 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "478/478 [==============================] - 2s 4ms/step - loss: 13939620.4092 - acc: 0.0000e+00 - val_loss: 14691683.0000 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "478/478 [==============================] - 2s 5ms/step - loss: 13733510.1712 - acc: 0.0000e+00 - val_loss: 14221262.0000 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 14030541.8643 - acc: 0.0000e+00 - val_loss: 14795181.0000 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 14354699.4875 - acc: 0.0000e+00 - val_loss: 14063847.0000 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13967396.9812 - acc: 0.0000e+00 - val_loss: 14412271.0000 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13669829.8288 - acc: 0.0000e+00 - val_loss: 14111972.0000 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14305164.7453 - acc: 0.0000e+00 - val_loss: 15008461.0000 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13860150.1900 - acc: 0.0000e+00 - val_loss: 13938523.0000 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13823831.8894 - acc: 0.0000e+00 - val_loss: 13870441.0000 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13739791.9019 - acc: 0.0000e+00 - val_loss: 13805515.0000 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 14031818.2213 - acc: 0.0000e+00 - val_loss: 13969678.0000 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 14344306.0355 - acc: 0.0000e+00 - val_loss: 14647672.0000 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 13576086.8977 - acc: 0.0000e+00 - val_loss: 14702208.0000 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14199100.3612 - acc: 0.0000e+00 - val_loss: 13917809.0000 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 13823723.5010 - acc: 0.0000e+00 - val_loss: 13860745.0000 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13791949.1200 - acc: 0.0000e+00 - val_loss: 14161303.0000 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14051656.0376 - acc: 0.0000e+00 - val_loss: 14368297.0000 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 14492847.6576 - acc: 0.0000e+00 - val_loss: 13615188.0000 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 13572905.5553 - acc: 0.0000e+00 - val_loss: 14136815.0000 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 13958817.3779 - acc: 0.0000e+00 - val_loss: 13640592.0000 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 13874324.4499 - acc: 0.0000e+00 - val_loss: 14283580.0000 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 13278138.7839 - acc: 0.0000e+00 - val_loss: 13646934.0000 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13678850.7891 - acc: 0.0000e+00 - val_loss: 13523070.0000 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 14155689.5908 - acc: 0.0000e+00 - val_loss: 13478503.0000 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13418061.3800 - acc: 0.0000e+00 - val_loss: 13547951.0000 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13772820.1159 - acc: 0.0000e+00 - val_loss: 13621747.0000 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "478/478 [==============================] - 2s 4ms/step - loss: 13222042.1127 - acc: 0.0000e+00 - val_loss: 14190261.0000 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "478/478 [==============================] - 2s 5ms/step - loss: 14499850.8434 - acc: 0.0000e+00 - val_loss: 13442559.0000 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "478/478 [==============================] - 2s 5ms/step - loss: 13050635.9562 - acc: 0.0000e+00 - val_loss: 14498740.0000 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "478/478 [==============================] - 2s 4ms/step - loss: 13611428.0585 - acc: 0.0000e+00 - val_loss: 14138285.0000 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "478/478 [==============================] - 3s 5ms/step - loss: 13413489.8914 - acc: 0.0000e+00 - val_loss: 13323491.0000 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13941519.0981 - acc: 0.0000e+00 - val_loss: 13251666.0000 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "478/478 [==============================] - 2s 4ms/step - loss: 13325040.6879 - acc: 0.0000e+00 - val_loss: 13433162.0000 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "478/478 [==============================] - 2s 4ms/step - loss: 13415149.4990 - acc: 0.0000e+00 - val_loss: 13129030.0000 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "478/478 [==============================] - 2s 4ms/step - loss: 13259315.1962 - acc: 0.0000e+00 - val_loss: 13478574.0000 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 14181531.3194 - acc: 0.0000e+00 - val_loss: 13154136.0000 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 14577897.0438 - acc: 0.0000e+00 - val_loss: 13214256.0000 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 12227930.6075 - acc: 0.0000e+00 - val_loss: 13043691.0000 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13177065.5605 - acc: 0.0000e+00 - val_loss: 13043849.0000 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "478/478 [==============================] - 2s 4ms/step - loss: 13266455.0939 - acc: 0.0000e+00 - val_loss: 12974329.0000 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 13071239.3549 - acc: 0.0000e+00 - val_loss: 12958768.0000 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "478/478 [==============================] - 2s 4ms/step - loss: 13178202.1733 - acc: 0.0000e+00 - val_loss: 13068988.0000 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 12789206.7808 - acc: 0.0000e+00 - val_loss: 13120419.0000 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 13642889.7860 - acc: 0.0000e+00 - val_loss: 13128666.0000 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 13404372.8309 - acc: 0.0000e+00 - val_loss: 12929298.0000 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 12677227.7641 - acc: 0.0000e+00 - val_loss: 12834248.0000 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 13502550.3257 - acc: 0.0000e+00 - val_loss: 13788525.0000 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 13004123.1503 - acc: 0.0000e+00 - val_loss: 13046819.0000 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 13288325.1983 - acc: 0.0000e+00 - val_loss: 12771631.0000 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "478/478 [==============================] - 2s 3ms/step - loss: 13209438.1785 - acc: 0.0000e+00 - val_loss: 12952848.0000 - val_acc: 0.0000e+00\n",
      "Epoch 297/300\n",
      "478/478 [==============================] - 2s 4ms/step - loss: 12897169.1524 - acc: 0.0000e+00 - val_loss: 12711216.0000 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 14067235.4322 - acc: 0.0000e+00 - val_loss: 12777627.0000 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "478/478 [==============================] - 1s 3ms/step - loss: 13129363.5491 - acc: 0.0000e+00 - val_loss: 12638164.0000 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 13138024.1795 - acc: 0.0000e+00 - val_loss: 13440305.0000 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 20, epochs = 300,validation_split = 0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee76f2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.40381949977932\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))\n",
    "print(100-MAPE)\n",
    "import matplotlib.pyplot as plt\n",
    "# print(history.history.keys())\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
