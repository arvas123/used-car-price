{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "72bd75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a50b0f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic 22589.52806122449\n",
      "Manual 13709.165551661888\n",
      "Semi-Auto 21654.315873015872\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/vw.csv') #load data into pandas dataframe\n",
    "df.head() #display first 5 rows\n",
    "df.sample(n=5) #display 5 random rows\n",
    "df_non_numeric = df.select_dtypes(exclude=[np.number]) #Finding the coloumns with categorical data\n",
    "for col in df_non_numeric:\n",
    "    if col!='transmission': continue\n",
    "    prices = defaultdict(int)\n",
    "    num = defaultdict(int)\n",
    "    for idx, val in enumerate(df_non_numeric[col]):\n",
    "        prices[val]+=df.at[idx,'price']\n",
    "        num[val]+=1\n",
    "    for key in prices:\n",
    "        print(key, prices[key]/num[key])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a68dc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how = 'all', inplace = True) #removes rows which contain any blank cells\n",
    "df_numeric = df.select_dtypes(include=[np.number]) #select coloumns which contain numeric data\n",
    "for col in df_numeric:\n",
    "    average =  np.average(df_numeric[col])\n",
    "    standard_deviation = np.std(df_numeric[col])\n",
    "    max_value = average + 3*standard_deviation\n",
    "    min_value = average - 3*standard_deviation\n",
    "    for idx, row_val in enumerate(df_numeric[col]):\n",
    "        if min_value<row_val<max_value: #check if value is an outlier with average +- 3*s.d.\n",
    "            continue\n",
    "#             print(df.iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96ab820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding\n",
    "df_non_numeric = df.select_dtypes(exclude=[np.number]) #Finding the coloumns with categorical data\n",
    "\n",
    "label = LabelEncoder()\n",
    "for col in df_non_numeric:\n",
    "    #Find the unique categories i.e (Manual, Semi-Auto and Automatics)\n",
    "    s=set()\n",
    "    for val in df_non_numeric[col]:\n",
    "        s.add(val)\n",
    "    s=list(s)\n",
    "    int_data = label.fit_transform(s)\n",
    "    int_data = int_data.reshape(len(int_data), 1)\n",
    "    onehot_data = OneHotEncoder(sparse=False) \n",
    "    onehot_data = (onehot_data.fit_transform(int_data)) #Convert the categories into onehot data\n",
    "    df[col] = np.array([onehot_data[s.index(val)] for val in df[col]]) #Add these categories to the dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a24cd45f-e8a5-4070-adcc-25c18db4260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5176330103422336\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABNYElEQVR4nO29e5hU5Zno+3vr0tX3CzRISzcI2oiASTu0YkZDsrckMG4c3XsSZczZmqhxkjFzyHn2uA/ODJmZMLM1x7Mnm+yZJNtBI3riBMZMvEUxYmZCTLQDbDtyEWkEoRsbaaD63l1dl+/8sS6sqq4uqi/VN97f89RTq75a36pvra5eb713McagKIqiKCPFN9ELUBRFUaY2KkgURVGUUaGCRFEURRkVKkgURVGUUaGCRFEURRkVgYlewHhTWVlpLrvssolehqIoypRi7969Z4wxs9K9d9EJkssuu4w9e/ZM9DIURVGmFCJyfKj31LSlKIqijAoVJIqiKMqoUEGiKIqijAoVJIqiKMqoUEGiKIqijIqcCRIRuVJEGj2PThH5uojMEJHXRKTJfq7wzHlIRI6IyHsistozvlxE9tnvfUdExB4Picg2e7xBRC7L1fkoiqIo6cmZIDHGvGeMqTPG1AHLgV7gJ8AG4HVjTC3wuv0aEVkCrAOWAmuA74qI3z7c94D7gVr7scYevxcIG2OuAL4NfCtX56MoiqKkZ7xMWzcB7xtjjgO3Alvt8a3Abfb2rcCPjDERY8wx4AhwnYhUAaXGmDeNVfP+qZQ5zrGeBW5ytJXxYO/xMHc93sDe4+Hx+khFUZRJx3gJknXAP9nblxhjWgHs59n2+Fyg2TOnxR6ba2+njifNMcbEgA5gZuqHi8j9IrJHRPa0tbWNyQkBbN55mF1NZ9i88/CYHVNRFGWqkXNBIiJ5wO8D/3yhXdOMmQzjmeYkDxjzmDGm3hhTP2tW2gz/EbF+1SJW1layftWiMTumoijKVGM8SqT8HvC/jTEf2a8/EpEqY0yrbbY6bY+3ADWeedXAh/Z4dZpx75wWEQkAZcC53JzGYJbPr+Cpe1eM18cpiqJMSsbDtPWHnDdrAbwA3G1v3w087xlfZ0diLcByqv/GNn91icj1tv/jrpQ5zrE+B/zcaO9gRVGUcSWnGomIFAKfAf7IM/wIsF1E7gVOAJ8HMMYcEJHtwEEgBjxgjInbc74KPAkUAK/YD4DHgadF5AiWJrIul+ejKIqiDEYuth/w9fX1Rqv/KoqiDA8R2WuMqU/3nma2K4qiKKNCBYmiKIoyKlSQKIqiKKNCBYmiKIoyKlSQKIqiKKNCBYmiKIoyKlSQKIqiKKNCBYmiKIoyKlSQKIqiKKNCBYmiKIoyKlSQKIqiKKNCBYmiKIoyKlSQKIqiKKNCBYmiKIoyKlSQKIqiKKNCBYmiKIoyKlSQDJO9x8Pc9XgDe4+HJ3opiqIokwIVJMNk887D7Go6w+adhyd6KYqiKJOCnPZsn46sX7Uo6VlRFOViRwXJMFk+v4Kn7l0x0ctQFEWZNOTUtCUi5SLyrIgcEpF3ReQTIjJDRF4TkSb7ucKz/0MickRE3hOR1Z7x5SKyz37vOyIi9nhIRLbZ4w0iclkuz0dRFEUZTK59JJuBHcaYxcDHgXeBDcDrxpha4HX7NSKyBFgHLAXWAN8VEb99nO8B9wO19mONPX4vEDbGXAF8G/hWjs9HURRFSSFngkRESoGVwOMAxpgBY0w7cCuw1d5tK3CbvX0r8CNjTMQYcww4AlwnIlVAqTHmTWOMAZ5KmeMc61ngJkdbGQ+yjeDSSC9FUaYzudRIFgJtwA9E5G0R2SIiRcAlxphWAPt5tr3/XKDZM7/FHptrb6eOJ80xxsSADmBm6kJE5H4R2SMie9ra2sbq/LKO4NJIL0VRpjO5dLYHgN8B/sQY0yAim7HNWEOQTpMwGcYzzUkeMOYx4DGA+vr6Qe+PlGwjuDTSS1GU6UwuBUkL0GKMabBfP4slSD4SkSpjTKtttjrt2b/GM78a+NAer04z7p3TIiIBoAw4l4uTSUe2EVwa6aUoynQmZ6YtY8wpoFlErrSHbgIOAi8Ad9tjdwPP29svAOvsSKwFWE7139jmry4Rud72f9yVMsc51ueAn9t+FEVRFGWcyHUeyZ8APxSRPOAo8CUs4bVdRO4FTgCfBzDGHBCR7VjCJgY8YIyJ28f5KvAkUAC8Yj/AcuQ/LSJHsDSRdTk+H0VRFCUFudh+wNfX15s9e/aM6TH3Hg+zeedh1wey4dnfcqozwkM3X8WdK+bxTMMJHn31EA+uXsydK+aN6WcriqKMByKy1xhTn+49zWwfA5yoLIemth4AHn31EHeumMejrx4i3Bt1XyuKokwnVJCMkr3Hw3T2RamrKXc1ktb2Pk51Rrijvoa7Hm/gU4tm8dI7rdxRX3OBoymKokw9VJCMks07D9PY0sHK2kqWz7eqvbz2Xz4NwF2PN7Cr6QwVhUFiCcPB1s4JXKmiKEpuUEEyStavWkRnf4zOvih7j4ddYeK8B7BmWRU79rdqHomiKNMS7UcySpbPr6A0P0BjS8eYZK5rORVFUaYaqpGMAUNlrjtO+H0nOwj3RgEumJjoddxrEqOiKFMBFSRjwFCZ6yMxbWk5FUVRphoqSLLEyQW5o76Gg62d7o3eyR9ZPr9iUD6Jd3vH/tasPkfLqSiKMtVQQZIlTi7IljeOEUucT+L0mqFS80nSbauQUBRluqGCJEseXL04rUYCg81R6d5L3VYURZkuaImUMWLv8TCbXjwAImxcuyQpDFhRFGWqk6lEiob/jhFOYmJjc7s2sFIU5aJCTVtjxPpVi+jsi4KImrAURbmoUI1kFHiTB5fPr+C5r93Icw/cAJAxqVCTDhVFmU6oIBkFQ/Viv1CPdu3hrijKdEJNW6NgqOTBCyUVatKhoijTCY3aGgZOwqE3U92JzvImI2rElqIo0w1tbDVGpKudtX7VIjbvPExnX5TGlg46+6KUFgRVoCiKctGgPpJhsH7VIlbWVvLg6sWsrK10hciupjMgwsraShBx/R/qVFcU5WIgp4JERD4QkX0i0igie+yxGSLymog02c8Vnv0fEpEjIvKeiKz2jC+3j3NERL4jImKPh0Rkmz3eICKX5fJ8ls+vYP2qRUlmrfWrFlFXUw7GsH7VIjauXTJIyKhTXVGU6cx4aCT/zhhT57GtbQBeN8bUAq/brxGRJcA6YCmwBviuiPjtOd8D7gdq7ccae/xeIGyMuQL4NvCtXJ/MppcOsqvpDJteOghYwgVjaGzpYNOLB9yii46QcYSKoijKdCWnznYR+QCoN8ac8Yy9B3zaGNMqIlXAvxljrhSRhwCMMQ/b+70K/BXwAfCvxpjF9vgf2vP/yNnHGPOmiASAU8Ask+GkRupsd0qgHGjtJBo3+H0Q8vuYW1EIQNPpbmaV5BHuiXLfjQvYcPNVw/4MRVGUycpElkgxwM9EZK+I3G+PXWKMaQWwn2fb43OBZs/cFntsrr2dOp40xxgTAzqAmamLEJH7RWSPiOxpa2sb0YlseukgjS0dROOWjIonoDeaoOl0N0WhACtrKznXPUAsYdjyxrERfYaiKMpUJNdRWzcYYz4UkdnAayJyKMO+kmbMZBjPNCd5wJjHgMfA0kgyL3kIbCUnFPDhFyjOD9DdH2NuRaFbpPGRl99lyxvHuO/GBSP6CEVRlKlITgWJMeZD+/m0iPwEuA74SESqPKat0/buLUCNZ3o18KE9Xp1m3DunxTZtlQHncnEuG29ZmjZPxJs/Mm9mEQVBH68fOs1nls4ZUfiv5qMoijLVyJlpS0SKRKTE2QY+C+wHXgDutne7G3je3n4BWGdHYi3Acqr/xjZ/dYnI9Xa01l0pc5xjfQ74eSb/yGjwOtG9eCOzHn31EF2ROE2nu0ccqaWRXoqiTDVyqZFcAvzEjtQNAM8YY3aIyG5gu4jcC5wAPg9gjDkgItuBg0AMeMAYE7eP9VXgSaAAeMV+ADwOPC0iR7A0kXU5PJ+0ePuyt3b00xuJ4ff5WLOsalTH00gvRVGmCloiZZjsPR62Qn+NYeMtS91e7V98ooGuSBzBctKE/MJVl5ZpkytFUaYF2thqDNm88zCNze1u3ogz1hWxlCdHLEfiRptcKYpyUaCCZJisX7WIwqCVJ9kzEGfv8TCd/TFqZxVRO7uY6ooCCoN+qsvzqaspZ/2qRVoqRVGUaY0WbcySZxpO8PDL71JWGMTRO4pCASu/pLmdkpCfJ+9ZATAo6uq2f/gVjc3tvH2inSfvuU5NXYqiTCtUI8mSh19+l65IjJZwH73RBBWFQTauXeLml3RF4mz48Tvct3X34Kgrd5+YmroURZl2qCDJkjmlIcAqi1JXXcaWu69l+fwKNt6ylJKQZeo62tZNuDdKRWEwKepq4y1Lqasuc01diqIo0wkVJFnyyOc+zsraSv7y95dSWhAEzicPfmHFfAI+IW4g4BMeXL14sPlKxNVMHNR3oijKdEB9JFny3qku9p3soLW9j6a2HgB3u+HoWWIJg18gljA8+uohrpxT4goTJ9LL2X7q3vO+lF1NVj1LZ0xRFGWqoRpJljz66iHCvVFOdUbc0vCnOiMARBOWprFwVjEVhUHCvdEkX4jTs6SuuizJtKVl5hVFmQ6oIMmSO+prCPiEm66yihW/duAU/VErd6Qw6KckFGDppaVEoglCfh9H27q57R9+5ZqtSvMDbgKjw1BlVxRFUaYSmtmeJXc93sCupjMEfEIskf6apXuvojDI/JlFNDa3U1EYdJ30iqIoUwnNbB8D1q9aREVhkFjCEPAlV68P+oWSkJ/fvfx8K5SQPRbujYIxaU1eiqIo0wEVJFmyfH4FW+6+lrqacuaU5RP0CQLUVBSwtKqUrkicfSc73P39Ph9fWDGfkpCfsz0DVBaHqKsuY0lVKdd882c803Bi4k5GURRlDFFBMgyWz6+gND9AS7iPaMJggO5IzM0TqSwOueVTeqNxfthwgq5InOZwH02nuyktCLJtTzPh3ijfeH6/hv0qijItUEGSJU7Ox5Kq0qS2jFfPLeO+rbs50zNA0+lu5lYUUFddRu3sYuKJhLtfyG+Vln9w9WLXl6JmLkVRpgMqSLJkw7O/ZVfTGR7/1bGkXr5vHDlDuDfKh+19ABTl+XnuazdSVZZPb/S8IInEE+zY38qdK+ax7Y8+oWG/iqJMGzQhMUtOtvcDEI0nR2U5QW+XlhewsLLI9YHcUW91DV5SVcoPG44zp6zAFRxO2K+iKMp0QAVJlsRsM5VfIBTwETeAsTQNgJ5IjLdPhGk4dpZIzPCDXx+jMC/AmmVV7PvrNRO4ckVRlNyipq0sGbA1kbiBUNBPJJZgIH7edBXujdIViROJWftFY4Zwb5RHXz00IetVFEUZL1SQZEntrCL3+cHVi6koDJLnP3/5gn5xnfA+gcqSPEpCfj61aBZLNr7Cko07NORXUZRpiQqSLOmLWdrH0bM9/M1LB6gsDvF7V8/BL+D3Wb6TvIB1ORMGTncN0BdN8LMDH9EbTdAbjat2oijKtCTngkRE/CLytoi8ZL+eISKviUiT/Vzh2fchETkiIu+JyGrP+HIR2We/9x0REXs8JCLb7PEGEbksV+fRakdlxRPQG03QdLqbXxxuI26sMYBoPOHmkYBVCTieSOATK/z3jvoaLRuvKMq0Yzw0kvXAu57XG4DXjTG1wOv2a0RkCbAOWAqsAb4rIs5d+XvA/UCt/XC81/cCYWPMFcC3gW/l6iS+/MmF+MWqnVUY9FE7u5g76mvwe5JKEgYWXVJMXU051RUFlIT8zJtZRMJAYcjPW8fOsavpDF98oiGpoKOiKMpUJqeCRESqgf8AbPEM3wpstbe3Ard5xn9kjIkYY44BR4DrRKQKKDXGvGmsCpNPpcxxjvUscJOjrYw1G26+ik23XU3MNmEdOd3N93cdtZzvfh9fWbmQisIgPZEYjc3ttIT7uHx2CTcttqoFh3ujfHC2G7Da8jY2t7N55+FBza2eaTihJVQURZlS5Foj+R/AfwUSnrFLjDGtAPbzbHt8LtDs2a/FHptrb6eOJ80xxsSADmAmKYjI/SKyR0T2tLW1jehE9h4P843n99MVidHeF0tKSowmEhxs7STcG3WbXmEtim17rFMK+IT23pj7ll+sQpBOcysny93pe6L+FEVRpgo5EyQishY4bYzZm+2UNGMmw3imOckDxjxmjKk3xtTPmjUry+Uks3nnYbcLYnlBIOmDLy0vcJtU1VWXAVBeaPUfcSK8vnnrMm6ruxSAoE/YdNvVLJ9fMai5lbP/g6sXj2idiqIo400uExJvAH5fRG4G8oFSEfn/gI9EpMoY02qbrU7b+7cANZ751cCH9nh1mnHvnBYRCQBlwLlcnIxzo1+zrIrte5rBGK5fOJNte5r5409fMShb/ZmGE9y3dTcPrl7M29/4LHuPh9m++wR1NeVsXLsEsHqcrF+1KGnenSvmceeKebk4BUVRlJyQdWMrEZkP1BpjdopIARAwxnRlOffTwJ8aY9aKyKPAWWPMIyKyAZhhjPmvIrIUeAa4DrgUyxFfa4yJi8hu4E+ABuBl4H8aY14WkQeAq40xXxGRdcB/MsbcnmktI21s5eA0uALcHiN11WWUFgRdYbN552H2fBCmNxqnMOin/rIKOvtjbt/2lbWVAOxqOsPK2kotl6IoyqQnU2OrrDQSEfkyVtTUDOByLK3g+8BNI1jPI8B2EbkXOAF8HsAYc0BEtgMHgRjwgDEmbs/5KvAkUAC8Yj8AHgeeFpEjWJrIuhGsZ1isX7WI1o5+TnX0cUd9DQdbO+nsj7nCBSwBEbLDueKJBLuazlBXXWaZvUQG9W1XFEWZymSlkYhII5am0GCMucYe22eMuTq3yxt7RqqRPNNwgkdfPcTVc8tcoVESCvDQzVexffcJEOH2+hp+8KtjnAz3Ek0YonFD0C/kB3w8dPOSrExWe4+H2bzzMOtXLRp2S97RzFUURcnEqDUSIGKMGXAia21/xEXV7P3hlw/SFYknaR5dkRh/8dw+K08k6OPhl9+lKxJLmheNG6LxuFtC/kI4UVzAsE1eo5mrKIoyUrKN2vqFiPwZUCAinwH+GXgxd8uafMwpKwAsv4hfrNpaYCUhgpXt3hWJURLyE7JrcIX8PqorCigM+mjt6M8qAXHNsioqCoOsWVY1KMfkQqRGgCmKoowH2QqSDUAbsA/4IyyH91/kalGTkZsWz0awEgvjxtI0/CnBxyG/MBA3blVgv0/o6B1wS6ps3nmYr//obS7b8FO+/qO3AQYJix37Wwn3Rtmxv3VQjsmFcCLH1KylKMp4kq0gKQCeMMZ83hjzOeAJe+yiYdue5kG2PG+Pq4BPyAtY5eWd4d5onK5InJKQn7qactavWsRzjVbksvOcKiy8WoWzvWZZ1SDNZLjaiqIoSq7IVpC8TrLgKAB2jv1yJi931NcMyn4sCfldrWTtx6p46OarCAV8+IBZJXnuPk/es4LnHriB5fMr3KRE5znVHOXVKpztHftbB2kmw9VWFEVRckW2zvZ8Y0y388IY0y0ihTla06RkyxtHMViSV8TSRi6fVcz7bd10ReI81/ghr+w7xbwZBTS19VCeHyQWN26GupN8+D/WXcP/WHeNe9xs2u46QiZd2LD6QxRFmWiy1Uh6ROR3nBcishzoy82SJid2OxISQGGeJX8Pf9TNQOy8fSsST3Ai3EdFYRBE3JpZm146mJX2kGqucl4DrpaSbkxRFGUiyVYj+TrwzyLilCapAu7IyYomKT7OV550Qnx7o/FB+/nFcsjH4glKQn57u4va2cV09kV5puGEW2Jl4y1LXeGweedhOvuiNLZ0AJaQSBfOqyG+iqJMNrISJMaY3SKyGLgSq1DiIWNMNKcrm2TkB330RhMX3O+uT1zGP/7yKF2ROLWziwl0Rwj3Ruk700MsYTh+zqruC5ZQ8AqMupryJH9J6vPe42FaO/opCflZs6wqR2eqKIoyPDIKEhH598aYn4vIf0p5q1ZEMMb8Sw7XNqmYWRyiN5zemidY2Zl11WVseeOYG811tK2bL39yIT9sOO5Gbz24erGrkaQTGF5TVar/ZPPOwzSdtlxV2SY4Koqi5JoLaSSfAn4O3JLmPQNcNIKkOzK0AuZ4SRyzlEPcwP/adZQ8O0FxTlkBd66Yx5VzSpL8JV6BkanMyfpVi+jsjyUJodGgJVUURRkLMgoSY8xfiogPeMUYs32c1jQpCffGLrxTGgyWEx6gKM/qHJzJz5HpveXzK3jugRtGtI50qL9FUZSx4II+EmNMQkS+BlzUgsTvg/iFXST47dBgx9xVEPRRXVFIUZ6f26+dx12PN7j+jXRaxXiG9WoIsaIoY0G21X83YoX7bgPcXrLGmJw0kcolI63+u2DDT0dcpbK6PJ/KknwAtyfJV1YuZMPNV43wiLlDzV2KoqQjU/XfbPNI7gH+GPgFsMfzuGgYTanjlvZ+S4B4hPaWN46Nek25QDPmFUUZLtkKkiXAPwC/BRqB/wkszdGaJiWjaW4f9EHt7GJuv3YeNRUFCJYJ7JmGE2O1vDFDKwgrijJcsr0/bgWuAr6DJUSusscuGmQUkiSagKbT3Xzv347QHO7DJxCJGx5++eCQcyaqKKNWEFYUZbhkm9l+pTHm457X/yoiv83FgiYr2TjaL0RLuI+VtZUcPdNDS7jP7XGSDo2oUhRlqpCtIHlbRK43xrwFICIrgF/lblnTkzy/j6fuXZHk0B4KjahSFGWqkG3U1rtY5VEco/484F2s8lPGGPOxnK1wjBlp1NbCDT9lOEpJYZqSKnXVZVbpYE+dreGiUVWKokwEYxG1tQZYgJXp/il7+2ZgLemz3hGRfBH5jYj8VkQOiMhf2+MzROQ1EWmynys8cx4SkSMi8p6IrPaMLxeRffZ73xG7ebyIhERkmz3eICKXZXk+w2a4lq10dbkaWzpobG6nsaVjxFFRGlWlKMpkIytBYow5nukxxLQI8O9t30odsEZErsdq2/u6MaYWq2HWBgARWQKsw4oGWwN8V0T89rG+B9wP1NqPNfb4vUDYGHMF8G3gW8M5+VziS+2ChdXsqq6mnLrqMtavWjQih7pGVSmKMtkYTVRrRoyF0wwraD8McCvnI762ArfZ27cCPzLGRIwxx4AjwHUiUgWUGmPeNJYd7qmUOc6xngVucrSViSaRxmJ4tmuAd1s76bHL0DvaxX1bd2ctTLKNqtJWvIqijBc5EyQAIuIXkUbgNPCaMaYBuMQY0wpgP8+2d58LNHumt9hjc+3t1PGkOcaYGNABzEyzjvtFZI+I7Glraxujsxs+CSASS9DU1sOGZ3/LkqpSwOpfMtamKjWBKYoyXmQbtTUijDFxoE5EyoGfiMiyDLun0yRMhvFMc1LX8RjwGFjO9kxrHi9OtvezbY8lNwM+GXNTlUZ9KYoyXuRUkDgYY9pF5N+wfBsfiUiVMabVNludtndrAWo806qBD+3x6jTj3jktIhIAyoApUf+rNxqnLxon5Be+dMMCNxLrvVNdPPrqIe6or+GtY+fAGG6/dh479rdmHamlkV2KoownORMkIjILiNpCpABYheUMfwG4G3jEfn7envIC8IyI/B1wKZZT/TfGmLiIdNmO+gbgLqzsejzHehP4HPBzk0088yTBYFUKfv3QaZpOd9Pa0c8Zu6PiljeOEbMdLd6uitkkJ2oyo6Io40kuNZIqYKsdeeUDthtjXhKRN4HtInIvVl7K5wGMMQdEZDtwEIgBD9imMYCvAk8CBcAr9gPgceBpETmCpYmsy+H55IS1H6vi9Xc/AuD9tm4uLS8gFk9w01WX8LMDpwDhjvoaDrZ2Zm2mWrOsin0nO7Qdr6Io40LOBIkx5h3gmjTjZ4Gbhpjzt8DfphnfAwzyrxhj+rEF0VTlp++04vMJPrEivZwyKud6BtxclLeOnuW5r92Y9TF37G8l3BvVdryKoowLOY3aUi5MNGGIxBIkDAT9Qu3sYtYsq+LYmZ7zO6WJaM4U3qu5JoqijCfj4mxXsiMaN5zpjvCDXx2jOdznjl82s5C9x8Nseumg63x/+OV36YrEeOPIGS6fVcwjf/AxdawrijIhqCCZZIR7o0Si8aSxF377IS+90+o6399vs4QIWOawptPdbN552HWsq7NdUZTxRE1bE4wAxXlWJZiVtZWsrK1kbkUhYDW/AktYxDyp8mWFQQqDPvw+a/7skjw6+6KumSsb09ZwMt81S15RlEyoRjLBGM67QBqOnSWRsPwmYIUGe3EqCkei8aSikN39MRq7OvjiEw08eY+lgXT2Rdnw43c8H2Qoyg+yce0SAO7bujvrkOLRajhjndeieTKKMrlQQTLBCFBWmEdXpI9ILHMKjCM82roHCPmFiC1p+mPWeFck7pZEaWzpSHsM5/1wb5SKwmBWDvnRZsmPtalNTXeKMrlQ09YEY4CPOvsJ+X0EUv4amf44eQEfddVllIQCJIxlBqudXcySqlLePhFmdkmeO78w6Ke6PJ+SUIA1y6pc09eWu68FuKDZyikUmc2+6RjrKDKNSlOUyYVqJJOAaNyQpkRYxh4oc0rzaWzpwC8QCviIxBIU5fl56s0P6I0m6IpYDvuQX5hbUcCpjn66IjF27G/lyjkl7nE2vXiAxpYO3j4R5sl7hq4qvPd4eFjmMO+8sTZDeQWboigTj2okU5SmNivPJG4gajeUf7+th0gsWfxEE4am0910RWIEfMKaZVXJlYFtB01XJM6mlw4O6VjfvPPwsMxh3nlahVhRpjeqkUxBfCRrK6UFAbr7425IsJdLywuoLMrj8Edd9EYTbN99go23LAXO+zy++ESDpcEYM6T/wesnGY5moVWIFWX6oxrJJCWY4S8TDPgoCfmZXZIHQGdfLCk8GCyfSWHQT0HAx8ZblrohxcfP9XL793/Nu62dVoIj8OQ9K6irKQdgRlEeAbu94zXf/BnPNJwAhm6o5WgwzzScSHp2NJpsG3GNFg1RVpSJQzWSSUqalu8ukViCSMwqRQ/puzHGjfV+U1sPm3cepsjOVXF8HG3dA7R1D/DFJxq4fHYJGENjSwf7P+wkljCuVvLoq4cy1utyNJh9JzsI90bdZxhfP4pGcinKxKEayRQmnskb72HNsio23rKUisLgoPe6InEam9tBhJW1ldx34wIqCoPcVncpFYVBHly9+ILHrigMckd9DStrK3lw9eJhR1SNhR9FI7kUZeJQjWQS4ZfBSYjDpTjkpzuSXGLlz36yj1kleQT84raUNEB5YYBZRSE6+mO809xOKOBjV9MZbqu7lOsWzOQXh9s4cbaHux5vOO/r+NHbtLb38eVPLmTDzVe5lYYPtna6msCVc0rY9OIBEGHj2iVJWkY67WMs/CjL51ewftUiTVRUlAlABckkYrRCBBgkRBzaugYGjbX3xvjY3HKOHjlDAuizI76ea/yQXxxuI9wb5fu7jibNabGLSW554xgbbr7KvfmvWVblCpzNOw+7CZHeGmDO61QT1FiF86p5S1EmBhUkFymFQT9zy/NZv2oRR8/00BLuQ7A0FUcj+cbz+4klTFLI79EzPbS293HfjQuA80Lgrscb3Jv4+lWL6OyLggzuRZ/LKC6NEFOUiUEFyTSnJOR3kxODPiHo97HokmIaWzpYOrfM3c8vcMMVlew72cF1C2Zy5ZwSls0to6ffEgibXjrI7fU1LKwsYu3VVfyw4Tg/3ddKfyzO2e4BygoCFAZ9tHb0896pLkoLgmlNTI7gcaKs1iyrYsf+Vvc5dc5wHPGaqKgoE4NMoRbnY0J9fb3Zs2fPsOddtuGnOVhN7gn5fUQ8XvmSUCAp32RlbaWrSTgEfMKyS0tpbOmgojDoRmF5hVImnDkrayuHvLE7Goyzb8AnxBJm0Bxnv0zHUhQl94jIXmNMfbr3NGprmhNJCe3qjyYLkfWrFlE7u5hQwIedPmLlpIhQV1NOUZ6fwqCf2tnF+J269lhfnFDAR3nheaU25BdKQgE+tWgWhUE/ez445+ahQHKuhxNl9eDqxVQUBgeZ0ByGisaarHkjk3VdipJLciZIRKRGRP5VRN4VkQMist4enyEir4lIk/1c4ZnzkIgcEZH3RGS1Z3y5iOyz3/uOiFXXQ0RCIrLNHm8QkctydT5TCc/9fhDe/JR9Jy2H+JduWOC2+wVLI9m4dgml+QFa2vvpjcapKsunq++8ELp8djGRWIKPzS3nx1/9XVbWVnJVVSldkRi/ONxGr13q/tFXD7lzvGG+jhnqzhXz2HL3tW4RyaFMYanjk7X0ymRdl6Lkklz6SGLAfzHG/G8RKQH2ishrwBeB140xj4jIBmAD8H+LyBJgHbAUuBTYKSKLjDFx4HvA/cBbwMvAGuAV4F4gbIy5QkTWAd8C7sjhOU0JqsoLADgZ7nNLQYb8wuzSfE6G+9zyKuHeKLd//9eEPGWHQwEff3nLUjectrW9j1OdEZZUlXK0rZuW9n4AivL8rqbg9Xts3nmYNcuq+MGvjnGqoy8pD2UoZ/hIfBuT1bE+WdelKLlk3HwkIvI88Pf249PGmFYRqQL+zRhzpYg8BGCMedje/1Xgr4APgH81xiy2x//Qnv9Hzj7GmDdFJACcAmaZDCd1MfhIhspHSfWXODjRWgDVFQVUFofAGDbestT9he34MkpCfi6fVcxGW9h4hYfjLAdcB7l3O115FacPvXO8ycBkXZeiTCSZfCTjErVlm5yuARqAS4wxrQC2MJlt7zYXS+NwaLHHovZ26rgzp9k+VkxEOoCZQJL3WETux9JomDdv6HIf04Wh8lHSCRFILmD/YXufmyuy6cUDboHHNcuqePTVQ4R7o5QWBN2ba2qJFAevA3+o3I7NOw9bWfUMzjeZSCbruhRlspJzQSIixcCPga8bYzpFhjTgp3vDZBjPNCd5wJjHgMfA0kgutOaLCQHy/EI0bkiQXLerZyCeZLaqLMojEk3Q2tHPMw0n3LDdzr4oPQNx5s8oTDLprFlWxfY9zdRVl6U19axftYjO/hgYk/T+RLfSHWpdiqKkJ6dRWyISxBIiPzTG/Is9/JFt0sJ+Pm2PtwA1nunVwIf2eHWa8aQ5tmmrDDg39mcyfTFAxBYiqbT3DXDNN3/GIy+/y31bd9PU1mMVgjzdzcMvH2RX0xl27G+ltCBI0+luSgusWl6OENixv5XG5nZ6IjHu27qbR15+d1Bl4I1rl1h5Ki8ecMcdLWfTSwcvGAGViyip5fMreO6BG3juazfmRJBpZJcy3chl1JYAjwPvGmP+zvPWC8Dd9vbdwPOe8XV2JNYCoBb4jW0G6xKR6+1j3pUyxznW54CfZ/KPKIMJ+oWSkB+/55vgbLd1DRDujbLljWOEe6NuN0aAOWUFrKytdDWS2tnFdPZF2fTSQTdqyQndPdUZcY+TGtHkmJEaWzrccWcexlwwAmqkUVITeTPXyC5lupFL09YNwH8G9olIoz32Z8AjwHYRuRc4AXwewBhzQES2AwexIr4esCO2AL4KPAkUYEVrvWKPPw48LSJHsDSRdTk8n2mHAJeUhGhp76e6PJ+egTjFoQDNto8ELMf9nLJ8OnoH6IrEKfQL82YUU5TnT/KbVBQGabKd8XU15W4nxvWrFvHeqS4effUQd9TX8NbRs3T2x9h7POxGhqWakdJFgTl1vFI1hJFGSU1kXS6N7FKmG5rZniVTKWprOKRGeHkjuABqKgpoDvdREgoAhq5IfFB2vFNGfssbx4glDHU15Rw/20O4N0pddVlSuRQnU70waGlBX1gxn7eOnk1bKdjBm90+VhV+J9oPoyhTDc1sV4YkNcIr9WdFe++AKzgCts3Ln/KtmT+jkLeOnnWz0zHG1VIQcc04e4+H6eyLUhIK0BuN0xWJs+WNYzS2dNDY3G6Vnk/D+lWLqKspH2Q6y8SFTFfj1blRUS4GVJAoGbnpqkuIJyxXvBPe29kXc784PoHGlg7eb+uhrrqMLXdfy8ZblrrlTzCWhrJ+1SI2vXiAxpYO4okENRUFlIT83HfjAkpCVvfGwx91c9vfvzHo5r98fgWl+QGrNL0xWTWwUj+EoowfKkgUl3Sx1M81fkhvSt9fv1/cKK+EscxjXZEYPQNxvvjEb9jw7G/PR221dFCab7niDn/UDUBvNMHZ7ghzygp46+hZvrBiPn6xWgN7ne5enE6M1y+cmdW5eLWYCznUp2IU1VRcszJ9UUGiuGTrLYum2MOclx+c6aErEqOprYcvPtHAkqpSKgqDLKkq5b6tu90e82AJk6bT3TS2dLBtT7N7jJKQn/WrFiXdKPceD7tO/W17mtnVdIb7tu52b6LpbqpeLeZCWslU1F6m4pqV6Yv2I1FGhU/OJzHGPNmMXZE42/Y0uzd/J3zYERiFQR9zKwopyvNz+7Xz2L6nOakkibdRFuD6XB5cvdgVKk7W+VARWNlGR03FKKqpuGZl+qKCRBkzDDCrJA8MnOsZ4FOLZnGuZ4AlVaVs29PMpxbN4pX9rQzEDDOLQzzyBx9znd13rkguXbNmWRX7TnawZlkVV84pAXAjrK6cU5JUy2skxSBTo7ac/aZKNJc28VImE2raUkZFIsUedrbbSmKMG/jF4TaeuncFB1s7CfdG+cXhNiIxgwGaw31JZplU89SO/a2Ee6Ps2N86KMLqQq/TkXr8oUxD2ZiM1D+hKMmoRqIMid8HQ9R5HIRj4vKLELWlS28kzjMNJ1xNYc2yKn7wxlFOtvdTnB/g7RNhnmk4wZ0r5iUVf9xy97VjbrpJNX8NdfxsPncikxkVZTKiCYlZMl0TEsea4pCfvoF4Un5KyO+jtCBAfzTBF1bM42BrJw1HzxLx7OSd5yQ4/rDhBHNKQzzyuY8D1g18SVUpP2w4zpyygiTTGAxtlnqm4QQPv3zQneMca6Tmq2zMX1PFRKYo2aIJicq40R2JD0pyjMQTtHUP0BWJ8f1dR9nVdMbVWtLNC/dG+cdfHnUjwDbvPOwmIlrjVuHIbM1Sj756iK5InDPdEZbPr0i731DmqqEiwi5kShtuVJWay5SpjAqSLMnL1L9WGTaOHHH6xDv93h18IoT8PgqDPtYsqwJbc55RnIdPLC1nzbKqpGMOlTvi9IV3ujWm6wM/lHC5b+vuEYXZDtVrfiimQzivCsOLFxUkWfJP93+C2llFE72MKUU2Xy5HoMQNPHnPdRQGrVnRhKEw5Kc3mrBCg4Ha2cX0D1i95SPx8+Nejp/tGZQ7cuWcEq6eW+ZGf6XTKIYSLk7Y8XB9Nd6oqmxursMVPJOR6SAMlZGhzvYs2bzzME1tPRO9jCmDDwb1OEktCOmlJN/PF59ooDg/SG80QmHQz4OrF7NjfyudfVEaWzqoKAzSFYm5jv2T4V6u+ebPeHD1Yu5cMY9NLx0k3BulMOinsy/KMw0n2L6nmfdPd9EVsZIhnVItiHB7fY3bHjhdOK3X8T5SP0e2jvnpEM6ruS0XL+psz5K9x8Pc/v1fD9nGVsmMYxhMbW3ptMBMvawCFAT9/MXaJQBuGfqDrZ20dvTTdLrbTXD0CyysLOJkex+90QSFQT+90XhSAqTTax6s2mDOWFckTl11Gc997cYxd5CnOvnV6a5MZdTZPkaEAv6JXsKUpSDoSxIWhvPCI13fZINVe+vRVw+x3c6Mf+vYOZ66dwWP/MHHWFlbyZc/uZCAT4gb7O6NCSoKg8wtzwcsIVIS8lNXXcbls0tobOngTM8AfoHqigLmlBXYH2x98khMM5n8AqlO/gvtryhTFTVtZcmGH7+TVCtKGUxB0EdfNH3iSW80gd8HARFmlebzYXvfoGRGESgI+AgF/bT3Rgn4hcriED39VtXh9093Weaq3SdAhHkzi1g2t4zDp7rojVp9Uqyw4eNUVxRQWRxye5zsPR5m04sH2Heyg7iBUx39fPPWZa5pCwabZpw56XqlONpLZ3+MxuZ2wDJdPdNwgkdfPcSDqxe75VwcJz9oDooyPVFBkiXvn+6e6CVMeoYSIg7xBMQxtIT7WFlbyZ4PzrlhwPG4IWEsgeNUG/YBTae7qasppzDooysS589+ss893vunu+mKxKirKacnEuNkuI//teuoreEMsHndNUmmqtKCoGvqiiUM2/c0s3HtErcLo9dfAnYbYNsM5tT1cnAEQl11WZKT3KkD9uirh3j7G58dVPpF/QjKRJHL3CYVJFmSZYK3kiW/bDpDcShAb9TqtCjg+jYcInFD7exiNq5dwp3/+NagY8QTCepqytm4dsmg6sJzygrcm31nf4zS/IDbX/7wR93WvsYkZdQ7/VYcgbF+1SI6+6L0DMTp7I/xTMMJV9gM5YhPp4VA8j+xaiLKRJBLbVh9JMq44BcrfNfprmggqV2vwcoRSU3XOXbGipRLeOxgK2srCfiE3miC0vwAy+dX8ODqxYQCPgSoKAxwqqOfJVWlrKytBGPY1XSGR189BCL0RuMEfML1C2fS2tFPScjPHfU1g8Jvl8+v4Lmv3UhVWT6Nze08+uoh14eSGkLs+D6unFOSVhPRBEVloslliLlqJMq4EDdQlOfPWLvrZLgPg/XrRuyIq1jCcOdjb7kmsJBf6OyLEksYCoM+N8x3x/5WMJZACvdaAuqxXx7lb267mu27T1AS8hPujTJ/htUO2FveHmDbnmbuqK/hvq273XBiB2+tsB37W1mzrIq7Hm9wx9P5SlIZrklLfSnKWJPLEPOcaSQi8oSInBaR/Z6xGSLymog02c8VnvceEpEjIvKeiKz2jC8XkX32e98RsUJsRCQkItvs8QYRuSxX56KMDY6/YSgcnSNBci/5iEf6zJtZRM+AY8ISGls6XE0hkiKlEga+8fx+Gls6mFNWQEVhkNuvnedmut9RX2NpSWKVZfn+rqOEe6M8/PLBtOu7ck4JT927gu27T7Cr6QybXjxw/oZvLDOcU4gSkrUKrwaTqm2k0z6mQ4KicvGQS9PWk8CalLENwOvGmFrgdfs1IrIEWAcsted8V0ScWNvvAfcDtfbDOea9QNgYcwXwbeBbOTsTZUwIZllmxi/p9/UJfOmGBRTlWV+NueX5bm947+631V3qZsjHEoaQXygKBdyy9E6J+oOtnVSV5RM3EPCdP0B5YV7S52568YArOAA3XBgRqyxLdRmIcKqjj66IFbIM2Zeqd157uz5mU89rNKjpTBlLciZIjDG7gHMpw7cCW+3trcBtnvEfGWMixphjwBHgOhGpAkqNMW8aK3PyqZQ5zrGeBW5ytJWJRstypSe1RS+k7xPvmMFSSRj485/s42R7H4VBP23dEX7ZdIa/fGF/Uo7KnNJ8QsHz82MJw8a1S6irKae1o5/W9j7qaspZv2oRa5ZVURLyM6Moz/1nmFmULEi8ggPg9voaS7upr+G1A6dobOmgsbnd1XoeXL2YvcfDrv8lXU0wr7axftUi19yWTSHJdGTaN917Ws5EGUvG20dyiTGmFcAY0yois+3xuYA3LKfFHova26njzpxm+1gxEekAZgJnSEFE7sfSapg3b17q22OOZr9nz1CXqr0vlnbcAG3dAwDY7o1BAur7u44mvb7l45cCVh0uxyeysraS5fMr2PDjd+iKxN0SKhWFQTbesjRp/sa1S9j00kF6+qN88ls/58P2PuLGar716/fPuvsV5fn5kl3W5Qe/OkaTHTK+Y39rUlfHVFv18vkVbLn72qSuj5C9n+SZhhN84/n9xBLGjVBLDWNOPc6FfDZaBl8ZDpPF2Z7uh6nJMJ5pzuBBYx4DHgOrRMpIFqhMbnwkZ8t7eemdVvZ8cI5wbxSfwOWVRe4N9IOz5+un1VWXcfu1Vs0up388WDdijEmqtRbwWWatJVWn2PLGMeaU5dPY0sH+D60beknI0ogcjeS+rbsJ90bp7I9ZlYztJMf3TnUNWUYlWwf9o68eIpYwlnnOjlCDzELjQo5XdfYrw2G8BclHIlJlayNVwGl7vAWo8exXDXxoj1enGffOaRGRAFDGYFPamDG7JMTprkiuDq948NbIguRaXEGfDOplAsl5PqGAj1nFeYgIzeE+YglDS3u/tZ8BRNjw43c4ca4nSZvpicT46xcOuE57x+yzq+kMdTXl1FWXcbZngLPdEeZWFAKw4ear2HDzVW7J+XBvlIBP+MKK+Rxs7WT9qkVuFWGAdz/scBt6bd55mH0nOyyNyO6vkm2PeS8Prl7M37x0ALBCmksLgsMSGunQxEllOIx3HskLwN329t3A857xdXYk1gIsp/pvbDNYl4hcb/s/7kqZ4xzrc8DPTQ4rUH591SL3V6aSW1JNg96X6YRIKrF4gj/+d7V0R9Kbx0519NF0uptILPlYTW09rhARrHDf1vY+SkIBrl8wg9KCIF/99BWEgn63sZbjfwC4o976LRRLGLcu2PL5FaxftcjtuxKJW9qK46N5cPViSkJ+amcXD7ppe/0Y3u1nGk5wzTd/5kaH3bliHiE7mXPbnuYxcdLn2tmfCQ0EmHrkTCMRkX8CPg1UikgL8JfAI8B2EbkXOAF8HsAYc0BEtgMHgRjwgDHGifH8KlYEWAHwiv0AeBx4WkSOYGki63J1LmDZubsicQqDPreEhzJ2+ACfT4hlISgcgn5J68CPm/OlSpyS885nzK0oID/gI78/SlvXQMrxwEmOF6y/uWPOcnJOHHOPX+BoWzdffOI3bmLlvpOe8GbPb5rl8yvID1jfGx/w5D3nb9DL51cMSl50SKcVrF+1yNV8Hn31kDt3qIz6qYia1aYeWkY+S5yS4Pl5VkHB1BtYwAcxlS9jylCCIuT3cdWlpZzpjtDWGWEgnnC1Fr9HcBiszpbRuMFgVfw91x3J+ENgdkkep7sGuK3uUuaU5vOPvzzKzOIQeQEfLeG+tHNKQn4un13C9Qtm8NSbHwDCX6xdwpVzSlx/C1h5NAUBHwG/j4duvsoVAnuPh9nw43c41dHHQzcvGVKwOIykPP1YOM/HywE/GR39k3FN402mMvIqSLLkrscb3F9Jyvjj1SwyNcjKRKrvJZXCoJ9FlxTT2NLhCiSTMi/gE+aUhmhp76cw6GNuRSGnOvrpisSscizgFnM8fq7X9Y2kUlEY5O1vfBZI/m55xzPhzFlZW5nVr3Zn/5JQgMtnFbHxlqXuDdFbsThViHnf27G/1f1Mb4Mwb4Xl6XqzHe71no5oP5IxwMk3qK4ocJPd/IJ78/Di16s6aoJ+S/Ooriigdnax11I0IiECljAI+s4nH/qwHPPV5fnU1ZRbTbREXMHhfM7M4pDrbP/mrcuoLMmnrrqMp++7nqqyfLoiMbcdr5MjcrZngHBvlFDAl+RbKw75KQkFkkxQ61ctorqiAL/A1XPLkvwfQ5Ep8z3Vh+Ls73SYTG1F7K1YnIr3Pe9nOpWRG5vbByVWTsfcFK00kBm95WWJ4yNZWFnE0/ddT0Xh+ZLkP/7q77rCpXZ2MTdcfl64CBdXgmJFYXDUx/CL5atYsXAGCyuLaDrd7caCX+hShgI+bqu71BUWzt/FmZcw5/8eCaAwz88bG27iuQduYPvuEzQ2t1NVXpD0N7u0LJ/nHriB5752Izv2t7o1tZzy8ytrK9ly97Usn1/hOqnbey3/Syye4KGbl7jX5XfmVbDvr1cn/fJfPr+ChZVFxA38+v2zQ97UvWRyhqcTDE6uiiMQvTdEp2RMOv+K9z3vZzoZ/U7QAEzvm+1EBh9MBVSQZIn3n8T5p/S+fvq+61lZW8kjf/Ax1q9aREnIimNwqtqGApPrUpeE/BQEx35N3f2DTTmC5Xuorii44Hy/wJc/uZCVtZVu2Xfn2l0xu5hnv/q71M4uJuSXJKHiXO+rqkr54EwPM4qC+AU+u3QO1eX5rnYRNzDgsW9FovHzv9ztzPXK4hDbv/K77k3Xm6C4pKqUgE842zPArqYzbN/TnPY8Hrp5idu9ccf+1qTvSzqc79d9Ny6gJBSgsigvKWrJG8l0oaimTIKhND+QZNYCK+orXcXiTO8tn1/BxluWUpof4L1TXW7kmt5sL04mS0LipCddNvJQr/ceD3P57GL3l+vZ7gGK8vyki0Z1+oaPJyG/1SQqF4qS48fO8wsDceOaiU6nREjBeV+HYN3DEwZKC6xf7m+fCLPng7Dd+dC6dm7ZFGPIC/j5vatn8/q7HzGnrICbFs9m255mToZ73cx3sJIREyl+QO+r3mjCjX66vb6G42d7uN0O43V6mHh9AT9sOE4sYTjbHWFlbSWdfdGkCCPHT7BmWRXLLi1163FlItVHcbC10zUROWakzr4ojS0d7DvZwfwZhW4BTO9nOj9qrpxTwtVzywDcKsXL51eMOhoqdZ2ZerkoFxcqSHLA5p2HaWxup7qigFMd/cwpy6clbNWHiptEUv5CVyRO7exijp3pSQp99fvIWHJ9NMybWUhVWT4NR88NqpibiaGc3E6dKC/Or/5Mzm1vz3bnXh/ujbLljWPutXB+WTsNpTbvPOyG5L70TiuxhOGasnzeOnYurWPbKdroJAGmOs5L8q32vHc93kBnXzSpsOOupjP8+v2z7lru27qb8sI8uiJ9gLBmWRU/eOMoJaGAW08r9ebqlGLxOtRTb7ZeU9SdK+YlmYrcTow15e51nj9TkrSbVAEx1A0+2yTDoZzvQ63T211SuTiZXPaWKYzX3OCYKTavu4Yj/+1m/vjTV9imF0MkZpL8CNUVVgjntj/6hDse8AmXlp03A82yGz7NKjlvIgv6BV8GlcIn5/0C3t2CfuHE2R6OnulhVmmIwqDPDiDInGwZ8Al/+x+vdh3HzjF9dgl2sG7SddVl7pq9z36xHN2Oc9sJWnDOxy9W1V6ngGJh0Eft7GK23H0td66Y55YZWVJVSu2sIkpCAe67cYF7Q+1JMakVBv18ZeVCKgqDfOmGBdTVlFM7q4iFs4rdtef5hbe/8VlXA0DO36Ad53QsYWlVhUGrn8nMojxKQlby38MvH6SprYeuSMzqh8J5E9WDqxe75rm7Hm9wfSnpbrappiivdtvZF3W7QDrmsY1rlySZkNIVgfSuwRnP1s4/lPP9U4tmJT07x7tzxTw1aV3kqCAZI7wRK6n/sJajPkZvNOHeMByhUVkccqNcttx9rXvzmlmU5zqMw71Rq8lT3BCJWcf40f2f4GPV5UlrcG6QJaEAl1cWJf3id4jGDZG41Te9JdxH/WUzqCwOJbWpTcd9Ny7gzhXzmGMLOLd3iOfgAZ/PTcpzzEvOc9xYZq9ILEFBXoAe+3rMq7Aq5m667WrO9QzQFYlzuitC/WUzLH/Tj95m4UM/5c9/so9wb5QfNhynKD/InNIQbx0755pt+mLnM9JrZxXx9H0rONja6Tawur2+hjM9AzSd7qYg6Kck5Ocv1i7lmYYTvH2indpZRUk3aMcP5gRVLJpTYt3Eb1nK5bNLAKudb+3s4qQKv6k31+17ml1fylA326H8EE5klNMFcigc57eTaT/aG/xQPpZfHG5LelYUBxUkY0SmiJX1qxa5jlvnF7bz69IpsucIIGf89mvnsWBmYdIvb+cXphMhtHHtkqTigH/7H69mZW0lT95zHUX5lqDyCVSX51M7u5ja2cWuJjCrxPrV39rRz8lw7wXP72BrJ5C+vLtDJJ5IMmX5xTJNOdqGE0F1ws6vKAn5KcoPuuYkJxKodnYxnf0xNr14gJZwn5vPEfAJc8oKaGxup6mtJyn09JwtsAxQlB90b66OOejhlw8S7o3iF+iNxrlmnpVR/uirh+iKxDh2dvA18P49vEJm49olbmCFFf4bdzWSQTg2uxHka6V+pzKF145l6O1Qgi2TE1+5uNGExAlmqCQux6ZeV1M+qCx4pvleZ+/DLx+kKxKnJBTgyXuuS3t8SPYbFNo1m8CKtCrLD1KUb/Xe2L77BD0Dcdq6+2nvjaX1mZSE/HxhxXz+8ZdH3WM6N/PywgDtvTG3zIxTbddrj/cWP6yrKedkey9tXQPMKs7j//rMlfzgjaOcbO9nRlGQypJ8NxnuM//931zfSSjg46o5JW601aYXD3D4o256o3GqKwroicTcz3um4QQbn9tH3Fih20V5/qQkO8icsJcpCW/v8XDaSsKp+2abyOf92zqC19szfiyTAadzcmG26DVIRhMSJzFD2a2dX6NejSWb+c4v0x37W7l8VjEAXZHYoPleLenLn1zoFg686xPzXZNaNG6VTi/ND1j5Ey0dNJ3uxgm8vWJWESUhf5IP5gsr5rNtT3OSZuL4UNp7rezvuz5xmdv21ulW6PyidyrlVhQG2bh2CVfNKQUsp/kP3jhKU1sPvdE4lSVWbgdYQvGmqy5xv8yRWILGlg63FS5YWohf4Fx3JOnz7lwxj6ttE+Gpjj43yW7TSwddn9ffvHSAcG/UrrCb3d/POZfG5nZKC4JJUVMX6piYircw5FP3rnADAbz7j3Wew3ROLswWvQbZo1FbkxTnxuD9VZQNa5ZVse9kB2uWVVm1nuzQVcfp6/y6Wj6/wr0Rg1UOHaybcixhBkVLgeX4RYTb62uSfhF7Gys5xQ1LQgHmlOVTlOentCDIrqYz3FZ3Kf/5E5e5Gof32OmeHfOUE30U80onc74UuxNd5cSfOaVOEBkU8dQbTbhRVs712Lh2iftLf/vuE1YssqevR7qwhaF+rXrHU8/J+dssqSpN+lt4/2bpSI3K8h7Pe5yRku5ctIy8XoPhoIJkkjPcXhLeX/h3rpjHc1+7ESBj+KmX1H8e55f78vkV7rGAJBPPnSvmuR0A05ldvNz1eIPrH+nsG5x7kKl74JplVfzgV8c41dHH7dfOc9fpCBqneGK62k8AX3yiga5InMtnFbm/6p3Pdz7TW0jRmfveqS7+5qWDgOGZhhNcOafEFYbe9XvNct5rmPq3cYStMzf1b+bgNWV5j+dcI+dv6lzHVJPchXCO39kfc3OenHMZSQ+TycRYmKWm+jUYT9RHMs3I5pdytv9YuShUl3rzGu6x063Je8PdvqfZ9Umk81l4BUu67aGuzdV/ucNtIxCyQ4EdweVoaM45VRQGXeG3q+mM+xpwW/YW5VumO7B8OD0DcYpCgSRBcKHrn04QDOd6un646jK3GdZ4+gJy6YPQIotjTyYfiWok04yhfkUN99fV3uNhOvtjg+oype6T6UaQ7v2RmuwcMrWNvevxhqQ6WJnO1xsy62SNQ3ptbe/xMHE3zllcH878mUU0Nre7veBrZxUlRTV19luBBeHeKJteOshzD9xAaX7AFaBOomJjS4db4WDTiwdcze9CphXvtXRMmOn29b7vFVSOSe32a+ddsHR9OlKDCYYrDHLZd0TNUuOLChIlLY6j2LnhDbVPphtBpvdHajbING/9qkV09sfo6bd6ozs5FUOtx5s1nqkO1uadh+mNJgj4hLs+cb6FrvOeY87r7I/R1NbjZsY3Nrefr/xra/5e/8Ztf/8GPQNxamcVcdJuBezU+0o910xaV6rZMd36HUG56cUDrvYxlEktW5zviLM9mdr5TgWz1HSKClNBoqQlm3/yC+0zFjeK4fyzOQEEjlkj9ebmXc/e4+GkrPFMZsA1y6rcUikHWzuTjun1raTTslLLhyRpT/bNvSQUoDcadyPV0pGu7In3/DJdp/WrFrmBEoArTB3B29kXHSR0s8GZjzEj+htPhZt9LplOnSDVR6JMajLZukfjD8p03NT3nNeOryNb38uFckIc53/trCKqygsyzr+QHyhbn0DqtZksvoTx+HU+2TSAybaeC6E+kjFgqv3RpwuZtJqhftFl80s3VTvx/m1Tw2u9UVND5Yt4u2dm8ytz+fwKnrxnxaDvVGp0nXdtqZFlXi4UQuz93KG0tIlkPH6dez/D8Y9N5P/zdNLIprwgEZE1wGbAD2wxxjySi8/Z9OIBGls66OyLZrRHK2PLhXwi3ueRHjf15p0aXuuMD0W6dWSzpnTnlnqsbG+wI/V3TJab2XgINO9nTCez0mRgSgsSEfED/wB8BmgBdovIC8aYgzn4sORnZcIZq5vgUDexbG9uqesYzZpGqjFMFs1ipIyHQPN+xlS/XpONKe0jEZFPAH9ljFltv34IwBjz8FBzRuojUdOWoigXM9PZRzIX8PY6bQEG/awRkfuB+wHmzRt+mCNMHhOAoijKZGOqF21MZ2capGIZYx4zxtQbY+pnzZo1DstSFEW5eJjqgqQFqPG8rgY+nKC1KIqiXJRMdUGyG6gVkQUikgesA16Y4DUpiqJcVExpH4kxJiYiXwNexQr/fcIYM7hphKIoipIzprQgATDGvAy8PNHrUBRFuViZ6qYtRVEUZYJRQaIoiqKMiimdkDgSRKQNOD7C6ZXAmQvudfGi1yczen0yo9dnaCbDtZlvjEmbP3HRCZLRICJ7hsrsVPT6XAi9PpnR6zM0k/3aqGlLURRFGRUqSBRFUZRRoYJkeDw20QuY5Oj1yYxen8zo9RmaSX1t1EeiKIqijArVSBRFUZRRoYJEURRFGRUqSLJERNaIyHsickRENkz0enKJiHwgIvtEpFFE9thjM0TkNRFpsp8rPPs/ZF+X90RktWd8uX2cIyLyHRGrvaSIhERkmz3eICKXjftJDgMReUJETovIfs/YuFwPEbnb/owmEbl7nE55WAxxff5KRE7a36FGEbnZ895Fc31EpEZE/lVE3hWRAyKy3h6fXt8fY4w+LvDAKgj5PrAQyAN+CyyZ6HXl8Hw/ACpTxv4fYIO9vQH4lr29xL4eIWCBfZ389nu/AT6B1TfmFeD37PE/Br5vb68Dtk30OV/geqwEfgfYP57XA5gBHLWfK+ztiom+Hllen78C/jTNvhfV9QGqgN+xt0uAw/Y1mFbfH9VIsuM64Igx5qgxZgD4EXDrBK9pvLkV2GpvbwVu84z/yBgTMcYcA44A14lIFVBqjHnTWN/qp1LmOMd6FrjJ+XU1GTHG7ALOpQyPx/VYDbxmjDlnjAkDrwFrxvr8RssQ12coLqrrY4xpNcb8b3u7C3gXq7PrtPr+qCDJjnQtfedO0FrGAwP8TET2itWmGOASY0wrWP8cwGx7fKhrM9feTh1PmmOMiQEdwMwcnEcuGY/rMdW/d18TkXds05djurlor49tcroGaGCafX9UkGRHVi19pxE3GGN+B/g94AERWZlh36GuTaZrNp2v51hej6l8nb4HXA7UAa3Af7fHL8rrIyLFwI+BrxtjOjPtmmZs0l8fFSTZcVG19DXGfGg/nwZ+gmXa+8hWr7GfT9u7D3VtWuzt1PGkOSISAMrI3jQyWRiP6zFlv3fGmI+MMXFjTAL4R6zvEFyE10dEglhC5IfGmH+xh6fV90cFSXZcNC19RaRIREqcbeCzwH6s83WiPu4Gnre3XwDW2ZEjC4Ba4De2ut4lItfb9tq7UuY4x/oc8HPb7juVGI/r8SrwWRGpsE1Dn7XHJj3OTdLmP2J9h+Aiuz72uTwOvGuM+TvPW9Pr+zPRUQ1T5QHcjBVx8T7w5xO9nhye50KsqJHfAgecc8Wyub4ONNnPMzxz/ty+Lu9hR5LY4/VYN5D3gb/nfCWFfOCfsRyJvwEWTvR5X+Ca/BOWeSaK9Svv3vG6HsA99vgR4EsTfS2GcX2eBvYB72Dd6KouxusD3IhlTnoHaLQfN0+374+WSFEURVFGhZq2FEVRlFGhgkRRFEUZFSpIFEVRlFGhgkRRFEUZFSpIFEVRlFGhgkS5qBERIyJPe14HRKRNRF6yX/++2NWexapo+6ej+Kyr5Xw13HMicsze3jn6M0n7eV8Ukb+3t4e9dhHpzsW6lOlHYKIXoCgTTA+wTEQKjDF9wGeAk86bxpgXGKPkU2PMPqySIYjIk8BLxphnvfuISMBY9ZIUZcqgGomiWCW5/4O9/YdYCXZA8q96LyJyuYjssAtb/lJEFtvjnxeR/SLyWxHZlc2Hi8i/ich/E5FfAOtF5Ba7r8TbIrJTRC4REZ9YfWLKPfOO2O/NEpEfi8hu+3HDBT5vqLUvEJE37WNsymbtigIqSBQFrLYA60QkH/gYVnXWC/EY8CfGmOXAnwLftce/Aaw2xnwc+P1hrKHcGPMpY8x/B94ArjfGXGOv7b8aq2bV81jlRhCRFcAHxpiPgM3At40x1wJ/AGwZ4do3A9+zj3NqGGtXLnLUtKVc9Bhj3rFLfP8h8PKF9rcruf4u8M9yvo1KyH7+FfCkiGwH/iXN9KHY5tmuBrbZ9arygGOefb4B/AC7gZE9vgpY4llLqVMvbZhrvwFLEIFV4uRbw1i/chGjgkRRLF4A/l/g01y4N4oPaDfG1KW+YYz5iq0t/AegUUTqjDFns/j8Hs/2/wT+zhjzgoh8GqvbIMCbwBUiMgurqdHfeNbzCdvH4yLpe4UNuXbnFLJYq6IkoaYtRbF4Avim7RDPiLH6SRwTkc+DVeFVRD5ub19ujGkwxnwDOENyGe9sKeO8w9/ts22swng/Af4Oq5qsI6B+BnzN2U9E6kaydixtap29/YURrFu5SFFBoiiAMabFGLN5GFO+ANwrIk6VZKf18qMisk9E9gO7sKooD5e/wjI9/RJLGHnZBvwfJJvC/k+gXqxuhAeBr4xw7euxGpntxhJmipIVWv1XURRFGRWqkSiKoiijQgWJoiiKMipUkCiKoiijQgWJoiiKMipUkCiKoiijQgWJoiiKMipUkCiKoiij4v8Hv69r+3bZRbIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "y = df['price'].values\n",
    "for col in df_numeric:\n",
    "    if col != 'mileage': continue\n",
    "    x = (df_numeric[col].values)\n",
    "    zx = stats.zscore(x,axis=None)\n",
    "    zy = stats.zscore(y,axis=None)\n",
    "    print(sum(zx*zy)/(len(x)-1))\n",
    "    fig=plt.figure()\n",
    "    ax1 = fig.add_subplot()\n",
    "    ax1.scatter(x,y, s=2)\n",
    "    ax1.set_ylabel('price')\n",
    "    ax1.set_xlabel('Miles Travelled')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42204166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10609, 8)\n",
      "(10609, 1)\n",
      "(4548, 8)\n",
      "(4548, 1)\n"
     ]
    }
   ],
   "source": [
    "target_variable = ['price']\n",
    "Predictors = ['model',\t'year',\t'transmission',\t'mileage',\t'fuelType',\t'tax',\t'mpg',\t'engineSize']\n",
    "X=df[Predictors].values\n",
    "y=df[target_variable].values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dfe5a080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 200241292.5564 - val_loss: 37605144.0000\n",
      "Epoch 2/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 36828043.8158 - val_loss: 36607664.0000\n",
      "Epoch 3/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 37094198.1917 - val_loss: 36656380.0000\n",
      "Epoch 4/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 35598281.3271 - val_loss: 35139732.0000\n",
      "Epoch 5/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 35813995.0376 - val_loss: 35055136.0000\n",
      "Epoch 6/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 34175064.0940 - val_loss: 35264728.0000\n",
      "Epoch 7/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 32470924.3289 - val_loss: 34492360.0000\n",
      "Epoch 8/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 33681608.8271 - val_loss: 32684582.0000\n",
      "Epoch 9/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 32793801.3120 - val_loss: 32427034.0000\n",
      "Epoch 10/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 32605746.9398 - val_loss: 29777224.0000\n",
      "Epoch 11/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 31125684.8271 - val_loss: 29960292.0000\n",
      "Epoch 12/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 28686348.8797 - val_loss: 26444076.0000\n",
      "Epoch 13/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 26808016.9173 - val_loss: 26218914.0000\n",
      "Epoch 14/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 24832557.6222 - val_loss: 22912398.0000\n",
      "Epoch 15/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 23395278.1992 - val_loss: 25155814.0000\n",
      "Epoch 16/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 23469136.1071 - val_loss: 25657144.0000\n",
      "Epoch 17/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 23149691.3008 - val_loss: 18716864.0000\n",
      "Epoch 18/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 21938234.4474 - val_loss: 18365358.0000\n",
      "Epoch 19/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 21123516.0113 - val_loss: 21905824.0000\n",
      "Epoch 20/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 23786683.9361 - val_loss: 17192070.0000\n",
      "Epoch 21/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 18869638.1711 - val_loss: 19768556.0000\n",
      "Epoch 22/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 19857985.1767 - val_loss: 21435994.0000\n",
      "Epoch 23/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 19411993.9774 - val_loss: 17407912.0000\n",
      "Epoch 24/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 19693117.9831 - val_loss: 17094886.0000\n",
      "Epoch 25/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 18985637.4812 - val_loss: 16214220.0000\n",
      "Epoch 26/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 18334518.7650 - val_loss: 16196220.0000\n",
      "Epoch 27/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 18480470.2068 - val_loss: 18425986.0000\n",
      "Epoch 28/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 17232629.7782 - val_loss: 15861167.0000\n",
      "Epoch 29/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 16081018.6955 - val_loss: 16062641.0000\n",
      "Epoch 30/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 17062731.0150 - val_loss: 14550148.0000\n",
      "Epoch 31/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 16164615.9023 - val_loss: 15644123.0000\n",
      "Epoch 32/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15757026.1034 - val_loss: 14253753.0000\n",
      "Epoch 33/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 18850165.2105 - val_loss: 16558156.0000\n",
      "Epoch 34/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 17422310.4267 - val_loss: 14642056.0000\n",
      "Epoch 35/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 15465370.6335 - val_loss: 15231153.0000\n",
      "Epoch 36/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15080526.9445 - val_loss: 16181659.0000\n",
      "Epoch 37/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 16384759.6316 - val_loss: 16635614.0000\n",
      "Epoch 38/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15739570.5000 - val_loss: 14656668.0000\n",
      "Epoch 39/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15337153.3647 - val_loss: 13854165.0000\n",
      "Epoch 40/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 16283209.0752 - val_loss: 15032722.0000\n",
      "Epoch 41/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15010200.6898 - val_loss: 16960972.0000\n",
      "Epoch 42/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15150255.5752 - val_loss: 17309898.0000\n",
      "Epoch 43/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15191581.3628 - val_loss: 14925379.0000\n",
      "Epoch 44/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14361692.1147 - val_loss: 13747020.0000\n",
      "Epoch 45/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15217875.2274 - val_loss: 13238772.0000\n",
      "Epoch 46/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15605793.5075 - val_loss: 14587700.0000\n",
      "Epoch 47/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15224122.3496 - val_loss: 14583941.0000\n",
      "Epoch 48/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14906866.4887 - val_loss: 15894175.0000\n",
      "Epoch 49/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15242612.4098 - val_loss: 13805817.0000\n",
      "Epoch 50/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14979467.1654 - val_loss: 13591869.0000\n",
      "Epoch 51/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 17039640.9380 - val_loss: 14570591.0000\n",
      "Epoch 52/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14414311.6654 - val_loss: 13552485.0000\n",
      "Epoch 53/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15004674.0695 - val_loss: 13220236.0000\n",
      "Epoch 54/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14190846.5019 - val_loss: 13533741.0000\n",
      "Epoch 55/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15565359.2274 - val_loss: 12821141.0000\n",
      "Epoch 56/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14343438.7650 - val_loss: 12741182.0000\n",
      "Epoch 57/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14735919.3910 - val_loss: 13635746.0000\n",
      "Epoch 58/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13946550.7368 - val_loss: 13072097.0000\n",
      "Epoch 59/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13984021.0752 - val_loss: 13476413.0000\n",
      "Epoch 60/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 16109043.6259 - val_loss: 16469157.0000\n",
      "Epoch 61/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15041428.2190 - val_loss: 15623535.0000\n",
      "Epoch 62/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14628398.7086 - val_loss: 13041864.0000\n",
      "Epoch 63/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13690824.8618 - val_loss: 15438946.0000\n",
      "Epoch 64/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14479779.8346 - val_loss: 16938528.0000\n",
      "Epoch 65/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14895240.7331 - val_loss: 14486734.0000\n",
      "Epoch 66/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14624545.1711 - val_loss: 14821931.0000\n",
      "Epoch 67/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14771357.5959 - val_loss: 14397700.0000\n",
      "Epoch 68/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13906010.7237 - val_loss: 14197722.0000\n",
      "Epoch 69/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14555353.5977 - val_loss: 14527069.0000\n",
      "Epoch 70/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14128763.5160 - val_loss: 14433171.0000\n",
      "Epoch 71/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13633802.7444 - val_loss: 19843280.0000\n",
      "Epoch 72/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14950422.4906 - val_loss: 13816364.0000\n",
      "Epoch 73/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15095141.3628 - val_loss: 12422769.0000\n",
      "Epoch 74/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13980996.9850 - val_loss: 14746809.0000\n",
      "Epoch 75/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13732494.0583 - val_loss: 12824558.0000\n",
      "Epoch 76/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13277836.3628 - val_loss: 12995576.0000\n",
      "Epoch 77/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 15747406.2989 - val_loss: 12139954.0000\n",
      "Epoch 78/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13661609.0545 - val_loss: 12825316.0000\n",
      "Epoch 79/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14458957.0094 - val_loss: 12780663.0000\n",
      "Epoch 80/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13007032.9699 - val_loss: 12910588.0000\n",
      "Epoch 81/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13620015.3195 - val_loss: 14144027.0000\n",
      "Epoch 82/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 13684579.9850 - val_loss: 12560300.0000\n",
      "Epoch 83/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14598653.8788 - val_loss: 13948924.0000\n",
      "Epoch 84/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14649096.5094 - val_loss: 13198893.0000\n",
      "Epoch 85/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13929650.8985 - val_loss: 12663014.0000\n",
      "Epoch 86/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12923332.2115 - val_loss: 14145366.0000\n",
      "Epoch 87/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13493636.1598 - val_loss: 14912990.0000\n",
      "Epoch 88/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14434693.0282 - val_loss: 17619304.0000\n",
      "Epoch 89/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13628767.4154 - val_loss: 13677105.0000\n",
      "Epoch 90/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12795291.9906 - val_loss: 12785632.0000\n",
      "Epoch 91/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13256216.8553 - val_loss: 25583764.0000\n",
      "Epoch 92/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14076423.7838 - val_loss: 14478576.0000\n",
      "Epoch 93/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13783977.1992 - val_loss: 11914170.0000\n",
      "Epoch 94/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12762860.9831 - val_loss: 12359470.0000\n",
      "Epoch 95/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13369163.7368 - val_loss: 12928328.0000\n",
      "Epoch 96/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13420993.8797 - val_loss: 16380709.0000\n",
      "Epoch 97/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14132583.6015 - val_loss: 12936296.0000\n",
      "Epoch 98/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13865690.4023 - val_loss: 13030614.0000\n",
      "Epoch 99/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13435229.7650 - val_loss: 11948636.0000\n",
      "Epoch 100/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13681851.1786 - val_loss: 12801486.0000\n",
      "Epoch 101/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13421025.1034 - val_loss: 11719156.0000\n",
      "Epoch 102/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12867684.3703 - val_loss: 13120723.0000\n",
      "Epoch 103/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12635111.5442 - val_loss: 12000018.0000\n",
      "Epoch 104/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13431550.4868 - val_loss: 16399103.0000\n",
      "Epoch 105/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13424338.8910 - val_loss: 11797475.0000\n",
      "Epoch 106/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13357446.1034 - val_loss: 13470871.0000\n",
      "Epoch 107/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13149852.2857 - val_loss: 11503154.0000\n",
      "Epoch 108/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14998619.9107 - val_loss: 11634811.0000\n",
      "Epoch 109/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13095873.2039 - val_loss: 13485595.0000\n",
      "Epoch 110/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 13380430.0677 - val_loss: 13928559.0000\n",
      "Epoch 111/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12679090.3120 - val_loss: 11891551.0000\n",
      "Epoch 112/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13244091.4474 - val_loss: 12419473.0000\n",
      "Epoch 113/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12739054.3374 - val_loss: 17442992.0000\n",
      "Epoch 114/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13527906.6353 - val_loss: 14571888.0000\n",
      "Epoch 115/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12871857.7293 - val_loss: 15651609.0000\n",
      "Epoch 116/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12838863.6805 - val_loss: 14638269.0000\n",
      "Epoch 117/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14325172.3440 - val_loss: 12057351.0000\n",
      "Epoch 118/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13185857.2566 - val_loss: 11697771.0000\n",
      "Epoch 119/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14412650.3929 - val_loss: 12220366.0000\n",
      "Epoch 120/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12917593.5489 - val_loss: 15584122.0000\n",
      "Epoch 121/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14219465.0771 - val_loss: 12111088.0000\n",
      "Epoch 122/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13270254.8816 - val_loss: 12253768.0000\n",
      "Epoch 123/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13268850.6504 - val_loss: 13770857.0000\n",
      "Epoch 124/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13237192.6786 - val_loss: 13207625.0000\n",
      "Epoch 125/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13691394.2951 - val_loss: 11397018.0000\n",
      "Epoch 126/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12378273.8167 - val_loss: 14469594.0000\n",
      "Epoch 127/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 13759082.2575 - val_loss: 13320508.0000\n",
      "Epoch 128/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 13258264.2068 - val_loss: 12467579.0000\n",
      "Epoch 129/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12506526.8741 - val_loss: 12599092.0000\n",
      "Epoch 130/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12958607.8440 - val_loss: 11605693.0000\n",
      "Epoch 131/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12697759.1898 - val_loss: 11741100.0000\n",
      "Epoch 132/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14279745.1823 - val_loss: 11674559.0000\n",
      "Epoch 133/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11860035.5188 - val_loss: 17675942.0000\n",
      "Epoch 134/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13560160.4530 - val_loss: 11992452.0000\n",
      "Epoch 135/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12187428.2218 - val_loss: 13146100.0000\n",
      "Epoch 136/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 14011688.2030 - val_loss: 11369743.0000\n",
      "Epoch 137/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13257000.3844 - val_loss: 12972429.0000\n",
      "Epoch 138/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12869844.7895 - val_loss: 13503108.0000\n",
      "Epoch 139/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 13572421.1861 - val_loss: 12302149.0000\n",
      "Epoch 140/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13026896.9793 - val_loss: 11515962.0000\n",
      "Epoch 141/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12903576.1090 - val_loss: 13199312.0000\n",
      "Epoch 142/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12948784.9041 - val_loss: 13590445.0000\n",
      "Epoch 143/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13057934.2237 - val_loss: 11181003.0000\n",
      "Epoch 144/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13378476.7011 - val_loss: 12599400.0000\n",
      "Epoch 145/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13029779.4464 - val_loss: 13201906.0000\n",
      "Epoch 146/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12794341.0056 - val_loss: 11361378.0000\n",
      "Epoch 147/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12667738.1729 - val_loss: 14450622.0000\n",
      "Epoch 148/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12693098.5677 - val_loss: 12684392.0000\n",
      "Epoch 149/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12861266.8600 - val_loss: 12030147.0000\n",
      "Epoch 150/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 13536224.0996 - val_loss: 13986766.0000\n",
      "Epoch 151/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 13195553.8139 - val_loss: 12032437.0000\n",
      "Epoch 152/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13481090.8402 - val_loss: 12166839.0000\n",
      "Epoch 153/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 13487771.8496 - val_loss: 12365811.0000\n",
      "Epoch 154/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12520735.9662 - val_loss: 13550019.0000\n",
      "Epoch 155/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12390259.3421 - val_loss: 11362690.0000\n",
      "Epoch 156/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13320471.0000 - val_loss: 11530346.0000\n",
      "Epoch 157/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12533087.3900 - val_loss: 11871204.0000\n",
      "Epoch 158/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13071736.6391 - val_loss: 15766974.0000\n",
      "Epoch 159/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13359446.5583 - val_loss: 11645688.0000\n",
      "Epoch 160/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12245201.0150 - val_loss: 11202649.0000\n",
      "Epoch 161/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11945905.4079 - val_loss: 12650660.0000\n",
      "Epoch 162/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13000312.6711 - val_loss: 14708491.0000\n",
      "Epoch 163/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13160979.1212 - val_loss: 11162234.0000\n",
      "Epoch 164/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12060608.4615 - val_loss: 11120227.0000\n",
      "Epoch 165/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12266073.7237 - val_loss: 12233220.0000\n",
      "Epoch 166/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12953822.2885 - val_loss: 11945499.0000\n",
      "Epoch 167/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11971259.0395 - val_loss: 12088472.0000\n",
      "Epoch 168/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13231657.7133 - val_loss: 11921075.0000\n",
      "Epoch 169/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12669963.7594 - val_loss: 11726945.0000\n",
      "Epoch 170/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12477151.4624 - val_loss: 12628815.0000\n",
      "Epoch 171/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12350572.7293 - val_loss: 12123460.0000\n",
      "Epoch 172/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12529383.5301 - val_loss: 14012783.0000\n",
      "Epoch 173/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13338586.3308 - val_loss: 13026485.0000\n",
      "Epoch 174/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12097009.5545 - val_loss: 14699121.0000\n",
      "Epoch 175/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13295030.3515 - val_loss: 12287314.0000\n",
      "Epoch 176/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12386979.9464 - val_loss: 13487711.0000\n",
      "Epoch 177/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12790210.3703 - val_loss: 11545073.0000\n",
      "Epoch 178/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12597161.1090 - val_loss: 12038314.0000\n",
      "Epoch 179/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12481508.0526 - val_loss: 11840790.0000\n",
      "Epoch 180/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13273290.1053 - val_loss: 11044941.0000\n",
      "Epoch 181/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12437403.4850 - val_loss: 11868400.0000\n",
      "Epoch 182/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12429025.2763 - val_loss: 14077129.0000\n",
      "Epoch 183/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12672961.2876 - val_loss: 13389775.0000\n",
      "Epoch 184/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12346506.4662 - val_loss: 11640302.0000\n",
      "Epoch 185/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12237596.6034 - val_loss: 11078906.0000\n",
      "Epoch 186/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13930642.6222 - val_loss: 13359370.0000\n",
      "Epoch 187/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12178565.3430 - val_loss: 12245697.0000\n",
      "Epoch 188/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11759320.8402 - val_loss: 12709608.0000\n",
      "Epoch 189/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12662750.7820 - val_loss: 11969149.0000\n",
      "Epoch 190/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12837958.1165 - val_loss: 12528885.0000\n",
      "Epoch 191/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12454448.3703 - val_loss: 11993744.0000\n",
      "Epoch 192/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12080497.1071 - val_loss: 14881031.0000\n",
      "Epoch 193/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12213725.3553 - val_loss: 13837404.0000\n",
      "Epoch 194/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13305319.5583 - val_loss: 11252709.0000\n",
      "Epoch 195/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12838049.8703 - val_loss: 12991837.0000\n",
      "Epoch 196/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12305556.3102 - val_loss: 11707404.0000\n",
      "Epoch 197/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12762589.4455 - val_loss: 12481021.0000\n",
      "Epoch 198/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11836248.6147 - val_loss: 12665177.0000\n",
      "Epoch 199/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12246971.9286 - val_loss: 15298221.0000\n",
      "Epoch 200/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12007522.2726 - val_loss: 12308198.0000\n",
      "Epoch 1/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12827727.5094 - val_loss: 11419045.0000\n",
      "Epoch 2/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12407811.9290 - val_loss: 15229049.0000\n",
      "Epoch 3/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12721114.7218 - val_loss: 11302448.0000\n",
      "Epoch 4/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12632736.5376 - val_loss: 11068349.0000\n",
      "Epoch 5/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12092179.4878 - val_loss: 10893670.0000\n",
      "Epoch 6/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12996998.1936 - val_loss: 11456285.0000\n",
      "Epoch 7/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12744691.1908 - val_loss: 13859910.0000\n",
      "Epoch 8/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12297873.2801 - val_loss: 10831715.0000\n",
      "Epoch 9/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12894889.0320 - val_loss: 10811804.0000\n",
      "Epoch 10/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12012586.7180 - val_loss: 11516783.0000\n",
      "Epoch 11/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11745930.2909 - val_loss: 14753088.0000\n",
      "Epoch 12/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12314455.8947 - val_loss: 13039126.0000\n",
      "Epoch 13/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12274009.5752 - val_loss: 11983000.0000\n",
      "Epoch 14/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12982613.3778 - val_loss: 14995214.0000\n",
      "Epoch 15/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12038520.9417 - val_loss: 11444768.0000\n",
      "Epoch 16/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12921053.7961 - val_loss: 11287609.0000\n",
      "Epoch 17/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 13579144.9624 - val_loss: 10942964.0000\n",
      "Epoch 18/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11765941.9492 - val_loss: 13111783.0000\n",
      "Epoch 19/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11859802.5169 - val_loss: 11572321.0000\n",
      "Epoch 20/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12436107.0789 - val_loss: 12248544.0000\n",
      "Epoch 21/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12544711.3590 - val_loss: 12171780.0000\n",
      "Epoch 22/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12010968.7989 - val_loss: 13183445.0000\n",
      "Epoch 23/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12339610.3130 - val_loss: 14029215.0000\n",
      "Epoch 24/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12528016.3853 - val_loss: 11632952.0000\n",
      "Epoch 25/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11928919.0103 - val_loss: 13400570.0000\n",
      "Epoch 26/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13035277.1278 - val_loss: 11067909.0000\n",
      "Epoch 27/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12243526.7519 - val_loss: 14600152.0000\n",
      "Epoch 28/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12260093.2838 - val_loss: 11692397.0000\n",
      "Epoch 29/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11984483.4135 - val_loss: 12512805.0000\n",
      "Epoch 30/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12370817.3741 - val_loss: 12693377.0000\n",
      "Epoch 31/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12071718.9887 - val_loss: 17716778.0000\n",
      "Epoch 32/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13812519.4267 - val_loss: 10857630.0000\n",
      "Epoch 33/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11949484.6635 - val_loss: 12667875.0000\n",
      "Epoch 34/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11805494.4455 - val_loss: 10755361.0000\n",
      "Epoch 35/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11725063.6466 - val_loss: 11622358.0000\n",
      "Epoch 36/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11952100.8910 - val_loss: 11432829.0000\n",
      "Epoch 37/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11959615.5019 - val_loss: 10757223.0000\n",
      "Epoch 38/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11882944.8421 - val_loss: 13012099.0000\n",
      "Epoch 39/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11619165.1504 - val_loss: 10943690.0000\n",
      "Epoch 40/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11896192.4398 - val_loss: 11808984.0000\n",
      "Epoch 41/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 14113387.7961 - val_loss: 11062971.0000\n",
      "Epoch 42/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12120227.2086 - val_loss: 11276945.0000\n",
      "Epoch 43/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11450404.5470 - val_loss: 16204188.0000\n",
      "Epoch 44/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11909730.7650 - val_loss: 12007387.0000\n",
      "Epoch 45/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12089312.5301 - val_loss: 12133326.0000\n",
      "Epoch 46/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12257134.8158 - val_loss: 11614626.0000\n",
      "Epoch 47/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11536485.7312 - val_loss: 12330126.0000\n",
      "Epoch 48/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12623632.5414 - val_loss: 11459778.0000\n",
      "Epoch 49/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12220501.6447 - val_loss: 10833897.0000\n",
      "Epoch 50/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11815030.2340 - val_loss: 13414226.0000\n",
      "Epoch 51/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12096248.3008 - val_loss: 11213611.0000\n",
      "Epoch 52/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11804391.4624 - val_loss: 11721932.0000\n",
      "Epoch 53/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12030315.0216 - val_loss: 13514829.0000\n",
      "Epoch 54/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12468516.5695 - val_loss: 11458434.0000\n",
      "Epoch 55/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12177140.4248 - val_loss: 10771306.0000\n",
      "Epoch 56/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11998300.3055 - val_loss: 12882656.0000\n",
      "Epoch 57/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11593605.4117 - val_loss: 14526655.0000\n",
      "Epoch 58/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12607888.2575 - val_loss: 12264654.0000\n",
      "Epoch 59/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11936843.9455 - val_loss: 11212662.0000\n",
      "Epoch 60/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12569168.5038 - val_loss: 10765417.0000\n",
      "Epoch 61/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12361392.2058 - val_loss: 11046818.0000\n",
      "Epoch 62/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12397978.9887 - val_loss: 11438659.0000\n",
      "Epoch 63/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13069618.6635 - val_loss: 11565088.0000\n",
      "Epoch 64/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12133143.6936 - val_loss: 13925081.0000\n",
      "Epoch 65/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12654603.2519 - val_loss: 11230049.0000\n",
      "Epoch 66/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12003523.2932 - val_loss: 10940711.0000\n",
      "Epoch 67/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11915055.9671 - val_loss: 11305988.0000\n",
      "Epoch 68/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11651201.5508 - val_loss: 10700629.0000\n",
      "Epoch 69/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11768689.7011 - val_loss: 10819789.0000\n",
      "Epoch 70/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12715805.0038 - val_loss: 10727648.0000\n",
      "Epoch 71/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12315654.3712 - val_loss: 11436611.0000\n",
      "Epoch 72/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11745891.0968 - val_loss: 11586166.0000\n",
      "Epoch 73/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11695025.1842 - val_loss: 11459497.0000\n",
      "Epoch 74/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12432940.4361 - val_loss: 11602474.0000\n",
      "Epoch 75/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11820342.8271 - val_loss: 11868449.0000\n",
      "Epoch 76/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12005728.5282 - val_loss: 10927382.0000\n",
      "Epoch 77/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12745986.9868 - val_loss: 12316148.0000\n",
      "Epoch 78/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12210191.1955 - val_loss: 12442172.0000\n",
      "Epoch 79/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12043692.0132 - val_loss: 11641516.0000\n",
      "Epoch 80/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11555213.1692 - val_loss: 14288095.0000\n",
      "Epoch 81/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12730589.4925 - val_loss: 10698011.0000\n",
      "Epoch 82/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12651481.3750 - val_loss: 12065742.0000\n",
      "Epoch 83/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11964976.0141 - val_loss: 12304589.0000\n",
      "Epoch 84/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12159075.6711 - val_loss: 12193939.0000\n",
      "Epoch 85/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12358934.0865 - val_loss: 11342598.0000\n",
      "Epoch 86/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11801934.0865 - val_loss: 12260878.0000\n",
      "Epoch 87/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11304187.9445 - val_loss: 10663918.0000\n",
      "Epoch 88/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12219777.6090 - val_loss: 11705158.0000\n",
      "Epoch 89/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11885836.4323 - val_loss: 10902110.0000\n",
      "Epoch 90/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11772299.7256 - val_loss: 11590627.0000\n",
      "Epoch 91/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12149388.6015 - val_loss: 11334129.0000\n",
      "Epoch 92/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12001513.4352 - val_loss: 11069281.0000\n",
      "Epoch 93/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12512914.1682 - val_loss: 10584303.0000\n",
      "Epoch 94/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11834279.8402 - val_loss: 12825361.0000\n",
      "Epoch 95/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11836860.5846 - val_loss: 14453917.0000\n",
      "Epoch 96/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12750928.5930 - val_loss: 10879355.0000\n",
      "Epoch 97/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11888969.8966 - val_loss: 11013398.0000\n",
      "Epoch 98/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11437430.8506 - val_loss: 10975000.0000\n",
      "Epoch 99/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12762037.3797 - val_loss: 12665026.0000\n",
      "Epoch 100/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12165864.4831 - val_loss: 11014332.0000\n",
      "Epoch 101/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11512632.2481 - val_loss: 11023499.0000\n",
      "Epoch 102/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12410774.5461 - val_loss: 11031363.0000\n",
      "Epoch 103/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11665088.7763 - val_loss: 11200199.0000\n",
      "Epoch 104/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11415043.3496 - val_loss: 13765709.0000\n",
      "Epoch 105/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12260491.6898 - val_loss: 11931842.0000\n",
      "Epoch 106/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11617670.7726 - val_loss: 12369019.0000\n",
      "Epoch 107/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11789812.1447 - val_loss: 11204808.0000\n",
      "Epoch 108/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11325120.9361 - val_loss: 10928110.0000\n",
      "Epoch 109/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11936315.9944 - val_loss: 11386114.0000\n",
      "Epoch 110/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11509175.7274 - val_loss: 13488900.0000\n",
      "Epoch 111/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11847255.7180 - val_loss: 11140943.0000\n",
      "Epoch 112/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11995047.2368 - val_loss: 10734297.0000\n",
      "Epoch 113/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11514363.8628 - val_loss: 11757683.0000\n",
      "Epoch 114/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11838973.0357 - val_loss: 11551701.0000\n",
      "Epoch 115/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11509604.7086 - val_loss: 13352173.0000\n",
      "Epoch 116/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11700445.9718 - val_loss: 13664840.0000\n",
      "Epoch 117/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12944836.9671 - val_loss: 10666813.0000\n",
      "Epoch 118/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11256903.8327 - val_loss: 11567907.0000\n",
      "Epoch 119/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11492489.8863 - val_loss: 11429835.0000\n",
      "Epoch 120/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11576201.4154 - val_loss: 15239753.0000\n",
      "Epoch 121/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11693360.4154 - val_loss: 15271176.0000\n",
      "Epoch 122/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12293041.4511 - val_loss: 11288085.0000\n",
      "Epoch 123/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11834197.0169 - val_loss: 13284835.0000\n",
      "Epoch 124/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12000778.4342 - val_loss: 10803966.0000\n",
      "Epoch 125/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12738235.5865 - val_loss: 11724977.0000\n",
      "Epoch 126/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12133799.7923 - val_loss: 10921225.0000\n",
      "Epoch 127/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11651985.9511 - val_loss: 10676779.0000\n",
      "Epoch 128/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11913798.1861 - val_loss: 11058760.0000\n",
      "Epoch 129/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11524031.6570 - val_loss: 11466876.0000\n",
      "Epoch 130/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11675566.8026 - val_loss: 10975634.0000\n",
      "Epoch 131/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11784417.4511 - val_loss: 16278569.0000\n",
      "Epoch 132/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12612871.8421 - val_loss: 14927424.0000\n",
      "Epoch 133/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11966916.0658 - val_loss: 11647221.0000\n",
      "Epoch 134/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12238587.4079 - val_loss: 12849948.0000\n",
      "Epoch 135/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11485878.2002 - val_loss: 12125142.0000\n",
      "Epoch 136/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11573791.5489 - val_loss: 13193003.0000\n",
      "Epoch 137/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12353816.5357 - val_loss: 10983135.0000\n",
      "Epoch 138/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12633490.2481 - val_loss: 11176828.0000\n",
      "Epoch 139/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12088092.6034 - val_loss: 11591072.0000\n",
      "Epoch 140/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11553192.4868 - val_loss: 14225284.0000\n",
      "Epoch 141/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11867369.8929 - val_loss: 10874940.0000\n",
      "Epoch 142/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12061473.6259 - val_loss: 13851607.0000\n",
      "Epoch 143/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11796796.7049 - val_loss: 10653433.0000\n",
      "Epoch 144/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11918270.4173 - val_loss: 12342325.0000\n",
      "Epoch 145/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11618512.4737 - val_loss: 11370319.0000\n",
      "Epoch 146/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11988529.6861 - val_loss: 10826881.0000\n",
      "Epoch 147/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11266356.1128 - val_loss: 12736227.0000\n",
      "Epoch 148/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11566723.0470 - val_loss: 11396017.0000\n",
      "Epoch 149/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11818921.9925 - val_loss: 14664219.0000\n",
      "Epoch 150/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12706103.5150 - val_loss: 11727637.0000\n",
      "Epoch 151/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12091392.7951 - val_loss: 13037356.0000\n",
      "Epoch 152/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11884048.6617 - val_loss: 11307069.0000\n",
      "Epoch 153/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11312603.7086 - val_loss: 10656596.0000\n",
      "Epoch 154/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11563852.0752 - val_loss: 12918054.0000\n",
      "Epoch 155/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11833357.8327 - val_loss: 11003406.0000\n",
      "Epoch 156/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11559421.1241 - val_loss: 11266443.0000\n",
      "Epoch 157/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11928949.9596 - val_loss: 10582051.0000\n",
      "Epoch 158/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11351252.9427 - val_loss: 13698750.0000\n",
      "Epoch 159/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12229040.6447 - val_loss: 10650341.0000\n",
      "Epoch 160/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11810247.6936 - val_loss: 11614743.0000\n",
      "Epoch 161/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11788494.1372 - val_loss: 10831966.0000\n",
      "Epoch 162/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11952602.9549 - val_loss: 11165648.0000\n",
      "Epoch 163/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11875986.3844 - val_loss: 13798807.0000\n",
      "Epoch 164/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11970250.6184 - val_loss: 10944338.0000\n",
      "Epoch 165/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11940841.8271 - val_loss: 10698804.0000\n",
      "Epoch 166/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11873894.8327 - val_loss: 11399450.0000\n",
      "Epoch 167/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11248602.4850 - val_loss: 10507718.0000\n",
      "Epoch 168/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11292561.4774 - val_loss: 11035960.0000\n",
      "Epoch 169/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11781501.2961 - val_loss: 12645560.0000\n",
      "Epoch 170/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11783849.2086 - val_loss: 10751400.0000\n",
      "Epoch 171/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11215089.9051 - val_loss: 11365988.0000\n",
      "Epoch 172/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11761157.8440 - val_loss: 12047114.0000\n",
      "Epoch 173/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12340260.4117 - val_loss: 11469671.0000\n",
      "Epoch 174/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10962751.0592 - val_loss: 10695645.0000\n",
      "Epoch 175/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11036541.1053 - val_loss: 11695702.0000\n",
      "Epoch 176/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11613455.0235 - val_loss: 11053248.0000\n",
      "Epoch 177/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12455791.5827 - val_loss: 11722440.0000\n",
      "Epoch 178/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12235404.8515 - val_loss: 12028918.0000\n",
      "Epoch 179/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11863340.9502 - val_loss: 11164737.0000\n",
      "Epoch 180/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11958579.3759 - val_loss: 11879735.0000\n",
      "Epoch 181/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11523064.2632 - val_loss: 12904417.0000\n",
      "Epoch 182/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11732204.7218 - val_loss: 12473105.0000\n",
      "Epoch 183/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 13910903.3421 - val_loss: 10565002.0000\n",
      "Epoch 184/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11507404.9953 - val_loss: 10684120.0000\n",
      "Epoch 185/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12073615.1447 - val_loss: 10825280.0000\n",
      "Epoch 186/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11676451.9981 - val_loss: 10919886.0000\n",
      "Epoch 187/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11555858.4145 - val_loss: 10562792.0000\n",
      "Epoch 188/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11364797.5056 - val_loss: 10554904.0000\n",
      "Epoch 189/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11388587.1316 - val_loss: 10928957.0000\n",
      "Epoch 190/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12020207.3600 - val_loss: 11287242.0000\n",
      "Epoch 191/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12269557.8440 - val_loss: 12418202.0000\n",
      "Epoch 192/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11929423.4868 - val_loss: 11233149.0000\n",
      "Epoch 193/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11832385.3900 - val_loss: 10855822.0000\n",
      "Epoch 194/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11279160.0282 - val_loss: 15233615.0000\n",
      "Epoch 195/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11853859.5188 - val_loss: 12605839.0000\n",
      "Epoch 196/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12225343.7256 - val_loss: 11838823.0000\n",
      "Epoch 197/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11777088.8496 - val_loss: 11492368.0000\n",
      "Epoch 198/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12404111.0752 - val_loss: 10775438.0000\n",
      "Epoch 199/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11334355.7096 - val_loss: 10539648.0000\n",
      "Epoch 200/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11785577.9023 - val_loss: 10539232.0000\n",
      "Epoch 1/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11569452.8722 - val_loss: 10719769.0000\n",
      "Epoch 2/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11810113.9342 - val_loss: 11011158.0000\n",
      "Epoch 3/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11201931.9370 - val_loss: 11660058.0000\n",
      "Epoch 4/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11342759.2998 - val_loss: 10592648.0000\n",
      "Epoch 5/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12045518.6325 - val_loss: 11186723.0000\n",
      "Epoch 6/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11649951.5733 - val_loss: 11525800.0000\n",
      "Epoch 7/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11666583.9887 - val_loss: 10681934.0000\n",
      "Epoch 8/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11135078.0432 - val_loss: 13622208.0000\n",
      "Epoch 9/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11801173.5996 - val_loss: 11342427.0000\n",
      "Epoch 10/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12120615.9248 - val_loss: 11796469.0000\n",
      "Epoch 11/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11571138.5094 - val_loss: 10412118.0000\n",
      "Epoch 12/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12040042.0169 - val_loss: 10751299.0000\n",
      "Epoch 13/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11632750.4417 - val_loss: 10750070.0000\n",
      "Epoch 14/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11474641.8139 - val_loss: 10703653.0000\n",
      "Epoch 15/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11989713.3045 - val_loss: 12478631.0000\n",
      "Epoch 16/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11506069.6015 - val_loss: 11001495.0000\n",
      "Epoch 17/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11249936.8102 - val_loss: 11062551.0000\n",
      "Epoch 18/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11211291.2303 - val_loss: 11185923.0000\n",
      "Epoch 19/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12314420.5639 - val_loss: 11813179.0000\n",
      "Epoch 20/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10992443.6814 - val_loss: 12311269.0000\n",
      "Epoch 21/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11402662.0733 - val_loss: 11034491.0000\n",
      "Epoch 22/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12078200.0320 - val_loss: 10733403.0000\n",
      "Epoch 23/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11646203.2744 - val_loss: 11708972.0000\n",
      "Epoch 24/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11061954.9267 - val_loss: 13294723.0000\n",
      "Epoch 25/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11828744.0395 - val_loss: 10395822.0000\n",
      "Epoch 26/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10962736.0019 - val_loss: 12540437.0000\n",
      "Epoch 27/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12269244.1729 - val_loss: 11438102.0000\n",
      "Epoch 28/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11662813.7500 - val_loss: 10587529.0000\n",
      "Epoch 29/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11185905.5489 - val_loss: 10891585.0000\n",
      "Epoch 30/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11538342.5761 - val_loss: 11384233.0000\n",
      "Epoch 31/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11352316.8759 - val_loss: 10705778.0000\n",
      "Epoch 32/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11650773.5461 - val_loss: 10957397.0000\n",
      "Epoch 33/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11389670.5930 - val_loss: 11117928.0000\n",
      "Epoch 34/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11600356.0432 - val_loss: 10878153.0000\n",
      "Epoch 35/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11564646.2509 - val_loss: 12316833.0000\n",
      "Epoch 36/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11709012.0752 - val_loss: 10761683.0000\n",
      "Epoch 37/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10998638.7472 - val_loss: 11613725.0000\n",
      "Epoch 38/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11692551.4286 - val_loss: 11637194.0000\n",
      "Epoch 39/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11598437.5113 - val_loss: 12916861.0000\n",
      "Epoch 40/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12000677.9492 - val_loss: 10723499.0000\n",
      "Epoch 41/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11496355.2594 - val_loss: 11978584.0000\n",
      "Epoch 42/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11871379.5470 - val_loss: 11512993.0000\n",
      "Epoch 43/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11457627.3421 - val_loss: 11942137.0000\n",
      "Epoch 44/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11561237.0738 - val_loss: 11452162.0000\n",
      "Epoch 45/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12005946.5808 - val_loss: 11870576.0000\n",
      "Epoch 46/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11526529.7453 - val_loss: 11681534.0000\n",
      "Epoch 47/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11495018.1071 - val_loss: 11229199.0000\n",
      "Epoch 48/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11296762.5564 - val_loss: 13838552.0000\n",
      "Epoch 49/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 12688237.5094 - val_loss: 10562972.0000\n",
      "Epoch 50/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11158753.8195 - val_loss: 11048916.0000\n",
      "Epoch 51/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11779433.5545 - val_loss: 12647661.0000\n",
      "Epoch 52/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12089226.3515 - val_loss: 10836973.0000\n",
      "Epoch 53/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10684134.9991 - val_loss: 10630607.0000\n",
      "Epoch 54/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11704625.0160 - val_loss: 11419200.0000\n",
      "Epoch 55/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 12068678.0695 - val_loss: 15080056.0000\n",
      "Epoch 56/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 12210154.6692 - val_loss: 10740498.0000\n",
      "Epoch 57/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10874614.5808 - val_loss: 11804661.0000\n",
      "Epoch 58/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11819549.4662 - val_loss: 11450692.0000\n",
      "Epoch 59/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11307761.3008 - val_loss: 10659295.0000\n",
      "Epoch 60/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11129796.7115 - val_loss: 10662027.0000\n",
      "Epoch 61/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11872710.1128 - val_loss: 11082684.0000\n",
      "Epoch 62/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 12271391.8741 - val_loss: 15520609.0000\n",
      "Epoch 63/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11874675.5320 - val_loss: 10832466.0000\n",
      "Epoch 64/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11221699.6391 - val_loss: 11220774.0000\n",
      "Epoch 65/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12137136.1100 - val_loss: 11959264.0000\n",
      "Epoch 66/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11365926.7613 - val_loss: 10746846.0000\n",
      "Epoch 67/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11784460.9192 - val_loss: 11085459.0000\n",
      "Epoch 68/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12639035.2481 - val_loss: 11353248.0000\n",
      "Epoch 69/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11401824.7209 - val_loss: 11100738.0000\n",
      "Epoch 70/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11672235.1621 - val_loss: 10620778.0000\n",
      "Epoch 71/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11938161.2782 - val_loss: 11277981.0000\n",
      "Epoch 72/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12017332.0150 - val_loss: 11699505.0000\n",
      "Epoch 73/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 12175661.8722 - val_loss: 11398650.0000\n",
      "Epoch 74/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11633304.3966 - val_loss: 10854037.0000\n",
      "Epoch 75/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10875228.8957 - val_loss: 10905746.0000\n",
      "Epoch 76/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11970407.2688 - val_loss: 12562348.0000\n",
      "Epoch 77/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12241995.4699 - val_loss: 11613162.0000\n",
      "Epoch 78/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12057784.3139 - val_loss: 11638496.0000\n",
      "Epoch 79/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12395879.1560 - val_loss: 11830826.0000\n",
      "Epoch 80/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11397694.4793 - val_loss: 11170502.0000\n",
      "Epoch 81/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11416693.4615 - val_loss: 10562899.0000\n",
      "Epoch 82/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11730177.7989 - val_loss: 10728437.0000\n",
      "Epoch 83/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11072740.2444 - val_loss: 11359351.0000\n",
      "Epoch 84/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12178435.4023 - val_loss: 10921087.0000\n",
      "Epoch 85/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11645880.7293 - val_loss: 10739903.0000\n",
      "Epoch 86/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12187595.3496 - val_loss: 10482488.0000\n",
      "Epoch 87/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11420122.5996 - val_loss: 11695004.0000\n",
      "Epoch 88/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11803049.7951 - val_loss: 11991892.0000\n",
      "Epoch 89/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11517902.9098 - val_loss: 10566378.0000\n",
      "Epoch 90/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11910733.7209 - val_loss: 11464279.0000\n",
      "Epoch 91/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11553099.6466 - val_loss: 11237311.0000\n",
      "Epoch 92/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11269364.0000 - val_loss: 10634576.0000\n",
      "Epoch 93/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11516860.6090 - val_loss: 10534845.0000\n",
      "Epoch 94/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11101111.8346 - val_loss: 11612142.0000\n",
      "Epoch 95/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11117367.5244 - val_loss: 10926469.0000\n",
      "Epoch 96/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11245264.8102 - val_loss: 11496779.0000\n",
      "Epoch 97/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11172453.5385 - val_loss: 10360410.0000\n",
      "Epoch 98/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11888354.5113 - val_loss: 11311474.0000\n",
      "Epoch 99/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11087992.9267 - val_loss: 10817590.0000\n",
      "Epoch 100/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11874265.6767 - val_loss: 10435067.0000\n",
      "Epoch 101/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11736869.4023 - val_loss: 10795144.0000\n",
      "Epoch 102/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10969956.3609 - val_loss: 10435470.0000\n",
      "Epoch 103/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11414272.3731 - val_loss: 11517637.0000\n",
      "Epoch 104/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12043536.1570 - val_loss: 11133666.0000\n",
      "Epoch 105/200\n",
      "531/531 [==============================] - 3s 7ms/step - loss: 11773414.2688 - val_loss: 10534955.0000\n",
      "Epoch 106/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11721618.8177 - val_loss: 11009174.0000\n",
      "Epoch 107/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11105190.2970 - val_loss: 11363489.0000\n",
      "Epoch 108/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11583639.7650 - val_loss: 10701913.0000\n",
      "Epoch 109/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11640888.7246 - val_loss: 10629255.0000\n",
      "Epoch 110/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11392240.9267 - val_loss: 11681806.0000\n",
      "Epoch 111/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 12156690.7500 - val_loss: 10688204.0000\n",
      "Epoch 112/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11280885.4624 - val_loss: 16110841.0000\n",
      "Epoch 113/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 12926756.5827 - val_loss: 11170311.0000\n",
      "Epoch 114/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11791335.1165 - val_loss: 10992287.0000\n",
      "Epoch 115/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11774399.2331 - val_loss: 12557326.0000\n",
      "Epoch 116/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11214029.1598 - val_loss: 10782940.0000\n",
      "Epoch 117/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12062768.4492 - val_loss: 12827192.0000\n",
      "Epoch 118/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11402637.5489 - val_loss: 15807952.0000\n",
      "Epoch 119/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11773512.1560 - val_loss: 10697101.0000\n",
      "Epoch 120/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11184433.7086 - val_loss: 10890858.0000\n",
      "Epoch 121/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11176382.1278 - val_loss: 10910922.0000\n",
      "Epoch 122/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11373273.2190 - val_loss: 10861048.0000\n",
      "Epoch 123/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11044386.8271 - val_loss: 11342245.0000\n",
      "Epoch 124/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11400270.2368 - val_loss: 11234309.0000\n",
      "Epoch 125/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11058062.7970 - val_loss: 11669074.0000\n",
      "Epoch 126/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11479111.1316 - val_loss: 10565692.0000\n",
      "Epoch 127/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11921089.3919 - val_loss: 11480870.0000\n",
      "Epoch 128/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11330546.0395 - val_loss: 11018330.0000\n",
      "Epoch 129/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11342222.2462 - val_loss: 10444737.0000\n",
      "Epoch 130/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11471083.9718 - val_loss: 12005783.0000\n",
      "Epoch 131/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11682105.7895 - val_loss: 16186140.0000\n",
      "Epoch 132/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11564419.7707 - val_loss: 11217374.0000\n",
      "Epoch 133/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10913545.4436 - val_loss: 10732497.0000\n",
      "Epoch 134/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11101797.5780 - val_loss: 10542800.0000\n",
      "Epoch 135/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11687149.6870 - val_loss: 12721731.0000\n",
      "Epoch 136/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11066674.0282 - val_loss: 10701388.0000\n",
      "Epoch 137/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11563992.8759 - val_loss: 10339211.0000\n",
      "Epoch 138/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11948163.6090 - val_loss: 12276223.0000\n",
      "Epoch 139/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11064452.4079 - val_loss: 11495184.0000\n",
      "Epoch 140/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11223036.0564 - val_loss: 12565191.0000\n",
      "Epoch 141/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11243866.7180 - val_loss: 10587713.0000\n",
      "Epoch 142/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11049680.0733 - val_loss: 10416361.0000\n",
      "Epoch 143/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10992084.2068 - val_loss: 12203289.0000\n",
      "Epoch 144/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11683299.8327 - val_loss: 12211707.0000\n",
      "Epoch 145/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12224644.6372 - val_loss: 11695018.0000\n",
      "Epoch 146/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11806188.7726 - val_loss: 10588617.0000\n",
      "Epoch 147/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11064052.3327 - val_loss: 11093899.0000\n",
      "Epoch 148/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11486123.8346 - val_loss: 13335079.0000\n",
      "Epoch 149/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12199697.8534 - val_loss: 10768000.0000\n",
      "Epoch 150/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11374309.5188 - val_loss: 13921880.0000\n",
      "Epoch 151/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11947481.5301 - val_loss: 10649764.0000\n",
      "Epoch 152/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10948171.2378 - val_loss: 10356851.0000\n",
      "Epoch 153/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11073412.3440 - val_loss: 10375541.0000\n",
      "Epoch 154/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12242001.6617 - val_loss: 10593011.0000\n",
      "Epoch 155/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10923394.3534 - val_loss: 13186240.0000\n",
      "Epoch 156/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11090670.1278 - val_loss: 12503525.0000\n",
      "Epoch 157/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11535798.1579 - val_loss: 10850537.0000\n",
      "Epoch 158/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12052652.6429 - val_loss: 11590642.0000\n",
      "Epoch 159/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11596558.6015 - val_loss: 10810240.0000\n",
      "Epoch 160/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11370260.0338 - val_loss: 10656143.0000\n",
      "Epoch 161/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11240901.5526 - val_loss: 10523136.0000\n",
      "Epoch 162/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11076892.5508 - val_loss: 12968565.0000\n",
      "Epoch 163/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12333373.2744 - val_loss: 11372186.0000\n",
      "Epoch 164/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11725213.0573 - val_loss: 11534331.0000\n",
      "Epoch 165/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11083018.4737 - val_loss: 10722666.0000\n",
      "Epoch 166/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10925481.6955 - val_loss: 11058651.0000\n",
      "Epoch 167/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11174764.2331 - val_loss: 11404210.0000\n",
      "Epoch 168/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11469921.2434 - val_loss: 11897916.0000\n",
      "Epoch 169/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11597014.8543 - val_loss: 10864470.0000\n",
      "Epoch 170/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11653945.8205 - val_loss: 11964457.0000\n",
      "Epoch 171/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11127573.7199 - val_loss: 12659711.0000\n",
      "Epoch 172/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10818526.4662 - val_loss: 10727124.0000\n",
      "Epoch 173/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11670547.8534 - val_loss: 10826902.0000\n",
      "Epoch 174/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11819765.2556 - val_loss: 11020360.0000\n",
      "Epoch 175/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11193144.0479 - val_loss: 12224229.0000\n",
      "Epoch 176/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12083637.6466 - val_loss: 10454345.0000\n",
      "Epoch 177/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 12397557.8252 - val_loss: 10555791.0000\n",
      "Epoch 178/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11336965.3383 - val_loss: 10883739.0000\n",
      "Epoch 179/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11955901.5282 - val_loss: 10489354.0000\n",
      "Epoch 180/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10703845.7820 - val_loss: 12952468.0000\n",
      "Epoch 181/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11124617.0310 - val_loss: 11118823.0000\n",
      "Epoch 182/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11370592.7613 - val_loss: 10805514.0000\n",
      "Epoch 183/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11181078.7368 - val_loss: 11289146.0000\n",
      "Epoch 184/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11766979.4624 - val_loss: 10500943.0000\n",
      "Epoch 185/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11164468.2824 - val_loss: 10971798.0000\n",
      "Epoch 186/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11263338.1363 - val_loss: 10362123.0000\n",
      "Epoch 187/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11227781.1269 - val_loss: 10701055.0000\n",
      "Epoch 188/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10650867.9577 - val_loss: 10306446.0000\n",
      "Epoch 189/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11313668.7190 - val_loss: 12270143.0000\n",
      "Epoch 190/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11727525.9286 - val_loss: 10278162.0000\n",
      "Epoch 191/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11392486.0113 - val_loss: 10708195.0000\n",
      "Epoch 192/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11442422.9826 - val_loss: 11580239.0000\n",
      "Epoch 193/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11417864.2180 - val_loss: 12108873.0000\n",
      "Epoch 194/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11070879.9135 - val_loss: 13150396.0000\n",
      "Epoch 195/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11539236.1147 - val_loss: 12674559.0000\n",
      "Epoch 196/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11030753.8769 - val_loss: 12597967.0000\n",
      "Epoch 197/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12117331.6617 - val_loss: 11886334.0000\n",
      "Epoch 198/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11228491.4098 - val_loss: 10982683.0000\n",
      "Epoch 199/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11953862.3524 - val_loss: 10371594.0000\n",
      "Epoch 200/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11235751.1372 - val_loss: 11054039.0000\n",
      "Epoch 1/200\n",
      "531/531 [==============================] - 4s 6ms/step - loss: 10605202.9445 - val_loss: 12259196.0000\n",
      "Epoch 2/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11083837.1617 - val_loss: 11832587.0000\n",
      "Epoch 3/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11248738.4126 - val_loss: 10411245.0000\n",
      "Epoch 4/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11069648.8703 - val_loss: 10981483.0000\n",
      "Epoch 5/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12421535.1936 - val_loss: 11066608.0000\n",
      "Epoch 6/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11827224.7265 - val_loss: 12236156.0000\n",
      "Epoch 7/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10710729.8477 - val_loss: 11948291.0000\n",
      "Epoch 8/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11704600.8985 - val_loss: 11413718.0000\n",
      "Epoch 9/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11522848.8665 - val_loss: 10356662.0000\n",
      "Epoch 10/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11411367.3252 - val_loss: 10514877.0000\n",
      "Epoch 11/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12376590.1617 - val_loss: 10945584.0000\n",
      "Epoch 12/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10877512.4182 - val_loss: 11866270.0000\n",
      "Epoch 13/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11206982.2556 - val_loss: 10555712.0000\n",
      "Epoch 14/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11777391.0940 - val_loss: 11158654.0000\n",
      "Epoch 15/200\n",
      "531/531 [==============================] - 3s 7ms/step - loss: 11674689.5451 - val_loss: 10323122.0000\n",
      "Epoch 16/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11487755.9558 - val_loss: 10289371.0000\n",
      "Epoch 17/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10730820.7923 - val_loss: 12673796.0000\n",
      "Epoch 18/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11655621.8421 - val_loss: 10432892.0000\n",
      "Epoch 19/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 10971094.1297 - val_loss: 11455500.0000\n",
      "Epoch 20/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11259668.1917 - val_loss: 11170869.0000\n",
      "Epoch 21/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11555147.0583 - val_loss: 10512375.0000\n",
      "Epoch 22/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11094222.1466 - val_loss: 10694363.0000\n",
      "Epoch 23/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11738589.9305 - val_loss: 10733010.0000\n",
      "Epoch 24/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11375204.6485 - val_loss: 10326597.0000\n",
      "Epoch 25/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11204361.5367 - val_loss: 13190375.0000\n",
      "Epoch 26/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 10988357.9286 - val_loss: 15607628.0000\n",
      "Epoch 27/200\n",
      "531/531 [==============================] - 4s 7ms/step - loss: 11402055.2331 - val_loss: 13038217.0000\n",
      "Epoch 28/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11862815.9361 - val_loss: 10303934.0000\n",
      "Epoch 29/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11890909.3252 - val_loss: 10457957.0000\n",
      "Epoch 30/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11541301.1964 - val_loss: 11317918.0000\n",
      "Epoch 31/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11517538.5075 - val_loss: 11468063.0000\n",
      "Epoch 32/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11741559.5677 - val_loss: 10926714.0000\n",
      "Epoch 33/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10990945.6363 - val_loss: 11335771.0000\n",
      "Epoch 34/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11018809.5977 - val_loss: 10907530.0000\n",
      "Epoch 35/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 10988903.5639 - val_loss: 10584984.0000\n",
      "Epoch 36/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10847172.2162 - val_loss: 10927129.0000\n",
      "Epoch 37/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11641190.5940 - val_loss: 12140195.0000\n",
      "Epoch 38/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11590643.7143 - val_loss: 11068270.0000\n",
      "Epoch 39/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11504159.4605 - val_loss: 10530330.0000\n",
      "Epoch 40/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11274118.0329 - val_loss: 10399517.0000\n",
      "Epoch 41/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11298055.9023 - val_loss: 11699748.0000\n",
      "Epoch 42/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11152045.0545 - val_loss: 10748445.0000\n",
      "Epoch 43/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10758087.4812 - val_loss: 11803961.0000\n",
      "Epoch 44/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11572610.2838 - val_loss: 11345199.0000\n",
      "Epoch 45/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11308598.8534 - val_loss: 11506373.0000\n",
      "Epoch 46/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11353197.2632 - val_loss: 14343789.0000\n",
      "Epoch 47/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 10690958.4962 - val_loss: 11540979.0000\n",
      "Epoch 48/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11465705.5113 - val_loss: 11178602.0000\n",
      "Epoch 49/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11203578.8647 - val_loss: 10281517.0000\n",
      "Epoch 50/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11828993.5244 - val_loss: 10867100.0000\n",
      "Epoch 51/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11278543.1043 - val_loss: 10393619.0000\n",
      "Epoch 52/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11005122.7509 - val_loss: 11934755.0000\n",
      "Epoch 53/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11351485.9605 - val_loss: 11224015.0000\n",
      "Epoch 54/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11025836.4286 - val_loss: 11189404.0000\n",
      "Epoch 55/200\n",
      "531/531 [==============================] - 4s 7ms/step - loss: 11590470.0780 - val_loss: 10803597.0000\n",
      "Epoch 56/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11323911.1992 - val_loss: 15160362.0000\n",
      "Epoch 57/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11715710.3308 - val_loss: 10528757.0000\n",
      "Epoch 58/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11900093.8393 - val_loss: 10999359.0000\n",
      "Epoch 59/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11275151.4859 - val_loss: 12663141.0000\n",
      "Epoch 60/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11078329.0263 - val_loss: 11987974.0000\n",
      "Epoch 61/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11549152.7444 - val_loss: 10365022.0000\n",
      "Epoch 62/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 11315359.3383 - val_loss: 13010278.0000\n",
      "Epoch 63/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11098002.0874 - val_loss: 10981987.0000\n",
      "Epoch 64/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11351447.2885 - val_loss: 12408066.0000\n",
      "Epoch 65/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10907469.0639 - val_loss: 12885244.0000\n",
      "Epoch 66/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11965845.5244 - val_loss: 11139946.0000\n",
      "Epoch 67/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10623833.6936 - val_loss: 11250993.0000\n",
      "Epoch 68/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11591641.8816 - val_loss: 10381750.0000\n",
      "Epoch 69/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11417993.4925 - val_loss: 10716015.0000\n",
      "Epoch 70/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11363239.5714 - val_loss: 11464031.0000\n",
      "Epoch 71/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11064710.3703 - val_loss: 10680594.0000\n",
      "Epoch 72/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10530087.3449 - val_loss: 14492435.0000\n",
      "Epoch 73/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11870094.6955 - val_loss: 12900319.0000\n",
      "Epoch 74/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11675961.8966 - val_loss: 10388950.0000\n",
      "Epoch 75/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10707399.6776 - val_loss: 11820024.0000\n",
      "Epoch 76/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11279267.8440 - val_loss: 22758688.0000\n",
      "Epoch 77/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11415076.6071 - val_loss: 10278536.0000\n",
      "Epoch 78/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11393520.4652 - val_loss: 14832185.0000\n",
      "Epoch 79/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12261611.6579 - val_loss: 10300332.0000\n",
      "Epoch 80/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11523894.7575 - val_loss: 12609366.0000\n",
      "Epoch 81/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11728914.7284 - val_loss: 10340667.0000\n",
      "Epoch 82/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 12062993.2180 - val_loss: 10357335.0000\n",
      "Epoch 83/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10817327.1128 - val_loss: 10725119.0000\n",
      "Epoch 84/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11275059.8440 - val_loss: 11917612.0000\n",
      "Epoch 85/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11050988.9173 - val_loss: 10606501.0000\n",
      "Epoch 86/200\n",
      "531/531 [==============================] - 4s 7ms/step - loss: 11437309.4831 - val_loss: 10617733.0000\n",
      "Epoch 87/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11340979.0705 - val_loss: 10496252.0000\n",
      "Epoch 88/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11566485.6071 - val_loss: 10926586.0000\n",
      "Epoch 89/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11004081.8966 - val_loss: 10772609.0000\n",
      "Epoch 90/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10969087.3177 - val_loss: 10409147.0000\n",
      "Epoch 91/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10794750.6541 - val_loss: 12154704.0000\n",
      "Epoch 92/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11525274.5498 - val_loss: 13000221.0000\n",
      "Epoch 93/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11440499.0395 - val_loss: 10320534.0000\n",
      "Epoch 94/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11361276.9699 - val_loss: 10842267.0000\n",
      "Epoch 95/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10796504.6974 - val_loss: 11766532.0000\n",
      "Epoch 96/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10874307.9586 - val_loss: 15249685.0000\n",
      "Epoch 97/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12502222.0376 - val_loss: 10712184.0000\n",
      "Epoch 98/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11657521.1485 - val_loss: 12330836.0000\n",
      "Epoch 99/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11467741.8853 - val_loss: 10460244.0000\n",
      "Epoch 100/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10490032.9765 - val_loss: 10940315.0000\n",
      "Epoch 101/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11015318.9549 - val_loss: 10508773.0000\n",
      "Epoch 102/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11588382.4314 - val_loss: 11479362.0000\n",
      "Epoch 103/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11658073.4474 - val_loss: 10432306.0000\n",
      "Epoch 104/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11179166.1974 - val_loss: 10738562.0000\n",
      "Epoch 105/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11529437.3647 - val_loss: 11426949.0000\n",
      "Epoch 106/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11417960.1579 - val_loss: 12314366.0000\n",
      "Epoch 107/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11001529.2030 - val_loss: 10382661.0000\n",
      "Epoch 108/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10589110.1071 - val_loss: 10294930.0000\n",
      "Epoch 109/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11044169.3177 - val_loss: 11477894.0000\n",
      "Epoch 110/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11761047.2039 - val_loss: 11716029.0000\n",
      "Epoch 111/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11450889.8421 - val_loss: 10226819.0000\n",
      "Epoch 112/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10523020.4586 - val_loss: 10969455.0000\n",
      "Epoch 113/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11871598.0677 - val_loss: 10528573.0000\n",
      "Epoch 114/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11447857.1212 - val_loss: 10481676.0000\n",
      "Epoch 115/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10993684.3929 - val_loss: 11175606.0000\n",
      "Epoch 116/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10657634.6786 - val_loss: 10407343.0000\n",
      "Epoch 117/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11291838.1410 - val_loss: 11895665.0000\n",
      "Epoch 118/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11662385.9041 - val_loss: 11185878.0000\n",
      "Epoch 119/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10758246.7867 - val_loss: 10919009.0000\n",
      "Epoch 120/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11043010.4004 - val_loss: 10712516.0000\n",
      "Epoch 121/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11212767.2039 - val_loss: 10389656.0000\n",
      "Epoch 122/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10677103.0930 - val_loss: 11461070.0000\n",
      "Epoch 123/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 12287145.5357 - val_loss: 10978149.0000\n",
      "Epoch 124/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10595985.8092 - val_loss: 12707465.0000\n",
      "Epoch 125/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11053883.9333 - val_loss: 11062659.0000\n",
      "Epoch 126/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11802822.7914 - val_loss: 10553733.0000\n",
      "Epoch 127/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11297505.0836 - val_loss: 15065148.0000\n",
      "Epoch 128/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11090012.5940 - val_loss: 13440071.0000\n",
      "Epoch 129/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10943579.6476 - val_loss: 10848940.0000\n",
      "Epoch 130/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11300300.8459 - val_loss: 10580960.0000\n",
      "Epoch 131/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11106005.4314 - val_loss: 11434251.0000\n",
      "Epoch 132/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11651197.5977 - val_loss: 11838026.0000\n",
      "Epoch 133/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11087267.9906 - val_loss: 10676446.0000\n",
      "Epoch 134/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11268478.7039 - val_loss: 10483682.0000\n",
      "Epoch 135/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11431005.6034 - val_loss: 11095602.0000\n",
      "Epoch 136/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11146061.9859 - val_loss: 11529183.0000\n",
      "Epoch 137/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10693898.3383 - val_loss: 10439131.0000\n",
      "Epoch 138/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10926961.2707 - val_loss: 10455180.0000\n",
      "Epoch 139/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10890360.1570 - val_loss: 10710833.0000\n",
      "Epoch 140/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11017960.0188 - val_loss: 11067822.0000\n",
      "Epoch 141/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11372478.3233 - val_loss: 11038327.0000\n",
      "Epoch 142/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10768509.8665 - val_loss: 10396687.0000\n",
      "Epoch 143/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10651705.7049 - val_loss: 10736200.0000\n",
      "Epoch 144/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11885564.7989 - val_loss: 12910555.0000\n",
      "Epoch 145/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11256446.2914 - val_loss: 11316508.0000\n",
      "Epoch 146/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11033679.1071 - val_loss: 11606297.0000\n",
      "Epoch 147/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11180383.7481 - val_loss: 12407025.0000\n",
      "Epoch 148/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11339212.7274 - val_loss: 10940024.0000\n",
      "Epoch 149/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10218132.8571 - val_loss: 10904843.0000\n",
      "Epoch 150/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10834508.8788 - val_loss: 10603280.0000\n",
      "Epoch 151/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11391353.7289 - val_loss: 11317714.0000\n",
      "Epoch 152/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10779160.0968 - val_loss: 10625060.0000\n",
      "Epoch 153/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11137000.2763 - val_loss: 13247922.0000\n",
      "Epoch 154/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11168844.5940 - val_loss: 10387886.0000\n",
      "Epoch 155/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11200655.5611 - val_loss: 11969432.0000\n",
      "Epoch 156/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11430291.9154 - val_loss: 10917097.0000\n",
      "Epoch 157/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11067257.1870 - val_loss: 10348277.0000\n",
      "Epoch 158/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11235243.2707 - val_loss: 11346017.0000\n",
      "Epoch 159/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11153242.7650 - val_loss: 10511632.0000\n",
      "Epoch 160/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11118541.2528 - val_loss: 10437520.0000\n",
      "Epoch 161/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11082649.1128 - val_loss: 10696030.0000\n",
      "Epoch 162/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11195626.1974 - val_loss: 11469607.0000\n",
      "Epoch 163/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11446032.0545 - val_loss: 10658899.0000\n",
      "Epoch 164/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11209909.1269 - val_loss: 10606375.0000\n",
      "Epoch 165/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11321531.5977 - val_loss: 11537256.0000\n",
      "Epoch 166/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10863781.9774 - val_loss: 11003020.0000\n",
      "Epoch 167/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11215325.4380 - val_loss: 11355686.0000\n",
      "Epoch 168/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11492770.1541 - val_loss: 10334689.0000\n",
      "Epoch 169/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10353007.5075 - val_loss: 10317401.0000\n",
      "Epoch 170/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10866921.8383 - val_loss: 11472522.0000\n",
      "Epoch 171/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11137698.2951 - val_loss: 10675835.0000\n",
      "Epoch 172/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10821113.0648 - val_loss: 10919671.0000\n",
      "Epoch 173/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11631516.0658 - val_loss: 13216845.0000\n",
      "Epoch 174/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10421190.4004 - val_loss: 13032754.0000\n",
      "Epoch 175/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10809355.2462 - val_loss: 10582783.0000\n",
      "Epoch 176/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10835542.0150 - val_loss: 12573066.0000\n",
      "Epoch 177/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10907661.0883 - val_loss: 11827330.0000\n",
      "Epoch 178/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11578077.0771 - val_loss: 14476831.0000\n",
      "Epoch 179/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11642823.3609 - val_loss: 10932389.0000\n",
      "Epoch 180/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10909092.8083 - val_loss: 10347809.0000\n",
      "Epoch 181/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10678086.8712 - val_loss: 11019055.0000\n",
      "Epoch 182/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11227711.3158 - val_loss: 10347897.0000\n",
      "Epoch 183/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11105021.4558 - val_loss: 10591254.0000\n",
      "Epoch 184/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10612312.0103 - val_loss: 12953240.0000\n",
      "Epoch 185/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12107859.9793 - val_loss: 10514694.0000\n",
      "Epoch 186/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10700679.3064 - val_loss: 10533732.0000\n",
      "Epoch 187/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10299051.2904 - val_loss: 10946064.0000\n",
      "Epoch 188/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11104831.1936 - val_loss: 11178901.0000\n",
      "Epoch 189/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10808052.9117 - val_loss: 10897731.0000\n",
      "Epoch 190/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11667370.5244 - val_loss: 11241954.0000\n",
      "Epoch 191/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11448923.6241 - val_loss: 10304258.0000\n",
      "Epoch 192/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11369046.5508 - val_loss: 10967008.0000\n",
      "Epoch 193/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10727619.9643 - val_loss: 11460809.0000\n",
      "Epoch 194/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10882046.4239 - val_loss: 10531205.0000\n",
      "Epoch 195/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10865249.7838 - val_loss: 10514554.0000\n",
      "Epoch 196/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10859798.6363 - val_loss: 11470201.0000\n",
      "Epoch 197/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11043095.1410 - val_loss: 11545915.0000\n",
      "Epoch 198/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10380198.6259 - val_loss: 11317515.0000\n",
      "Epoch 199/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11501787.0226 - val_loss: 10504852.0000\n",
      "Epoch 200/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11193061.6626 - val_loss: 11091101.0000\n",
      "Epoch 1/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10699093.1034 - val_loss: 10801609.0000\n",
      "Epoch 2/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11017375.8440 - val_loss: 10615948.0000\n",
      "Epoch 3/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11092443.1805 - val_loss: 10907581.0000\n",
      "Epoch 4/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11111794.5564 - val_loss: 11174974.0000\n",
      "Epoch 5/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10994087.8055 - val_loss: 11245728.0000\n",
      "Epoch 6/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10995857.7387 - val_loss: 10459621.0000\n",
      "Epoch 7/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10183749.9699 - val_loss: 10643259.0000\n",
      "Epoch 8/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10769417.2650 - val_loss: 10401262.0000\n",
      "Epoch 9/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11624796.0658 - val_loss: 10800177.0000\n",
      "Epoch 10/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10868807.2848 - val_loss: 10588277.0000\n",
      "Epoch 11/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11158647.8346 - val_loss: 11939490.0000\n",
      "Epoch 12/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10824168.5686 - val_loss: 12196290.0000\n",
      "Epoch 13/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11564884.9004 - val_loss: 11823254.0000\n",
      "Epoch 14/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10826751.1513 - val_loss: 10592025.0000\n",
      "Epoch 15/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11032541.3806 - val_loss: 10787670.0000\n",
      "Epoch 16/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11046385.9958 - val_loss: 12242908.0000\n",
      "Epoch 17/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11471702.4192 - val_loss: 10467767.0000\n",
      "Epoch 18/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10589082.2932 - val_loss: 10692146.0000\n",
      "Epoch 19/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10766848.0273 - val_loss: 11077012.0000\n",
      "Epoch 20/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10745668.0602 - val_loss: 10699028.0000\n",
      "Epoch 21/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10904900.8383 - val_loss: 11073394.0000\n",
      "Epoch 22/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11212851.8026 - val_loss: 10784417.0000\n",
      "Epoch 23/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11052737.9060 - val_loss: 10445776.0000\n",
      "Epoch 24/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10403188.3233 - val_loss: 11816759.0000\n",
      "Epoch 25/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10910147.1523 - val_loss: 10402313.0000\n",
      "Epoch 26/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10382193.8205 - val_loss: 11016754.0000\n",
      "Epoch 27/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11260826.9229 - val_loss: 11211671.0000\n",
      "Epoch 28/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10735947.1682 - val_loss: 11438947.0000\n",
      "Epoch 29/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10268289.7820 - val_loss: 10606719.0000\n",
      "Epoch 30/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11072184.1786 - val_loss: 10559959.0000\n",
      "Epoch 31/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10733036.9962 - val_loss: 10465605.0000\n",
      "Epoch 32/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10960895.6612 - val_loss: 11202575.0000\n",
      "Epoch 33/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10995757.3571 - val_loss: 12524629.0000\n",
      "Epoch 34/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10893654.4605 - val_loss: 10914917.0000\n",
      "Epoch 35/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10797094.8026 - val_loss: 10479519.0000\n",
      "Epoch 36/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10693881.7951 - val_loss: 11233955.0000\n",
      "Epoch 37/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11653703.9117 - val_loss: 10670015.0000\n",
      "Epoch 38/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10834000.0489 - val_loss: 10948055.0000\n",
      "Epoch 39/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11197756.3675 - val_loss: 12456805.0000\n",
      "Epoch 40/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 12118055.8083 - val_loss: 10446726.0000\n",
      "Epoch 41/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10859461.7998 - val_loss: 10322385.0000\n",
      "Epoch 42/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10526409.3205 - val_loss: 11237199.0000\n",
      "Epoch 43/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10949496.5630 - val_loss: 11052714.0000\n",
      "Epoch 44/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11312550.4455 - val_loss: 10673628.0000\n",
      "Epoch 45/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10736595.6109 - val_loss: 10513446.0000\n",
      "Epoch 46/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10790093.2885 - val_loss: 10486646.0000\n",
      "Epoch 47/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11229828.1297 - val_loss: 10577172.0000\n",
      "Epoch 48/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11256894.0376 - val_loss: 10676020.0000\n",
      "Epoch 49/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11014453.2914 - val_loss: 10487006.0000\n",
      "Epoch 50/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10626782.9417 - val_loss: 11256200.0000\n",
      "Epoch 51/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11319628.2105 - val_loss: 10403597.0000\n",
      "Epoch 52/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10912840.4699 - val_loss: 10731988.0000\n",
      "Epoch 53/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10772423.2951 - val_loss: 11434599.0000\n",
      "Epoch 54/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11192840.7068 - val_loss: 10719643.0000\n",
      "Epoch 55/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11142117.1833 - val_loss: 10865567.0000\n",
      "Epoch 56/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10843393.1353 - val_loss: 11049084.0000\n",
      "Epoch 57/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11577335.2030 - val_loss: 10428339.0000\n",
      "Epoch 58/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11070449.9455 - val_loss: 13269083.0000\n",
      "Epoch 59/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11144430.7068 - val_loss: 11021913.0000\n",
      "Epoch 60/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11271362.8900 - val_loss: 10970778.0000\n",
      "Epoch 61/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10681834.9182 - val_loss: 10453376.0000\n",
      "Epoch 62/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10637891.5780 - val_loss: 10890120.0000\n",
      "Epoch 63/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10823374.2538 - val_loss: 10981639.0000\n",
      "Epoch 64/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11074679.1053 - val_loss: 10796467.0000\n",
      "Epoch 65/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10609347.4972 - val_loss: 10489012.0000\n",
      "Epoch 66/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11125641.0310 - val_loss: 10562612.0000\n",
      "Epoch 67/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10701570.7744 - val_loss: 10348974.0000\n",
      "Epoch 68/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11388961.1165 - val_loss: 11087406.0000\n",
      "Epoch 69/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10961069.0470 - val_loss: 10504256.0000\n",
      "Epoch 70/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10904398.5827 - val_loss: 10412191.0000\n",
      "Epoch 71/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10989940.2274 - val_loss: 11119469.0000\n",
      "Epoch 72/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11408386.1729 - val_loss: 11016539.0000\n",
      "Epoch 73/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11665553.2105 - val_loss: 11193910.0000\n",
      "Epoch 74/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10842234.2086 - val_loss: 11464425.0000\n",
      "Epoch 75/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10744049.9211 - val_loss: 12041423.0000\n",
      "Epoch 76/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10674640.5301 - val_loss: 11108746.0000\n",
      "Epoch 77/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10685850.3985 - val_loss: 14685114.0000\n",
      "Epoch 78/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11471416.8271 - val_loss: 10421216.0000\n",
      "Epoch 79/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11100619.5808 - val_loss: 10482919.0000\n",
      "Epoch 80/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11110965.3144 - val_loss: 10490379.0000\n",
      "Epoch 81/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10555483.6053 - val_loss: 10380383.0000\n",
      "Epoch 82/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11024874.2528 - val_loss: 10943347.0000\n",
      "Epoch 83/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11384508.2848 - val_loss: 10442391.0000\n",
      "Epoch 84/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11271462.4323 - val_loss: 11358238.0000\n",
      "Epoch 85/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11268816.1485 - val_loss: 10587689.0000\n",
      "Epoch 86/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10450060.6861 - val_loss: 10830858.0000\n",
      "Epoch 87/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11119029.3694 - val_loss: 10367220.0000\n",
      "Epoch 88/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10960787.8440 - val_loss: 10661028.0000\n",
      "Epoch 89/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11224112.8346 - val_loss: 11348235.0000\n",
      "Epoch 90/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10758618.3440 - val_loss: 11326722.0000\n",
      "Epoch 91/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10615595.2782 - val_loss: 10766262.0000\n",
      "Epoch 92/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11411377.8242 - val_loss: 11278413.0000\n",
      "Epoch 93/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10783017.3459 - val_loss: 10389954.0000\n",
      "Epoch 94/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10939160.9615 - val_loss: 10484760.0000\n",
      "Epoch 95/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10451885.2444 - val_loss: 10527429.0000\n",
      "Epoch 96/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10961545.3083 - val_loss: 10401229.0000\n",
      "Epoch 97/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10926892.4756 - val_loss: 11119981.0000\n",
      "Epoch 98/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11177695.7180 - val_loss: 10817432.0000\n",
      "Epoch 99/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11168448.1598 - val_loss: 10858480.0000\n",
      "Epoch 100/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10658570.3195 - val_loss: 13629810.0000\n",
      "Epoch 101/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11742491.1974 - val_loss: 11219726.0000\n",
      "Epoch 102/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11680343.3947 - val_loss: 10406323.0000\n",
      "Epoch 103/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11069014.7556 - val_loss: 11130531.0000\n",
      "Epoch 104/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10700890.9041 - val_loss: 12133376.0000\n",
      "Epoch 105/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10873994.1372 - val_loss: 10599650.0000\n",
      "Epoch 106/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11152808.7312 - val_loss: 10570620.0000\n",
      "Epoch 107/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10792302.6081 - val_loss: 11468780.0000\n",
      "Epoch 108/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11019975.9060 - val_loss: 10533851.0000\n",
      "Epoch 109/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10939486.7989 - val_loss: 11773652.0000\n",
      "Epoch 110/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11026033.1071 - val_loss: 12070058.0000\n",
      "Epoch 111/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11560849.6579 - val_loss: 10539561.0000\n",
      "Epoch 112/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10925175.4041 - val_loss: 10610303.0000\n",
      "Epoch 113/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10609749.0738 - val_loss: 10987221.0000\n",
      "Epoch 114/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11075229.9464 - val_loss: 10369421.0000\n",
      "Epoch 115/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11003909.2622 - val_loss: 11170712.0000\n",
      "Epoch 116/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11133642.9925 - val_loss: 10544748.0000\n",
      "Epoch 117/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11086782.3590 - val_loss: 10956968.0000\n",
      "Epoch 118/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11648728.9699 - val_loss: 11978605.0000\n",
      "Epoch 119/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10957118.2744 - val_loss: 11016052.0000\n",
      "Epoch 120/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10968905.9549 - val_loss: 11621979.0000\n",
      "Epoch 121/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11246136.0066 - val_loss: 10752838.0000\n",
      "Epoch 122/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10646255.0597 - val_loss: 10538751.0000\n",
      "Epoch 123/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10512130.3759 - val_loss: 12114240.0000\n",
      "Epoch 124/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11194799.2951 - val_loss: 10370602.0000\n",
      "Epoch 125/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11343081.8797 - val_loss: 11915247.0000\n",
      "Epoch 126/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11737712.1382 - val_loss: 10447840.0000\n",
      "Epoch 127/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10889871.7528 - val_loss: 10438557.0000\n",
      "Epoch 128/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10651433.9850 - val_loss: 11346548.0000\n",
      "Epoch 129/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11309752.8299 - val_loss: 10715806.0000\n",
      "Epoch 130/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11074400.6184 - val_loss: 11754067.0000\n",
      "Epoch 131/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10723883.4417 - val_loss: 10649581.0000\n",
      "Epoch 132/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10796934.9370 - val_loss: 11467916.0000\n",
      "Epoch 133/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11049493.5113 - val_loss: 10450513.0000\n",
      "Epoch 134/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11456656.1673 - val_loss: 10999858.0000\n",
      "Epoch 135/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11105927.7218 - val_loss: 11413370.0000\n",
      "Epoch 136/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11021152.7575 - val_loss: 10736384.0000\n",
      "Epoch 137/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11073155.2303 - val_loss: 12726014.0000\n",
      "Epoch 138/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10943959.5865 - val_loss: 10807330.0000\n",
      "Epoch 139/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11223476.2491 - val_loss: 11868535.0000\n",
      "Epoch 140/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10814627.6936 - val_loss: 10443312.0000\n",
      "Epoch 141/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11254413.4333 - val_loss: 10707968.0000\n",
      "Epoch 142/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10368433.1090 - val_loss: 10786567.0000\n",
      "Epoch 143/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10894174.4737 - val_loss: 11117677.0000\n",
      "Epoch 144/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11512269.9248 - val_loss: 10877985.0000\n",
      "Epoch 145/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11267021.2613 - val_loss: 11554701.0000\n",
      "Epoch 146/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10468937.1917 - val_loss: 10736040.0000\n",
      "Epoch 147/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11050418.2970 - val_loss: 10811614.0000\n",
      "Epoch 148/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10600967.3102 - val_loss: 10382141.0000\n",
      "Epoch 149/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10891578.2773 - val_loss: 10887706.0000\n",
      "Epoch 150/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11161470.6476 - val_loss: 11710124.0000\n",
      "Epoch 151/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10555009.6278 - val_loss: 11131495.0000\n",
      "Epoch 152/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10237572.3318 - val_loss: 10314479.0000\n",
      "Epoch 153/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10765880.5789 - val_loss: 10795226.0000\n",
      "Epoch 154/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11098341.7209 - val_loss: 10600634.0000\n",
      "Epoch 155/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10670267.8421 - val_loss: 10906851.0000\n",
      "Epoch 156/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10380771.1184 - val_loss: 10359658.0000\n",
      "Epoch 157/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10872383.8064 - val_loss: 12187437.0000\n",
      "Epoch 158/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10713703.2462 - val_loss: 13591480.0000\n",
      "Epoch 159/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11837634.2538 - val_loss: 13755359.0000\n",
      "Epoch 160/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10894769.0583 - val_loss: 15583457.0000\n",
      "Epoch 161/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10968157.4417 - val_loss: 12449203.0000\n",
      "Epoch 162/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10904550.3412 - val_loss: 11594803.0000\n",
      "Epoch 163/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10152568.7575 - val_loss: 10928532.0000\n",
      "Epoch 164/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10261933.3120 - val_loss: 10489310.0000\n",
      "Epoch 165/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11126337.7970 - val_loss: 10502802.0000\n",
      "Epoch 166/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11585672.6278 - val_loss: 10509736.0000\n",
      "Epoch 167/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10618094.2162 - val_loss: 10542744.0000\n",
      "Epoch 168/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11271438.5695 - val_loss: 10509545.0000\n",
      "Epoch 169/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11032740.6617 - val_loss: 11731369.0000\n",
      "Epoch 170/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10978110.2556 - val_loss: 11972437.0000\n",
      "Epoch 171/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11159636.4154 - val_loss: 10319197.0000\n",
      "Epoch 172/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10839321.3177 - val_loss: 11860475.0000\n",
      "Epoch 173/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11391500.0733 - val_loss: 11049140.0000\n",
      "Epoch 174/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10252543.6429 - val_loss: 11767212.0000\n",
      "Epoch 175/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10615331.8195 - val_loss: 11491704.0000\n",
      "Epoch 176/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10595178.7180 - val_loss: 11762373.0000\n",
      "Epoch 177/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10920090.7312 - val_loss: 10483313.0000\n",
      "Epoch 178/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10472882.4220 - val_loss: 11660497.0000\n",
      "Epoch 179/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11040972.4502 - val_loss: 11433907.0000\n",
      "Epoch 180/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11165653.3797 - val_loss: 10860576.0000\n",
      "Epoch 181/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11027593.2030 - val_loss: 10852062.0000\n",
      "Epoch 182/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10651200.9314 - val_loss: 10694131.0000\n",
      "Epoch 183/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11455344.7152 - val_loss: 10316772.0000\n",
      "Epoch 184/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10988685.9474 - val_loss: 11061633.0000\n",
      "Epoch 185/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10796427.5338 - val_loss: 11606410.0000\n",
      "Epoch 186/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10863476.3383 - val_loss: 13485241.0000\n",
      "Epoch 187/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11265472.2951 - val_loss: 10755007.0000\n",
      "Epoch 188/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10892407.6889 - val_loss: 10614165.0000\n",
      "Epoch 189/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10219107.5761 - val_loss: 11055015.0000\n",
      "Epoch 190/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11164727.7669 - val_loss: 11155040.0000\n",
      "Epoch 191/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11138473.1429 - val_loss: 11207721.0000\n",
      "Epoch 192/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10971561.2932 - val_loss: 10988462.0000\n",
      "Epoch 193/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11089038.2594 - val_loss: 10390380.0000\n",
      "Epoch 194/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10683524.0846 - val_loss: 10762953.0000\n",
      "Epoch 195/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10744768.5940 - val_loss: 10664908.0000\n",
      "Epoch 196/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11324520.8271 - val_loss: 11089034.0000\n",
      "Epoch 197/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10848525.1786 - val_loss: 10444996.0000\n",
      "Epoch 198/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11390422.1805 - val_loss: 10588175.0000\n",
      "Epoch 199/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10911972.2735 - val_loss: 10562593.0000\n",
      "Epoch 200/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11039427.4586 - val_loss: 10527183.0000\n",
      "Epoch 1/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11103837.1692 - val_loss: 12081495.0000\n",
      "Epoch 2/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10969416.8816 - val_loss: 10879893.0000\n",
      "Epoch 3/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11297496.2312 - val_loss: 10510136.0000\n",
      "Epoch 4/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10551956.7622 - val_loss: 12100214.0000\n",
      "Epoch 5/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11028087.8891 - val_loss: 11299908.0000\n",
      "Epoch 6/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10942352.6316 - val_loss: 11097608.0000\n",
      "Epoch 7/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11151322.0207 - val_loss: 10775619.0000\n",
      "Epoch 8/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10918943.6024 - val_loss: 10277370.0000\n",
      "Epoch 9/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10692772.1034 - val_loss: 11128843.0000\n",
      "Epoch 10/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10715607.9549 - val_loss: 11225747.0000\n",
      "Epoch 11/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10700687.6466 - val_loss: 11163243.0000\n",
      "Epoch 12/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11314462.3205 - val_loss: 10436946.0000\n",
      "Epoch 13/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11050818.3891 - val_loss: 11020348.0000\n",
      "Epoch 14/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10591889.5282 - val_loss: 10709661.0000\n",
      "Epoch 15/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10219596.1852 - val_loss: 13630618.0000\n",
      "Epoch 16/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11643367.0921 - val_loss: 10796270.0000\n",
      "Epoch 17/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10611674.3346 - val_loss: 10547685.0000\n",
      "Epoch 18/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11470971.6128 - val_loss: 10969213.0000\n",
      "Epoch 19/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10894030.2096 - val_loss: 11647215.0000\n",
      "Epoch 20/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10969164.2867 - val_loss: 10358508.0000\n",
      "Epoch 21/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10971424.5508 - val_loss: 10439548.0000\n",
      "Epoch 22/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10603739.9944 - val_loss: 13357230.0000\n",
      "Epoch 23/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11021128.3947 - val_loss: 10469035.0000\n",
      "Epoch 24/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11327030.8346 - val_loss: 11204749.0000\n",
      "Epoch 25/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11316512.2669 - val_loss: 11407223.0000\n",
      "Epoch 26/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10837159.1466 - val_loss: 10373451.0000\n",
      "Epoch 27/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10532566.1241 - val_loss: 11213586.0000\n",
      "Epoch 28/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11014057.4192 - val_loss: 10318206.0000\n",
      "Epoch 29/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11831173.6739 - val_loss: 11181419.0000\n",
      "Epoch 30/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10752807.0291 - val_loss: 11030279.0000\n",
      "Epoch 31/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11124647.7763 - val_loss: 10672086.0000\n",
      "Epoch 32/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10969045.1015 - val_loss: 10912700.0000\n",
      "Epoch 33/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10821758.3703 - val_loss: 10525948.0000\n",
      "Epoch 34/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10769691.5677 - val_loss: 10731962.0000\n",
      "Epoch 35/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10267634.5432 - val_loss: 10879534.0000\n",
      "Epoch 36/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10992424.3694 - val_loss: 10354586.0000\n",
      "Epoch 37/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10591725.9004 - val_loss: 13435522.0000\n",
      "Epoch 38/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10730015.9549 - val_loss: 10851931.0000\n",
      "Epoch 39/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10605907.7942 - val_loss: 10508529.0000\n",
      "Epoch 40/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11141724.5357 - val_loss: 10701122.0000\n",
      "Epoch 41/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10797493.3703 - val_loss: 10441016.0000\n",
      "Epoch 42/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10810211.7848 - val_loss: 10567858.0000\n",
      "Epoch 43/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11137517.4568 - val_loss: 10604648.0000\n",
      "Epoch 44/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10427517.3045 - val_loss: 11278313.0000\n",
      "Epoch 45/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10980788.5987 - val_loss: 11287902.0000\n",
      "Epoch 46/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11200421.1692 - val_loss: 10419649.0000\n",
      "Epoch 47/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11195692.2538 - val_loss: 10575485.0000\n",
      "Epoch 48/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10825760.3741 - val_loss: 10721978.0000\n",
      "Epoch 49/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11604111.9389 - val_loss: 10650965.0000\n",
      "Epoch 50/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10914364.6598 - val_loss: 10573542.0000\n",
      "Epoch 51/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10421903.0320 - val_loss: 11061532.0000\n",
      "Epoch 52/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10885055.6071 - val_loss: 11182820.0000\n",
      "Epoch 53/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11564740.2021 - val_loss: 11894589.0000\n",
      "Epoch 54/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10851834.6419 - val_loss: 10338293.0000\n",
      "Epoch 55/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10719352.3910 - val_loss: 11485184.0000\n",
      "Epoch 56/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10758023.8026 - val_loss: 10669462.0000\n",
      "Epoch 57/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10830149.0169 - val_loss: 11500894.0000\n",
      "Epoch 58/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11620052.6335 - val_loss: 10527345.0000\n",
      "Epoch 59/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10498916.5479 - val_loss: 10610534.0000\n",
      "Epoch 60/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11179745.8872 - val_loss: 11379244.0000\n",
      "Epoch 61/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10454231.9972 - val_loss: 10642286.0000\n",
      "Epoch 62/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10517478.1372 - val_loss: 10793839.0000\n",
      "Epoch 63/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10631825.2660 - val_loss: 10757242.0000\n",
      "Epoch 64/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10766935.3402 - val_loss: 10703843.0000\n",
      "Epoch 65/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10697018.7547 - val_loss: 11044951.0000\n",
      "Epoch 66/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11410459.4643 - val_loss: 11577650.0000\n",
      "Epoch 67/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10851992.5263 - val_loss: 10696550.0000\n",
      "Epoch 68/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11021179.5150 - val_loss: 10859701.0000\n",
      "Epoch 69/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10735126.9746 - val_loss: 11528157.0000\n",
      "Epoch 70/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10712393.7340 - val_loss: 10613404.0000\n",
      "Epoch 71/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10389926.6372 - val_loss: 10638421.0000\n",
      "Epoch 72/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10586974.1222 - val_loss: 11387017.0000\n",
      "Epoch 73/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11095208.4887 - val_loss: 10634843.0000\n",
      "Epoch 74/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10576290.9149 - val_loss: 10584761.0000\n",
      "Epoch 75/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11464322.9079 - val_loss: 11634430.0000\n",
      "Epoch 76/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11608504.8910 - val_loss: 12183791.0000\n",
      "Epoch 77/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11786588.2989 - val_loss: 10439592.0000\n",
      "Epoch 78/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10638397.9352 - val_loss: 10929125.0000\n",
      "Epoch 79/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10893012.3477 - val_loss: 12089589.0000\n",
      "Epoch 80/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11295444.0789 - val_loss: 12179820.0000\n",
      "Epoch 81/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10807035.5865 - val_loss: 11523773.0000\n",
      "Epoch 82/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11353576.5663 - val_loss: 10434885.0000\n",
      "Epoch 83/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10617948.7622 - val_loss: 10762617.0000\n",
      "Epoch 84/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10935978.1203 - val_loss: 12126635.0000\n",
      "Epoch 85/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10153796.3120 - val_loss: 10497074.0000\n",
      "Epoch 86/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11127902.1109 - val_loss: 12239095.0000\n",
      "Epoch 87/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10849231.2284 - val_loss: 10958585.0000\n",
      "Epoch 88/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10856234.1626 - val_loss: 11041421.0000\n",
      "Epoch 89/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10622925.3449 - val_loss: 11245230.0000\n",
      "Epoch 90/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10682860.8214 - val_loss: 10434636.0000\n",
      "Epoch 91/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10857533.2650 - val_loss: 10521036.0000\n",
      "Epoch 92/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11430138.6992 - val_loss: 11131241.0000\n",
      "Epoch 93/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11738686.5940 - val_loss: 12100824.0000\n",
      "Epoch 94/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10978505.3816 - val_loss: 10456925.0000\n",
      "Epoch 95/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10887765.3872 - val_loss: 11718330.0000\n",
      "Epoch 96/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10805587.7989 - val_loss: 11594992.0000\n",
      "Epoch 97/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10869635.3280 - val_loss: 10571835.0000\n",
      "Epoch 98/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11497582.4201 - val_loss: 11968695.0000\n",
      "Epoch 99/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10793344.3910 - val_loss: 11361061.0000\n",
      "Epoch 100/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11170065.9173 - val_loss: 10828037.0000\n",
      "Epoch 101/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10611004.7350 - val_loss: 10506896.0000\n",
      "Epoch 102/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11254551.4699 - val_loss: 12980157.0000\n",
      "Epoch 103/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10642039.5376 - val_loss: 11145912.0000\n",
      "Epoch 104/200\n",
      "531/531 [==============================] - 3121s 6s/step - loss: 10479180.5902 - val_loss: 11056370.0000\n",
      "Epoch 105/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11386453.8966 - val_loss: 10818809.0000\n",
      "Epoch 106/200\n",
      "531/531 [==============================] - 21728s 41s/step - loss: 11427216.9079 - val_loss: 10409824.0000\n",
      "Epoch 107/200\n",
      "531/531 [==============================] - 3s 7ms/step - loss: 10670311.7303 - val_loss: 10309940.0000\n",
      "Epoch 108/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10988125.7284 - val_loss: 11498981.0000\n",
      "Epoch 109/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10799032.9173 - val_loss: 10775009.0000\n",
      "Epoch 110/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11009115.8684 - val_loss: 10346220.0000\n",
      "Epoch 111/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10610836.9530 - val_loss: 10714153.0000\n",
      "Epoch 112/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 10276961.9492 - val_loss: 11245582.0000\n",
      "Epoch 113/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10252252.0902 - val_loss: 10814374.0000\n",
      "Epoch 114/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11359712.1551 - val_loss: 10567823.0000\n",
      "Epoch 115/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 11050925.5160 - val_loss: 10880010.0000\n",
      "Epoch 116/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10998947.7726 - val_loss: 10342150.0000\n",
      "Epoch 117/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 10464341.8553 - val_loss: 10655545.0000\n",
      "Epoch 118/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11334259.6673 - val_loss: 10308885.0000\n",
      "Epoch 119/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10677769.9944 - val_loss: 11330698.0000\n",
      "Epoch 120/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10469433.1419 - val_loss: 10424088.0000\n",
      "Epoch 121/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 10446746.2086 - val_loss: 11431506.0000\n",
      "Epoch 122/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11062417.1466 - val_loss: 10773142.0000\n",
      "Epoch 123/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 10864817.9060 - val_loss: 11540926.0000\n",
      "Epoch 124/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10480576.1203 - val_loss: 10568736.0000\n",
      "Epoch 125/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11019273.5545 - val_loss: 10608665.0000\n",
      "Epoch 126/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10776733.3064 - val_loss: 13409858.0000\n",
      "Epoch 127/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12028261.9643 - val_loss: 11348797.0000\n",
      "Epoch 128/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10593965.7951 - val_loss: 11209446.0000\n",
      "Epoch 129/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10797781.6391 - val_loss: 11416423.0000\n",
      "Epoch 130/200\n",
      "531/531 [==============================] - 1s 1ms/step - loss: 11044111.6175 - val_loss: 10705212.0000\n",
      "Epoch 131/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11089491.7199 - val_loss: 10682115.0000\n",
      "Epoch 132/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11055113.7340 - val_loss: 10810654.0000\n",
      "Epoch 133/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11103469.1147 - val_loss: 10515691.0000\n",
      "Epoch 134/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10605336.2237 - val_loss: 12017732.0000\n",
      "Epoch 135/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10312176.6372 - val_loss: 10900582.0000\n",
      "Epoch 136/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10560079.5912 - val_loss: 12016423.0000\n",
      "Epoch 137/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10521032.8571 - val_loss: 11589294.0000\n",
      "Epoch 138/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10976912.1880 - val_loss: 10438253.0000\n",
      "Epoch 139/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11195648.6861 - val_loss: 10769480.0000\n",
      "Epoch 140/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10663728.0583 - val_loss: 10674743.0000\n",
      "Epoch 141/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11072689.7801 - val_loss: 11333994.0000\n",
      "Epoch 142/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10536696.2331 - val_loss: 10396574.0000\n",
      "Epoch 143/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10834735.0019 - val_loss: 10548274.0000\n",
      "Epoch 144/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10746002.1297 - val_loss: 12587314.0000\n",
      "Epoch 145/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11221670.1748 - val_loss: 10984306.0000\n",
      "Epoch 146/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10732925.5442 - val_loss: 11071987.0000\n",
      "Epoch 147/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11050005.7763 - val_loss: 10485318.0000\n",
      "Epoch 148/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11356128.5357 - val_loss: 10917046.0000\n",
      "Epoch 149/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10503054.5555 - val_loss: 10512611.0000\n",
      "Epoch 150/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10573797.0075 - val_loss: 14569069.0000\n",
      "Epoch 151/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11019816.8609 - val_loss: 11706686.0000\n",
      "Epoch 152/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 9986166.7359 - val_loss: 12455197.0000\n",
      "Epoch 153/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11148247.9507 - val_loss: 10607396.0000\n",
      "Epoch 154/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10697931.9793 - val_loss: 10464131.0000\n",
      "Epoch 155/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11047148.5226 - val_loss: 11948427.0000\n",
      "Epoch 156/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10908033.5113 - val_loss: 10630747.0000\n",
      "Epoch 157/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10941623.1494 - val_loss: 10375706.0000\n",
      "Epoch 158/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10980995.1410 - val_loss: 11468287.0000\n",
      "Epoch 159/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10685348.8628 - val_loss: 10612142.0000\n",
      "Epoch 160/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10666492.9878 - val_loss: 10405560.0000\n",
      "Epoch 161/200\n",
      "531/531 [==============================] - 4s 7ms/step - loss: 10359300.8647 - val_loss: 11913725.0000\n",
      "Epoch 162/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10784699.1100 - val_loss: 10706675.0000\n",
      "Epoch 163/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10843632.4925 - val_loss: 10890147.0000\n",
      "Epoch 164/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 10638574.7030 - val_loss: 10549345.0000\n",
      "Epoch 165/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11590393.1410 - val_loss: 10480150.0000\n",
      "Epoch 166/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10284442.7378 - val_loss: 10479247.0000\n",
      "Epoch 167/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11397472.5564 - val_loss: 10564341.0000\n",
      "Epoch 168/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10797984.1880 - val_loss: 10687526.0000\n",
      "Epoch 169/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10649878.5132 - val_loss: 10640226.0000\n",
      "Epoch 170/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 10952298.6823 - val_loss: 12710482.0000\n",
      "Epoch 171/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 10748013.6147 - val_loss: 11454069.0000\n",
      "Epoch 172/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 10663276.1767 - val_loss: 10315302.0000\n",
      "Epoch 173/200\n",
      "531/531 [==============================] - 3s 6ms/step - loss: 11005078.1184 - val_loss: 10348169.0000\n",
      "Epoch 174/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10483670.1842 - val_loss: 11123097.0000\n",
      "Epoch 175/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10889934.0226 - val_loss: 10329899.0000\n",
      "Epoch 176/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10643250.2143 - val_loss: 10534832.0000\n",
      "Epoch 177/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10612530.2077 - val_loss: 10361864.0000\n",
      "Epoch 178/200\n",
      "531/531 [==============================] - 2s 5ms/step - loss: 10778842.1767 - val_loss: 10328931.0000\n",
      "Epoch 179/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10591599.9436 - val_loss: 11156838.0000\n",
      "Epoch 180/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11061826.4258 - val_loss: 11073885.0000\n",
      "Epoch 181/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10530890.8120 - val_loss: 10778754.0000\n",
      "Epoch 182/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10739857.3402 - val_loss: 12399350.0000\n",
      "Epoch 183/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11197579.4850 - val_loss: 11045232.0000\n",
      "Epoch 184/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10765632.6053 - val_loss: 11903379.0000\n",
      "Epoch 185/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11071843.4906 - val_loss: 11534259.0000\n",
      "Epoch 186/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11357458.8553 - val_loss: 10379687.0000\n",
      "Epoch 187/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10288659.3553 - val_loss: 11993002.0000\n",
      "Epoch 188/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10490125.7068 - val_loss: 11469200.0000\n",
      "Epoch 189/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11067284.8064 - val_loss: 11005105.0000\n",
      "Epoch 190/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10304375.7462 - val_loss: 10436881.0000\n",
      "Epoch 191/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10485958.9276 - val_loss: 10724450.0000\n",
      "Epoch 192/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10427566.6720 - val_loss: 10786167.0000\n",
      "Epoch 193/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10668971.5846 - val_loss: 10765960.0000\n",
      "Epoch 194/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11063908.6306 - val_loss: 10787905.0000\n",
      "Epoch 195/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10513351.3120 - val_loss: 11319224.0000\n",
      "Epoch 196/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11626779.6560 - val_loss: 10418948.0000\n",
      "Epoch 197/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10115485.3769 - val_loss: 11405469.0000\n",
      "Epoch 198/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11313436.7086 - val_loss: 11563063.0000\n",
      "Epoch 199/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10685768.9398 - val_loss: 10690972.0000\n",
      "Epoch 200/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11313469.5207 - val_loss: 10788606.0000\n",
      "Epoch 1/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10844221.7096 - val_loss: 10752097.0000\n",
      "Epoch 2/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10627487.6767 - val_loss: 10818275.0000\n",
      "Epoch 3/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11060818.4305 - val_loss: 11162918.0000\n",
      "Epoch 4/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11122586.1880 - val_loss: 10437370.0000\n",
      "Epoch 5/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10657769.2744 - val_loss: 11193117.0000\n",
      "Epoch 6/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11476162.0658 - val_loss: 10453423.0000\n",
      "Epoch 7/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10839631.0282 - val_loss: 10350868.0000\n",
      "Epoch 8/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10632340.8158 - val_loss: 11248706.0000\n",
      "Epoch 9/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10991914.0338 - val_loss: 10350139.0000\n",
      "Epoch 10/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10914382.1870 - val_loss: 10562617.0000\n",
      "Epoch 11/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10362627.2039 - val_loss: 11473671.0000\n",
      "Epoch 12/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10795375.5028 - val_loss: 11173303.0000\n",
      "Epoch 13/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10892372.8102 - val_loss: 10959890.0000\n",
      "Epoch 14/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10505374.5611 - val_loss: 10623902.0000\n",
      "Epoch 15/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11349950.4793 - val_loss: 10663498.0000\n",
      "Epoch 16/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10352498.4427 - val_loss: 10281771.0000\n",
      "Epoch 17/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10791667.5000 - val_loss: 11472891.0000\n",
      "Epoch 18/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11182162.5216 - val_loss: 11046907.0000\n",
      "Epoch 19/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10967154.2650 - val_loss: 11071452.0000\n",
      "Epoch 20/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10471302.0977 - val_loss: 10377153.0000\n",
      "Epoch 21/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10233206.1429 - val_loss: 10894026.0000\n",
      "Epoch 22/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11453330.8515 - val_loss: 11554123.0000\n",
      "Epoch 23/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10442255.3477 - val_loss: 10386556.0000\n",
      "Epoch 24/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10249015.2058 - val_loss: 10615618.0000\n",
      "Epoch 25/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10743807.2293 - val_loss: 10838417.0000\n",
      "Epoch 26/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11639438.4229 - val_loss: 10925350.0000\n",
      "Epoch 27/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10398619.6269 - val_loss: 10604008.0000\n",
      "Epoch 28/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10185074.4953 - val_loss: 10359899.0000\n",
      "Epoch 29/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10454058.2744 - val_loss: 10326311.0000\n",
      "Epoch 30/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10674613.1748 - val_loss: 10274663.0000\n",
      "Epoch 31/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10223908.0263 - val_loss: 12566427.0000\n",
      "Epoch 32/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10904130.0959 - val_loss: 10337132.0000\n",
      "Epoch 33/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10694295.6419 - val_loss: 10898565.0000\n",
      "Epoch 34/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10632026.8835 - val_loss: 10310461.0000\n",
      "Epoch 35/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10603065.9812 - val_loss: 10590812.0000\n",
      "Epoch 36/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10733774.2716 - val_loss: 12709502.0000\n",
      "Epoch 37/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11302013.8891 - val_loss: 11343204.0000\n",
      "Epoch 38/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11088130.5564 - val_loss: 11235390.0000\n",
      "Epoch 39/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10591004.3759 - val_loss: 10966969.0000\n",
      "Epoch 40/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10785265.3496 - val_loss: 10398543.0000\n",
      "Epoch 41/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10542116.7077 - val_loss: 11569435.0000\n",
      "Epoch 42/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10204179.3496 - val_loss: 10488266.0000\n",
      "Epoch 43/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11003581.6269 - val_loss: 11013397.0000\n",
      "Epoch 44/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11069976.4784 - val_loss: 10666665.0000\n",
      "Epoch 45/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10617918.4868 - val_loss: 10624603.0000\n",
      "Epoch 46/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10263027.8355 - val_loss: 10294351.0000\n",
      "Epoch 47/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11228881.4868 - val_loss: 10842164.0000\n",
      "Epoch 48/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10647666.2632 - val_loss: 10684672.0000\n",
      "Epoch 49/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11198597.8195 - val_loss: 10298633.0000\n",
      "Epoch 50/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10793148.5940 - val_loss: 10928471.0000\n",
      "Epoch 51/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10797986.0113 - val_loss: 10627617.0000\n",
      "Epoch 52/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10971017.0122 - val_loss: 10339163.0000\n",
      "Epoch 53/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10585871.1786 - val_loss: 10892021.0000\n",
      "Epoch 54/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10949754.2218 - val_loss: 11457421.0000\n",
      "Epoch 55/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10658479.7331 - val_loss: 10343072.0000\n",
      "Epoch 56/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11207125.5620 - val_loss: 10270095.0000\n",
      "Epoch 57/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10506977.7491 - val_loss: 11121324.0000\n",
      "Epoch 58/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10994289.0771 - val_loss: 11566102.0000\n",
      "Epoch 59/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10667310.6711 - val_loss: 11394660.0000\n",
      "Epoch 60/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10793769.9737 - val_loss: 10786684.0000\n",
      "Epoch 61/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10763188.4135 - val_loss: 11169582.0000\n",
      "Epoch 62/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10895387.6805 - val_loss: 10947656.0000\n",
      "Epoch 63/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11409370.1222 - val_loss: 10276284.0000\n",
      "Epoch 64/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10379407.1870 - val_loss: 10864186.0000\n",
      "Epoch 65/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11693304.5855 - val_loss: 10636863.0000\n",
      "Epoch 66/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10780900.5780 - val_loss: 12898309.0000\n",
      "Epoch 67/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10673614.4643 - val_loss: 10782412.0000\n",
      "Epoch 68/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11273061.4605 - val_loss: 10613504.0000\n",
      "Epoch 69/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10230313.8130 - val_loss: 10576600.0000\n",
      "Epoch 70/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10425428.0357 - val_loss: 10381348.0000\n",
      "Epoch 71/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10747388.9098 - val_loss: 10482206.0000\n",
      "Epoch 72/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11154641.0959 - val_loss: 10342994.0000\n",
      "Epoch 73/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10388102.9380 - val_loss: 12883610.0000\n",
      "Epoch 74/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11169025.9079 - val_loss: 10810964.0000\n",
      "Epoch 75/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10867497.0663 - val_loss: 11686642.0000\n",
      "Epoch 76/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10858697.1147 - val_loss: 10504215.0000\n",
      "Epoch 77/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11536712.1278 - val_loss: 11900600.0000\n",
      "Epoch 78/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11065095.4427 - val_loss: 10357545.0000\n",
      "Epoch 79/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11202471.1034 - val_loss: 10729009.0000\n",
      "Epoch 80/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10239896.1889 - val_loss: 10940807.0000\n",
      "Epoch 81/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10477136.6786 - val_loss: 13246235.0000\n",
      "Epoch 82/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11329608.1955 - val_loss: 10852545.0000\n",
      "Epoch 83/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10747024.4135 - val_loss: 11599961.0000\n",
      "Epoch 84/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10495278.3064 - val_loss: 11628597.0000\n",
      "Epoch 85/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10476670.1880 - val_loss: 14651551.0000\n",
      "Epoch 86/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 11644415.5921 - val_loss: 10706779.0000\n",
      "Epoch 87/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 11009931.3994 - val_loss: 10619057.0000\n",
      "Epoch 88/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10580672.5996 - val_loss: 11967477.0000\n",
      "Epoch 89/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11621459.2735 - val_loss: 11499401.0000\n",
      "Epoch 90/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10907338.3496 - val_loss: 11884285.0000\n",
      "Epoch 91/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10780033.0724 - val_loss: 10784358.0000\n",
      "Epoch 92/200\n",
      "531/531 [==============================] - 3s 5ms/step - loss: 10540088.2838 - val_loss: 10876969.0000\n",
      "Epoch 93/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11224807.9737 - val_loss: 10465221.0000\n",
      "Epoch 94/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10508874.2274 - val_loss: 11050858.0000\n",
      "Epoch 95/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10745256.0291 - val_loss: 10950206.0000\n",
      "Epoch 96/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10827814.5677 - val_loss: 10894344.0000\n",
      "Epoch 97/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10870629.8929 - val_loss: 10506385.0000\n",
      "Epoch 98/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10335446.4643 - val_loss: 10418562.0000\n",
      "Epoch 99/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10546555.3026 - val_loss: 10277407.0000\n",
      "Epoch 100/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10366049.1598 - val_loss: 10848231.0000\n",
      "Epoch 101/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10658534.3947 - val_loss: 12703627.0000\n",
      "Epoch 102/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10868353.7425 - val_loss: 10637175.0000\n",
      "Epoch 103/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10487469.6551 - val_loss: 11589231.0000\n",
      "Epoch 104/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11185271.4549 - val_loss: 10492930.0000\n",
      "Epoch 105/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11830596.1034 - val_loss: 11330311.0000\n",
      "Epoch 106/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10823932.0320 - val_loss: 10894357.0000\n",
      "Epoch 107/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10458505.8835 - val_loss: 10366420.0000\n",
      "Epoch 108/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11532976.5282 - val_loss: 12538968.0000\n",
      "Epoch 109/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10818535.4398 - val_loss: 11186096.0000\n",
      "Epoch 110/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11288453.2331 - val_loss: 10481045.0000\n",
      "Epoch 111/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10465709.8590 - val_loss: 10780592.0000\n",
      "Epoch 112/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10617483.1259 - val_loss: 10448742.0000\n",
      "Epoch 113/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10387302.2124 - val_loss: 10988877.0000\n",
      "Epoch 114/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 11070977.1805 - val_loss: 10706124.0000\n",
      "Epoch 115/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10649310.5038 - val_loss: 10711911.0000\n",
      "Epoch 116/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11049127.8045 - val_loss: 10662283.0000\n",
      "Epoch 117/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10285773.1720 - val_loss: 10311012.0000\n",
      "Epoch 118/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11126103.8571 - val_loss: 11372867.0000\n",
      "Epoch 119/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11267365.7970 - val_loss: 10845017.0000\n",
      "Epoch 120/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11195286.7246 - val_loss: 10507470.0000\n",
      "Epoch 121/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11150471.8985 - val_loss: 10617973.0000\n",
      "Epoch 122/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10544987.8788 - val_loss: 11071157.0000\n",
      "Epoch 123/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10711163.9117 - val_loss: 10699826.0000\n",
      "Epoch 124/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10596287.5921 - val_loss: 10543437.0000\n",
      "Epoch 125/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10746603.9192 - val_loss: 10285873.0000\n",
      "Epoch 126/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11076951.9756 - val_loss: 11621328.0000\n",
      "Epoch 127/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11382035.8271 - val_loss: 11421876.0000\n",
      "Epoch 128/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10932581.5376 - val_loss: 10318755.0000\n",
      "Epoch 129/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10621744.4173 - val_loss: 11862487.0000\n",
      "Epoch 130/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10733782.2890 - val_loss: 10759709.0000\n",
      "Epoch 131/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10004347.6241 - val_loss: 11691466.0000\n",
      "Epoch 132/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11401883.3816 - val_loss: 10947329.0000\n",
      "Epoch 133/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 11332557.6551 - val_loss: 10325211.0000\n",
      "Epoch 134/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10280603.2904 - val_loss: 10263566.0000\n",
      "Epoch 135/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11043813.4117 - val_loss: 12661212.0000\n",
      "Epoch 136/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10891113.3910 - val_loss: 10318435.0000\n",
      "Epoch 137/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10640461.2068 - val_loss: 11159044.0000\n",
      "Epoch 138/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10858577.6391 - val_loss: 11097502.0000\n",
      "Epoch 139/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10157976.8026 - val_loss: 10961811.0000\n",
      "Epoch 140/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 12433055.4079 - val_loss: 10386213.0000\n",
      "Epoch 141/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10744836.9211 - val_loss: 10971480.0000\n",
      "Epoch 142/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11151193.3853 - val_loss: 10392880.0000\n",
      "Epoch 143/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10330317.4117 - val_loss: 10320535.0000\n",
      "Epoch 144/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10688693.2331 - val_loss: 10745194.0000\n",
      "Epoch 145/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10277917.9352 - val_loss: 10663929.0000\n",
      "Epoch 146/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10000332.9680 - val_loss: 10456688.0000\n",
      "Epoch 147/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11111646.4605 - val_loss: 10749998.0000\n",
      "Epoch 148/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10924846.2914 - val_loss: 10601209.0000\n",
      "Epoch 149/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10412765.3600 - val_loss: 10879272.0000\n",
      "Epoch 150/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10527058.9793 - val_loss: 10645480.0000\n",
      "Epoch 151/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10572446.3280 - val_loss: 12431002.0000\n",
      "Epoch 152/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10758550.0865 - val_loss: 10344601.0000\n",
      "Epoch 153/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10782614.3947 - val_loss: 11452891.0000\n",
      "Epoch 154/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10983276.5395 - val_loss: 11487030.0000\n",
      "Epoch 155/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10665737.0376 - val_loss: 10697925.0000\n",
      "Epoch 156/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11202413.0733 - val_loss: 10574358.0000\n",
      "Epoch 157/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11186582.4690 - val_loss: 10694548.0000\n",
      "Epoch 158/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10600873.7556 - val_loss: 10587657.0000\n",
      "Epoch 159/200\n",
      "531/531 [==============================] - 2s 4ms/step - loss: 10501148.9474 - val_loss: 12600518.0000\n",
      "Epoch 160/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 11275935.3722 - val_loss: 10777550.0000\n",
      "Epoch 161/200\n",
      "531/531 [==============================] - 2s 3ms/step - loss: 10660860.2697 - val_loss: 10294302.0000\n",
      "Epoch 162/200\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 10998711.7998 - val_loss: 10375128.0000\n",
      "Epoch 163/200\n",
      "531/531 [==============================] - 1s 3ms/step - loss: 10658459.9305 - val_loss: 10659286.0000\n",
      "Epoch 164/200\n",
      "272/531 [==============>...............] - ETA: 0s - loss: 11975072.6507"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-a64e65e755cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mMAPE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mRMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(8,)))\n",
    "model.add(tf.keras.layers.Dense(8, kernel_initializer = 'normal', activation  = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(8, kernel_initializer = 'normal', activation  = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(8, kernel_initializer = 'normal', activation  = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1, kernel_initializer = 'normal'))\n",
    "with open('errors.txt','w') as f:\n",
    "    for lr in np.arange(0.001, 0.05, 0.001):\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=0.005)\n",
    "        model.compile(loss='mse', optimizer=optimizer)\n",
    "        history = model.fit(X_train, y_train, batch_size = 20, epochs = 200, validation_data=(X_test, y_test))\n",
    "        MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))\n",
    "        RMSE = np.mean((np.sqrt((y_test-model.predict(X_test))**2)))\n",
    "        f.write(f'{str(MAPE)} {str(RMSE)}\\n')\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.savefig(f\"/home/arvas/Math/IA/pictures/losses/loss_{lr}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5620ae7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 177523388.3008 - val_loss: 37439240.0000\n",
      "Epoch 2/300\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 38024325.5075 - val_loss: 38117620.0000\n",
      "Epoch 3/300\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 37361803.6955 - val_loss: 34676124.0000\n",
      "Epoch 4/300\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 35037913.2707 - val_loss: 34446472.0000\n",
      "Epoch 5/300\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 33933328.5639 - val_loss: 33791220.0000\n",
      "Epoch 6/300\n",
      "531/531 [==============================] - 1s 2ms/step - loss: 33070789.5320 - val_loss: 32721096.0000\n",
      "Epoch 7/300\n",
      "301/531 [================>.............] - ETA: 0s - loss: 33115472.1794"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-46faadf70a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ee76f2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.04566173289092\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))\n",
    "print(MAPE)\n",
    "import matplotlib.pyplot as plt\n",
    "# print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
